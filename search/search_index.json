{
    "docs": [
        {
            "location": "/", 
            "text": "Introduction\n\n\nWhen designing and building APIs, there are a lot of things to consider. Among these are \nsecurity\n, \nmedia types\n, \ndocumentation\n, and \nversioning\n. These, and a lot of other concerns, are what we address here, in order to offer comprehensible guidelines on how to design APIs.\n\n\nMotivation\n\n\nThe motivation behind the \nAPI Guidelines\n is to define standards or \"best practices\" in order to:\n\n\n\n\ndesign robust and long-lasting APIs of high quality\n\n\ndesign APIs that are easy to understand and use\n\n\nhave a consistent API \"look and feel\" across the board\n\n\nfacilitate APIs as a Product\n\n\n\n\nAbout These Guidelines\n\n\nThese guidelines are a work in progress, and is maintained by the \nAPI Enablement Team\n \nNow defunct - who then?\n during their initial work. Later teams are responsible for adhering to these guidelines during API design and development, and to continue to evolve these guidelines.\n\n\nWhat should we do when the guideline changes? Do existing APIs have to be changed as well?\n\n\nConventions Used in These Guidelines\n\n\nIn these guidelines when referring to an API, we implicitly mean a web API delivered over HTTP.\n\n\nThe terms: API, web API, and public API may be used interchangeably throughout these guidelines.\n\n\nThe following typographical conventions are used in these guidelines:\n\n\nConstant width\n program listings, as well as within paragraphs to refer to URLs, mime types, HTTP methods, HTTP headers, and HTTP status codes.\n\n\nEach section will usually be comprised of one or more lists of recommendations:\n\n\n\n\nDO\n to signify that you should do this.\n\n\nCONSIDER\n to signify that you should consider doing this.\n\n\nAVOID\n to signify that you should avoid doing this.\n\n\nDO NOT\n to signify that you should not do this.\n\n\n\n\nShould we consider using the requirement level keywords \nMUST\n, \nSHOULD\n, etc., from RFC 2119 instead?\n\n\nAdmonitions\n\n\n\n\nNote\n\n\nthese sections hold additional information\n\n\n\n\n\n\nTip\n\n\nthese sections hold tips\n\n\n\n\n\n\nWarning\n\n\nthese sections hold cautions\n\n\n\n\n\n\nLarger blocks of code and examples\n\n\ncurl https://example.org/api/resource \n|\n jq", 
            "title": "Introduction"
        }, 
        {
            "location": "/#introduction", 
            "text": "When designing and building APIs, there are a lot of things to consider. Among these are  security ,  media types ,  documentation , and  versioning . These, and a lot of other concerns, are what we address here, in order to offer comprehensible guidelines on how to design APIs.", 
            "title": "Introduction"
        }, 
        {
            "location": "/#motivation", 
            "text": "The motivation behind the  API Guidelines  is to define standards or \"best practices\" in order to:   design robust and long-lasting APIs of high quality  design APIs that are easy to understand and use  have a consistent API \"look and feel\" across the board  facilitate APIs as a Product", 
            "title": "Motivation"
        }, 
        {
            "location": "/#about-these-guidelines", 
            "text": "These guidelines are a work in progress, and is maintained by the  API Enablement Team   Now defunct - who then?  during their initial work. Later teams are responsible for adhering to these guidelines during API design and development, and to continue to evolve these guidelines.  What should we do when the guideline changes? Do existing APIs have to be changed as well?", 
            "title": "About These Guidelines"
        }, 
        {
            "location": "/#conventions-used-in-these-guidelines", 
            "text": "In these guidelines when referring to an API, we implicitly mean a web API delivered over HTTP.  The terms: API, web API, and public API may be used interchangeably throughout these guidelines.  The following typographical conventions are used in these guidelines:  Constant width  program listings, as well as within paragraphs to refer to URLs, mime types, HTTP methods, HTTP headers, and HTTP status codes.  Each section will usually be comprised of one or more lists of recommendations:   DO  to signify that you should do this.  CONSIDER  to signify that you should consider doing this.  AVOID  to signify that you should avoid doing this.  DO NOT  to signify that you should not do this.   Should we consider using the requirement level keywords  MUST ,  SHOULD , etc., from RFC 2119 instead?", 
            "title": "Conventions Used in These Guidelines"
        }, 
        {
            "location": "/#admonitions", 
            "text": "Note  these sections hold additional information    Tip  these sections hold tips    Warning  these sections hold cautions    Larger blocks of code and examples  curl https://example.org/api/resource  |  jq", 
            "title": "Admonitions"
        }, 
        {
            "location": "/api-design/", 
            "text": "Spec-Driven Development\n\n\nThe overall point of view on API design is to approach API design from the 'outside-in' perspective.\n\n\nThe orientation for APIs is to think about design choices from the application developer's point of view. \n\n\nThe goal is to make the developers as successful as possible.\n\n\nThe primary design principle when crafting your API should be to maximize developer productivity and success. This is what we call pragmatic REST.\n\n\nYou have to get the design right, because design communicates how something will be used.\n\n\nThe question becomes - what is the design with optimal benefit for the app developer?\n\n\nThe developer point of view is the guiding principle for all the specific tips and best practices we've compiled\n\n\nWe call our point of view in API design \"pragmatic REST\", because it places the success of the developer over and above any other design principle. The developer is the customer for the Web API.\n\n\nThe success of an API design is measured by how quickly developers can get up to speed and start enjoying success using your API.\n\n\nFeedback\n\n\nOne of the quickest ways to get feedback on your API is to define it using a specification language. An API specification language allows for building APIs in a consistent manner, utilizing pattern design and code reuse to help ensure that the APIs remains uniform across the full interface, keeping resources and methods standardized.\n\n\n\n\nDO\n define Your API in a flexible, but standard specification language (e.g. RAML, Swagger, JSON-API, etc.).\n\n\n\n\n\n\nBe aware that none of the popular specification frameworks support Hypermedia Links (let alone HATEOS). \n\n\n\n\nCode to the Spec... and Don't Deviate\n\n\nIf you have taken advantage of the above steps and carefully laid out your API, carefully designed your spec, user tested, and perfected your API \u2013 there is nothing worse than throwing all that work away by deviating from the spec and doing one-off things.\n\n\nMUST: Follow API First Principle\n\n\nAs mentioned in the introduction, API First is one of our engineering and architecture principles. In a nutshell API First requires two aspects:\n\n\n\n\ndefine APIs outside the code first using a standard specification language get early review feedback from peers and client developers\n\n\nBy defining APIs outside the code, we want to facilitate early review feedback and also a development discipline that focus service interface design on...\n\n\nprofound understanding of the domain and required functionality\n\n\ngeneralized business entities / resources, i.e. avoidance of use case specific APIs\n\n\nclear separation of WHAT vs. HOW concerns, i.e. abstraction from implementation aspects \u2014 APIs should be stable even if we \n    replace complete service implementation including its underlying technology stack\n\n\nMoreover, API definitions with standardized specification format also facilitate...\n\n\nsingle source of truth for the API specification; it is a crucial part of a contract between service provider and client users\n\n\ninfrastructure tooling for API discovery, API GUIs, API documents, automated quality checks\n\n\n\n\nAn element of API First are also this API Guidelines and a lightweight API review process [internal link] as to get early review feedback from peers and client developers. Peer review is important for us to get high quality APIs, to enable architectural and design alignment and to supported development of client applications decoupled from service provider engineering life cycle.\n\n\nIt is important to learn, that API First is not in conflict with the agile development principles that we love. Service applications should evolve incrementally \u2014 and so its APIs. Of course, our API specification will and should evolve iteratively in different cycles; however, each starting with draft status and early team and peer review feedback. API may change and profit from implementation concerns and automated testing feedback. API evolution during development life cycle may include breaking changes for not yet productive features and as long as we have aligned the changes with the clients. Hence, API First does not mean that you must have 100% domain and requirement understanding and can never produce code before you have defined the complete API and get it confirmed by peer review. On the other hand, API First obviously is in conflict with the bad practice of publishing API definition and asking for peer review after the service integration or even the service productive operation has started. It is crucial to request and get early feedback \u2014 as early as possible, but not before the API changes are comprehensive with focus to the next evolution step and have a certain quality (including API Guideline compliance), already confirmed via team internal reviews.\n\n\nMUST: Write APIs in U.S. English\n\n\nThe API Guild drafted and owns this document.\n\n\nThe list of status code that can be omitted from API specifications includes but is not limited to:\n\n\n401 Unauthorized\n403 Forbidden\n404 Not Found unless it has some additional semantics\n405 Method Not Allowed\n406 Not Acceptable\n408 Request Timeout\n413 Payload Too Large\n414 URI Too Long\n415 Unsupported Media Type\n500 Internal Server Error\n503 Service Unavailable\n\n\nMUST: Provide Online Access to OpenAPI Reference Definition\n\n\nMUST: Use REST Maturity Level 2\n\n\nWe strive for a good implementation of REST Maturity Level 2 as it enables us to build resource-oriented APIs that make full use of HTTP verbs and status codes. You can see this expressed by many rules throughout these guidelines, e.g.:\n\n\nAvoid Actions \u2014 Think About Resources\nKeep URLs Verb-Free\nUse HTTP Methods Correctly\nUse Meaningful HTTP Status Codes\nAlthough this is not HATEOAS, it should not prevent you from designing proper link relationships in your APIs as stated in rules below.\n\n\nMAY: Use REST Maturity Level 3 - HATEOAS\n\n\nWe do not generally recommend to implement REST Maturity Level 3. HATEOAS comes with additional API complexity without real value in our SOA context where client and server interact via REST APIs and provide complex business functions as part of our e-commerce SaaS platform.\n\n\nOur major concerns regarding the promised advantages of HATEOAS (see also RESTistential Crisis over Hypermedia APIs, Why I Hate HATEOAS and others):\n\n\nWe follow the API First principle with APIs explicitly defined outside the code with standard specification language. HATEOAS does not really add value for SOA client engineers in terms of API self-descriptiveness: a client engineer finds necessary links and usage description (depending on resource state) in the API reference definition anyway.\nGeneric HATEOAS clients which need no prior knowledge about APIs and explore API capabilities based on hypermedia information provided, is a theoretical concept that we haven't seen working in practise and does not fit to our SOA set-up. The OpenAPI description format (and tooling based on OpenAPI) doesn't provide sufficient support for HATEOAS either.\nIn practice relevant HATEOAS approximations (e.g. following specifications like HAL or JSON API) support API navigation by abstracting from URL endpoint and HTTP method aspects via link types. So, Hypermedia does not prevent clients from required manual changes when domain model changes over time.\nHypermedia make sense for humans, less for SOA machine clients. We would expect use cases where it may provide value more likely in the frontend and human facing service domain.\nHypermedia does not prevent API clients to implement shortcuts and directly target resources without 'discovering' them\nHowever, we do not forbid HATEOAS; you could use it, if you checked its limitations and still see clear value for your usage scenario that justifies its additional complexity. If you use HATEOAS please share experience and present your findings in the API Guild [internal link].\n\n\nDog-food your own API\n\n\nChatty APIs\n\n\nLet's think about how app developers use that API you're designing and dealing with chatty APIs.\n\n\nImagine how developers will use your API\n\n\nWhen designing your API and resources, try to imagine how developers will use it to say construct a user interface, an iPhone app, or many other apps.\n\n\nSome API designs become very chatty - meaning just to build a simple UI or app, you have dozens or hundreds of API calls back to the server.\n\n\nThe API team can sometimes decide not to deal with creating a nice, resource-oriented RESTful API, and just fall back to a mode where they create the 3 or 4 Java-style getter and setter methods they know they need to power a particular user interface.\n\n\nWe don't recommend this. You can design a RESTful API and still mitigate the chattiness.\n\n\nBe complete and RESTful and provide shortcuts\n\n\nFirst design your API and its resources according to pragmatic RESTful design principles and then provide shortcuts.\n\n\nWhat kind of shortcut? Say you know that 80% of all your apps are going to need some sort of composite response, then build the kind of request that gives them what they need.\n\n\nJust don't do the latter instead of the former. First design using good pragmatic RESTful principles!\n\n\nTake advantage of the partial response syntax\n\n\nThe partial response syntax discussed in a previous section can help.\n\n\nTo avoid creating one-off base URLs, you can use the partial response syntax to drill down to dependent and associated resources.\n\n\nIn the case of our dogs API, the dogs have association with owners, who in turn have associations with veterinarians, and so on. Keep nesting the partial response syntax using dot notation to get back just the information you need.\n\n\n/owners/5678?fields=name,dogs.name", 
            "title": "Api design"
        }, 
        {
            "location": "/api-design/#spec-driven-development", 
            "text": "The overall point of view on API design is to approach API design from the 'outside-in' perspective.  The orientation for APIs is to think about design choices from the application developer's point of view.   The goal is to make the developers as successful as possible.  The primary design principle when crafting your API should be to maximize developer productivity and success. This is what we call pragmatic REST.  You have to get the design right, because design communicates how something will be used.  The question becomes - what is the design with optimal benefit for the app developer?  The developer point of view is the guiding principle for all the specific tips and best practices we've compiled  We call our point of view in API design \"pragmatic REST\", because it places the success of the developer over and above any other design principle. The developer is the customer for the Web API.  The success of an API design is measured by how quickly developers can get up to speed and start enjoying success using your API.", 
            "title": "Spec-Driven Development"
        }, 
        {
            "location": "/api-design/#feedback", 
            "text": "One of the quickest ways to get feedback on your API is to define it using a specification language. An API specification language allows for building APIs in a consistent manner, utilizing pattern design and code reuse to help ensure that the APIs remains uniform across the full interface, keeping resources and methods standardized.   DO  define Your API in a flexible, but standard specification language (e.g. RAML, Swagger, JSON-API, etc.).    Be aware that none of the popular specification frameworks support Hypermedia Links (let alone HATEOS).", 
            "title": "Feedback"
        }, 
        {
            "location": "/api-design/#code-to-the-spec-and-dont-deviate", 
            "text": "If you have taken advantage of the above steps and carefully laid out your API, carefully designed your spec, user tested, and perfected your API \u2013 there is nothing worse than throwing all that work away by deviating from the spec and doing one-off things.", 
            "title": "Code to the Spec... and Don't Deviate"
        }, 
        {
            "location": "/api-design/#must-follow-api-first-principle", 
            "text": "As mentioned in the introduction, API First is one of our engineering and architecture principles. In a nutshell API First requires two aspects:   define APIs outside the code first using a standard specification language get early review feedback from peers and client developers  By defining APIs outside the code, we want to facilitate early review feedback and also a development discipline that focus service interface design on...  profound understanding of the domain and required functionality  generalized business entities / resources, i.e. avoidance of use case specific APIs  clear separation of WHAT vs. HOW concerns, i.e. abstraction from implementation aspects \u2014 APIs should be stable even if we \n    replace complete service implementation including its underlying technology stack  Moreover, API definitions with standardized specification format also facilitate...  single source of truth for the API specification; it is a crucial part of a contract between service provider and client users  infrastructure tooling for API discovery, API GUIs, API documents, automated quality checks   An element of API First are also this API Guidelines and a lightweight API review process [internal link] as to get early review feedback from peers and client developers. Peer review is important for us to get high quality APIs, to enable architectural and design alignment and to supported development of client applications decoupled from service provider engineering life cycle.  It is important to learn, that API First is not in conflict with the agile development principles that we love. Service applications should evolve incrementally \u2014 and so its APIs. Of course, our API specification will and should evolve iteratively in different cycles; however, each starting with draft status and early team and peer review feedback. API may change and profit from implementation concerns and automated testing feedback. API evolution during development life cycle may include breaking changes for not yet productive features and as long as we have aligned the changes with the clients. Hence, API First does not mean that you must have 100% domain and requirement understanding and can never produce code before you have defined the complete API and get it confirmed by peer review. On the other hand, API First obviously is in conflict with the bad practice of publishing API definition and asking for peer review after the service integration or even the service productive operation has started. It is crucial to request and get early feedback \u2014 as early as possible, but not before the API changes are comprehensive with focus to the next evolution step and have a certain quality (including API Guideline compliance), already confirmed via team internal reviews.", 
            "title": "MUST: Follow API First Principle"
        }, 
        {
            "location": "/api-design/#must-write-apis-in-us-english", 
            "text": "The API Guild drafted and owns this document.  The list of status code that can be omitted from API specifications includes but is not limited to:  401 Unauthorized\n403 Forbidden\n404 Not Found unless it has some additional semantics\n405 Method Not Allowed\n406 Not Acceptable\n408 Request Timeout\n413 Payload Too Large\n414 URI Too Long\n415 Unsupported Media Type\n500 Internal Server Error\n503 Service Unavailable", 
            "title": "MUST: Write APIs in U.S. English"
        }, 
        {
            "location": "/api-design/#must-provide-online-access-to-openapi-reference-definition", 
            "text": "", 
            "title": "MUST: Provide Online Access to OpenAPI Reference Definition"
        }, 
        {
            "location": "/api-design/#must-use-rest-maturity-level-2", 
            "text": "We strive for a good implementation of REST Maturity Level 2 as it enables us to build resource-oriented APIs that make full use of HTTP verbs and status codes. You can see this expressed by many rules throughout these guidelines, e.g.:  Avoid Actions \u2014 Think About Resources\nKeep URLs Verb-Free\nUse HTTP Methods Correctly\nUse Meaningful HTTP Status Codes\nAlthough this is not HATEOAS, it should not prevent you from designing proper link relationships in your APIs as stated in rules below.", 
            "title": "MUST: Use REST Maturity Level 2"
        }, 
        {
            "location": "/api-design/#may-use-rest-maturity-level-3-hateoas", 
            "text": "We do not generally recommend to implement REST Maturity Level 3. HATEOAS comes with additional API complexity without real value in our SOA context where client and server interact via REST APIs and provide complex business functions as part of our e-commerce SaaS platform.  Our major concerns regarding the promised advantages of HATEOAS (see also RESTistential Crisis over Hypermedia APIs, Why I Hate HATEOAS and others):  We follow the API First principle with APIs explicitly defined outside the code with standard specification language. HATEOAS does not really add value for SOA client engineers in terms of API self-descriptiveness: a client engineer finds necessary links and usage description (depending on resource state) in the API reference definition anyway.\nGeneric HATEOAS clients which need no prior knowledge about APIs and explore API capabilities based on hypermedia information provided, is a theoretical concept that we haven't seen working in practise and does not fit to our SOA set-up. The OpenAPI description format (and tooling based on OpenAPI) doesn't provide sufficient support for HATEOAS either.\nIn practice relevant HATEOAS approximations (e.g. following specifications like HAL or JSON API) support API navigation by abstracting from URL endpoint and HTTP method aspects via link types. So, Hypermedia does not prevent clients from required manual changes when domain model changes over time.\nHypermedia make sense for humans, less for SOA machine clients. We would expect use cases where it may provide value more likely in the frontend and human facing service domain.\nHypermedia does not prevent API clients to implement shortcuts and directly target resources without 'discovering' them\nHowever, we do not forbid HATEOAS; you could use it, if you checked its limitations and still see clear value for your usage scenario that justifies its additional complexity. If you use HATEOAS please share experience and present your findings in the API Guild [internal link].", 
            "title": "MAY: Use REST Maturity Level 3 - HATEOAS"
        }, 
        {
            "location": "/api-design/#dog-food-your-own-api", 
            "text": "", 
            "title": "Dog-food your own API"
        }, 
        {
            "location": "/api-design/#chatty-apis", 
            "text": "Let's think about how app developers use that API you're designing and dealing with chatty APIs.  Imagine how developers will use your API  When designing your API and resources, try to imagine how developers will use it to say construct a user interface, an iPhone app, or many other apps.  Some API designs become very chatty - meaning just to build a simple UI or app, you have dozens or hundreds of API calls back to the server.  The API team can sometimes decide not to deal with creating a nice, resource-oriented RESTful API, and just fall back to a mode where they create the 3 or 4 Java-style getter and setter methods they know they need to power a particular user interface.  We don't recommend this. You can design a RESTful API and still mitigate the chattiness.  Be complete and RESTful and provide shortcuts  First design your API and its resources according to pragmatic RESTful design principles and then provide shortcuts.  What kind of shortcut? Say you know that 80% of all your apps are going to need some sort of composite response, then build the kind of request that gives them what they need.  Just don't do the latter instead of the former. First design using good pragmatic RESTful principles!  Take advantage of the partial response syntax  The partial response syntax discussed in a previous section can help.  To avoid creating one-off base URLs, you can use the partial response syntax to drill down to dependent and associated resources.  In the case of our dogs API, the dogs have association with owners, who in turn have associations with veterinarians, and so on. Keep nesting the partial response syntax using dot notation to get back just the information you need.  /owners/5678?fields=name,dogs.name", 
            "title": "Chatty APIs"
        }, 
        {
            "location": "/apis/", 
            "text": "Application Programming Interfaces\n\n\nAn API specifies how software should interact. Particularly, how a client can use an API, what URIs are available, what HTTP methods may be used, what query string parameters it accepts, what data can be sent, and what responses to expect.\n\n\nAPI as a Product\n\n\nWhen creating APIs intended for use by someone else, whether it is actually sold or not, it can and should most likely be treated as a product in itself.\n\n\nThis can be very easy to lose sight of, so before jumping to the more specific advice on how to achieve successful APIs, keep the following overall principles in mind:\n\n\nBe Customer-Centric\n\n\nDo not focus on data rather than customers. Instead focus on target developer's problems, by involving customers early in the design process. Make use of reviews and customers feedback, and provide service level support. Make APIs irresistible by having a high attention to API quality and client developer experience.\n\n\n\n\nTreat Every API as if it was a Public API\n\n\nDo not skip on usability and security when creating private or partner APIs, as this can make the transition into a public API difficult. Instead actively improve and maintain API consistency over the long term.\n\n\nComponentize Your Systems\n\n\nIdentifying, breaking apart, and isolating small feature sets in big systems:\n\n\n\n\ncan help innovation by creating platforms to enable other organizations to build new applications that better suit their needs\n\n\noffers a higher degree of composability, which makes it possible to offer products as open systems instead of inflexible off-the-shelf solutions\n\n\nmay help monetize existing assets\n\n\n\n\nTypes of APIs\n\n\nWeb APIs can typically be broken into two broad categories: \nRPC\n and \nREST\n. These guidelines will only deal with REST.\n\n\nRPC (Remote Procedure Call)\nRPC (e.g., gRPC and SOAP) is generally a poor fit for most public API implementations, as they usually require special purpose libraries or SDKs to work properly. A requirement that a lot of clients cannot meet without a lot of extra work and/or clunky third-party libraries.\nThis, and the fact that most RPC implementations do not use HTTP to its full extend, has led us to \nexclude RPC from these guidelines\n. However, if all of your clients are using legacy systems that depend on SOAP libraries, it may make more sense in that case to build a SOAP API for them.\nA lot of documentation, best practices and general advise on how to build RPC APIs can be found throughout the web.\nOrganizing APIs\n\n\nLarge API vendors (like Facebook, Twitter, and Foursquare) usually have their APIs organized behind one or more subdomains, like e.g.:\n\n\n\n\n\n\n\n\nFacebook\n\n\nTwitter\n\n\nForsquare\n\n\n\n\n\n\n\n\n\n\ngraph.facebook.com\n\n\nstream.twitter.com\n\n\napi.foursquare.com\n\n\n\n\n\n\napi.facebook.com\n\n\napi.twitter.com\n\n\n\n\n\n\n\n\n\n\nsearch.twitter.com\n\n\n\n\n\n\n\n\n\n\nIt is not difficult to imagine how Facebook and Twitter ended up with more than one API - timing, team organization, acquisitions have likely played their part. However, following Foursquare's lead and consolidating all API requests under one API subdomain, might be the best interest of API consumers.\n\n\n\n\nDO\n consolidate API requests in one subdomain, e.g. \nhttps://api.example.org\n. It is cleaner, easier and more intuitive for developers who want to build cool stuff using your APIs.\n\n\n\n\nDeveloper Portal\n\n\nA developer portal might be a good idea for hosting examples, application notes, authentication guidance, human-readable documentation, error scenarios and descriptions, etc. Again some of the major API vendors all have dedicated developer portals:\n\n\n\n\n\n\n\n\nFacebook\n\n\nTwitter\n\n\nForsquare\n\n\n\n\n\n\n\n\n\n\ndevelopers.facebook.com\n\n\ndev.twitter.com\n\n\ndevelopers.foursquare.com\n\n\n\n\n\n\n\n\n\n\nDO\n use the \ndev.example.org\n or \ndevelopers.example.org\n subdomains to expose your developer portal, if the API subdomain resides on \napi.example.org\n.\n\n\nCONSIDER\n using redirects, if you can gather based on the incoming request from a browser where the developer really needs to go. E.g., if a developer types \napi.example.org\n in the browser without any furher information in the \nGET\n request, it is probably safe to redirect to the developer portal and help get the developer.\n\n\n\n\nAPI Operation\n\n\n\n\nDO\n setup instrumentation from the outset of the API implementation to monitor important business metrics/KPIs.\n\n\nDO\n gather information about the clients. This information, for instance, is useful to identify potential review partners for API changes.\n\n\n\n\n\n\nTools\n\n\nThe demand for flexibility and extensibility has driven the development of APIs and tools alike, and in many regards it has never been easier to create an API than it is today with multitudes of frameworks (such as JAX-RS, Apigility, Django REST Framework, Grape), specs (RAML, Swagger, API Blueprint, IO Docs), and tools (API Designer, API Science, APImatic) available.", 
            "title": "Application Programming Interfaces"
        }, 
        {
            "location": "/apis/#application-programming-interfaces", 
            "text": "An API specifies how software should interact. Particularly, how a client can use an API, what URIs are available, what HTTP methods may be used, what query string parameters it accepts, what data can be sent, and what responses to expect.", 
            "title": "Application Programming Interfaces"
        }, 
        {
            "location": "/apis/#api-as-a-product", 
            "text": "When creating APIs intended for use by someone else, whether it is actually sold or not, it can and should most likely be treated as a product in itself.  This can be very easy to lose sight of, so before jumping to the more specific advice on how to achieve successful APIs, keep the following overall principles in mind:", 
            "title": "API as a Product"
        }, 
        {
            "location": "/apis/#be-customer-centric", 
            "text": "Do not focus on data rather than customers. Instead focus on target developer's problems, by involving customers early in the design process. Make use of reviews and customers feedback, and provide service level support. Make APIs irresistible by having a high attention to API quality and client developer experience.", 
            "title": "Be Customer-Centric"
        }, 
        {
            "location": "/apis/#treat-every-api-as-if-it-was-a-public-api", 
            "text": "Do not skip on usability and security when creating private or partner APIs, as this can make the transition into a public API difficult. Instead actively improve and maintain API consistency over the long term.", 
            "title": "Treat Every API as if it was a Public API"
        }, 
        {
            "location": "/apis/#componentize-your-systems", 
            "text": "Identifying, breaking apart, and isolating small feature sets in big systems:   can help innovation by creating platforms to enable other organizations to build new applications that better suit their needs  offers a higher degree of composability, which makes it possible to offer products as open systems instead of inflexible off-the-shelf solutions  may help monetize existing assets", 
            "title": "Componentize Your Systems"
        }, 
        {
            "location": "/apis/#types-of-apis", 
            "text": "Web APIs can typically be broken into two broad categories:  RPC  and  REST . These guidelines will only deal with REST.  RPC (Remote Procedure Call) RPC (e.g., gRPC and SOAP) is generally a poor fit for most public API implementations, as they usually require special purpose libraries or SDKs to work properly. A requirement that a lot of clients cannot meet without a lot of extra work and/or clunky third-party libraries. This, and the fact that most RPC implementations do not use HTTP to its full extend, has led us to  exclude RPC from these guidelines . However, if all of your clients are using legacy systems that depend on SOAP libraries, it may make more sense in that case to build a SOAP API for them. A lot of documentation, best practices and general advise on how to build RPC APIs can be found throughout the web.", 
            "title": "Types of APIs"
        }, 
        {
            "location": "/apis/#organizing-apis", 
            "text": "Large API vendors (like Facebook, Twitter, and Foursquare) usually have their APIs organized behind one or more subdomains, like e.g.:     Facebook  Twitter  Forsquare      graph.facebook.com  stream.twitter.com  api.foursquare.com    api.facebook.com  api.twitter.com      search.twitter.com      It is not difficult to imagine how Facebook and Twitter ended up with more than one API - timing, team organization, acquisitions have likely played their part. However, following Foursquare's lead and consolidating all API requests under one API subdomain, might be the best interest of API consumers.   DO  consolidate API requests in one subdomain, e.g.  https://api.example.org . It is cleaner, easier and more intuitive for developers who want to build cool stuff using your APIs.", 
            "title": "Organizing APIs"
        }, 
        {
            "location": "/apis/#developer-portal", 
            "text": "A developer portal might be a good idea for hosting examples, application notes, authentication guidance, human-readable documentation, error scenarios and descriptions, etc. Again some of the major API vendors all have dedicated developer portals:     Facebook  Twitter  Forsquare      developers.facebook.com  dev.twitter.com  developers.foursquare.com      DO  use the  dev.example.org  or  developers.example.org  subdomains to expose your developer portal, if the API subdomain resides on  api.example.org .  CONSIDER  using redirects, if you can gather based on the incoming request from a browser where the developer really needs to go. E.g., if a developer types  api.example.org  in the browser without any furher information in the  GET  request, it is probably safe to redirect to the developer portal and help get the developer.", 
            "title": "Developer Portal"
        }, 
        {
            "location": "/apis/#api-operation", 
            "text": "DO  setup instrumentation from the outset of the API implementation to monitor important business metrics/KPIs.  DO  gather information about the clients. This information, for instance, is useful to identify potential review partners for API changes.", 
            "title": "API Operation"
        }, 
        {
            "location": "/apis/#tools", 
            "text": "The demand for flexibility and extensibility has driven the development of APIs and tools alike, and in many regards it has never been easier to create an API than it is today with multitudes of frameworks (such as JAX-RS, Apigility, Django REST Framework, Grape), specs (RAML, Swagger, API Blueprint, IO Docs), and tools (API Designer, API Science, APImatic) available.", 
            "title": "Tools"
        }, 
        {
            "location": "/caching/", 
            "text": "Caching and Conditional Requests\n\n\nCaching is one of the most useful features built on top of HTTP's uniform interface. You can take advantage of caching to reduce end user perceived latency, to increase reliasbility, to reduce bandwidth usage and cost, and to reduce server load. They can be in server network, content delivery networks (CDNs), or in the client network (forward proxies).\n\n\nIt is common to use the word \ncache\n to refer to either an object cache (memcached) or HTTP caches. Both of these caches improve performacne and have key roles to play in the overall web service deployment architecture. But there is an important difference between the two. HTTP caches do not require clients and servers to call any special programming API to manage data in the cache, as long as you are using HTTP as defined.\n\n\norigin server\n\n\nThey are slightly different - the ETag does not have any information that the client can use to determine whether or not to make a request for that file again in the future. If ETag is all it has, it will always have to make a request. However, when the server reads the ETag from the client request, the server can then determine whether to send the file (HTTP 200) or tell the client to just use their local copy (HTTP 304). An ETag is basically just a checksum for a file that semantically changes when the content of the file changes.\n\n\nThe Expires header is used by the client (and proxies/caches) to determine whether or not it even needs to make a request to the server at all. The closer you are to the Expires date, the more likely it is the client (or proxy) will make an HTTP request for that file from the server.\n\n\nSo really what you want to do is use BOTH headers - set the Expires header to a reasonable value based on how often the content changes. Then configure ETags to be sent so that when clients DO send a request to the server, it can more easily determine whether or not to send the file back.\n\n\nOne last note about ETag - if you are using a load-balanced server setup with multiple machines running Apache you will probably want to turn off ETag generation. This is because inodes are used as part of the ETag hash algorithm which will be different between the servers. You can configure Apache to not use inodes as part of the calculation but then you'd want to make sure the timestamps on the files are exactly the same, to ensure the same ETag gets generated for all servers.\n\n\n\n\nHow to set Expiration Caching Headers\n\n\n\n\nExpiration caching is based on the \nCache-Control\n and \nExpires\n headers. These headers instruct clients and caches to keep a copy of the representation returned by the server for a specific length of time.\n\n\nBased on the frequency of updates, determine a time period (the \nfreshness lifetime\n) during which caches can serve a representation. After this time, caches will consider cached representations stale.\n\n\nWhen serving a representation, include a \nCache-Control\n header with a \nmax-age\n value (in seconds) equal to the freshness lifetime. The \nCache-Control\n header is a HTTP 1.1 header. To support legacy HTTP 1.0 caches, include a \nExpires\n header with the expiration date-time. The expiration date-time is a time at which the server generated the representation plus the freshness lifetime. Also include a \nDate\n header with a date-time at which the server returned the response. Including this header helps clients compute the freshness lifetime as the difference between the values of the \nExpires\n and \nDate\n headers.\n\n\nIf the caches must not serve cached copies, add \nCache-Control: no-cache\n to the HTTP headers. Also add a \nPragma: no-cache\n to support HTTP 1.0 caches.\n\n\nList of \nCache-Control\n directives:\n\n\n\n\npublic\n (default): when the request is authenticated, but you still want to allow shared caches to serve cached responses.\n\n\nprivate\n: when the response is preivate to the client or user. Any client-side caches (browsers/forward proxies) can cache the representation, but sharede caches along the network must not cache it.\n\n\nno-cache\n and \nno-store\n: prevents any cache from storing or serving a cached response.\n\n\nmax-age\n: the freshness lifetime in seconds.\n\n\ns-maxage\n: life \nmax-age\n, but is meant only for shared caches. Just use \nmax-age\n.\n\n\nmust-revalidate\n: caches must check the origin server before serving stale representations.\n\n\nproxy-revalidate\n: same as \nmust-revalidate\n but only for shared caches.\n\n\n\n\nThe \nAge\n header is added by the cache. It indicates how long ago the cache retrieved the representation from the origin server.\n\n\nThe key to optimal expiration caching is calculating a resonable freshness lifetime value for the resource representation. If you gave historical information such as update logs for the representations, use them to establish a base lifetime. \n\n\nWhen to set Expiration Caching Headers\n\n\n\n\nSet expiration caching headers for responses of \nGET\n and \nHEAD\n request for all successful response codes.\n\n\n\n\nConsider adding caching headers to:\n\n\n\n\n300 Multiple Choices\n: The representation with this status may not change often.\n\n\n301 Moved Permanently\n\n\n404 Not Found\n\n\n405 Method Not Allowed\n\n\n410 Gone\n\n\n\n\n\n\n\n\nWhen and how to use Expiration Headers in Clients\n\n\n\n\n\n\nAvoid implementing support for expiration caching within clients, instead deploy a forward proxy in the client network, and avoid implementing you own caching layer in the client code.\n\n\nConditional Request\n\n\nConditional request address two programs. For \nGET\n request conditional request help clients and caches validate that a cached representation can still be considered fresh. For unsafe request such as \nPUT\n, \nPOST\n and \nDELETE\n conditional requests provide concurrency control.\n\n\nNot supporting conditional \nGET\n request reduces performance.\n\n\nNot makeing unsafe requests conditional, when facing concurrency, ay affect the integrity of the application. In absence of adequate concurrency control checks, the server is susceptible to \"lost updates\" and \"stale deletes\".\n\n\nPerssimistic concurrency control, the client gets a lock, obtain the current state of a resource, makes modifications, and then releases the lock. During this process the server present other clients from aquiring a lock to the same resource.\n\n\nOptimistic concurrency control, the client gets a token, and attempts a write operation with the token. The operation success if the token is still valid or fails otherwise.\n\n\nHTTP, being stateless, is designed for optimistic concurrency control.\n\n\nConditional \nGET\n request can extend the life of stale representations.\n\n\n\n\nHow to Generate \nLast-Modified\n and \nETag\n Headers\n\n\n\n\nUse \nLast-Modified\n and \nETag\n response headers to drive conditional requests. Clients use the following:\n\n\n\n\nIf-Modified-Since\n and \nIf-None-Match\n for validating cached representations\n\n\nIf-Unmodified-Since\n and \nIf-Match\n as preconditions for concurrency control\n\n\n\n\na timestamp for the modifed date-time and/or a sequence number of keep track of a version.\n\n\nuse an MD5 hash of the representation body, or of some field of the data that changes every time the resource ip updated\n\n\nmake sure to use a different \nETag\n value of each representation of the resource (this include different media types, etc.).\n\n\nLast-Modified\n has a 1 second resolution is considered a \"weak\" validator.\n\nETag\n is a strong validator since its value can change every time the entity is modified.\nEntity tag is an object hash code\n\n\nYou do not need to use both \nLast-Modified\n and \nETag\n headers to support conditional requests. Use either or both consistently to support conditional requests.\n\n\n\n\nHow to Implement Conditional \nGET\n Requests in Servers\n\n\n\n\nSend \nIf-Modified-Since\n and \nIf-None-Match\n headers based \nLast-Modified\n and \nETag\n headers from a previous request.\n\n\nConditional requests do not cut down on the number of requests from the client, but they can reduce the number of times a server needs to send a fresh representation.\n\n\nCheck \nIf-None-Match\n against \nETag\n, and check \nIf-Modified-Since\n against \nLast-Modified\n, if either checks are false or missing return the latest copy of the representation including new \nETag\n and/or \nLast-Modified\n, else return \n304 Not Modified\n. To support validation to extend the life of a cached copy the server must return expiration headers as well.\n\n\nThe values of \nETag\n, \nIf-Match\n, and \nIf-None-Match\n are quoted strings.\n\n\n\n\nHow to Submit Conditional \nGET\n and \nHEAD\n Requests from Clients\n\n\n\n\nStore \nETag\n and/or \nLast-Modified\n along with the representation data.\nand reply them on future requests.\n\n\nInclude \nIf-Modified-Since\n with the value from \nLast-Modified\n\nInclude \nIf-None-Match\n with the value from \nETag\n\n\nDo not send conditional requests unless you have a copy of the representaton stored locally on the client.\n\n\n\n\nHow to Implement Conditional \nPUT\n Requests in Servers\n\n\n\n\nIf the resource exists:\n\n\n\n\nIf the client does not include \nIf-Unmodified-Since\n and/or \nIf-Match\n header return \n403 Forbidden\n. Explain why in the body.\n\n\nIf the suppiled \nIf-Unmodified-Since\n or \nIf-Match\n do not match the server values return \n412 Precondition Failed\n. Explain why in the body.\n\n\n\n\nIf the conditions match return \n200 OK\n or \n204 No Content\n and update the resource. Optionally include \nLast-Modified\n and/or \nETag\n headers provided the response also include a \nContent-Location\n header with the URI of the updated resource.\n\n\n\n\n\n\nHow to Implement Conditional \nDELETE\n Requests in Servers\n\n\n\n\n\n\nIf the client does not include \nIf-Unmodified-Since\n and/or \nIf-Match\n header return \n403 Forbidden\n. Explain why in the body.\n\n\n\n\nIf the suppiled \nIf-Unmodified-Since\n or \nIf-Match\n do not match the server values return \n412 Precondition Failed\n. Explain why in the body.\n\n\n\n\nIf the conditions match return \n200 OK\n or \n204 No Content\n and delete the resource.\n\n\n\n\n\n\nHow to Make Unconditional \nGET\n Requests from Clients\n\n\n\n\n\n\nHTTP 1.1 allows clients to modify expiration caching and ash for fresh representations. To get a fresh represention after you receive \n412 Precondition Failed\n or even after a successful \nPUT\n or \nPATCH\n to get the latest representation.\n\n\nInclude \nCache-Control: no-cache\n and \nPragma: no-cache\n in the \nGET\n request.\n\n\nDo not make unconditional \nGET\n request unless necessary as the downgrade performacne and increase latency.\n\n\n\n\nHow to Submit Conditional \nPUT\n and \nDELETE\n Requests from Clients\n\n\n\n\nInclude \nIf-Unmodified-Since\n with the stored value of \nLast-Modified\n\nInclude \nIf-Match\n with the stored value of \nETag\n\nIf the server return \n412 Precondition Failed\n submit an unconditional request to ontain a fresh \nLast-Modified\n and \nETag\n, verify the decision to update or delete the resource is still valid per the fresh representation, and then repeat the \nPUT\n or \nDELETE\n with the new header values.\n\n\nDo not use \nHEAD\n to obtain fresh \nLast-Modified\n and \nETag\n you will also new the current satet of the resource to determine if you can go ahead with the operation.\n\n\n\n\nHow to Make \nPOST\n Requests Conditional\n\n\nHow to Generate One-Time URIs\n\n\n\n\nCommon methods of ETag generation include using a collision-resistant hash function of the resource's content, a hash of the last modification timestamp, or even just a revision number.\n\n\nMAY: Consider using ETag together with If-(None-)Match header\n\n\nWhen creating or updating resources it may be necessary to expose conflicts and to prevent the lost update problem. This can be best accomplished by using the ETag header together with the If-Match and If-None-Match. The contents of an ETag: \n header is either (a) a hash of the response body, (b) a hash of the last modified field of the entity, or \n a version number or identifier of the entity version.\n\n\nTo expose conflicts between concurrent update operations via PUT, POST, or PATCH, the If-Match: \n header can be used to force the server to check whether the version of the updated entity is conforming to the requested \n. If no matching entity is found, the operation is supposed a to respond with status code 412 - precondition failed.\n\n\nBeside other use cases, the If-None-Match: header with parameter * can be used in a similar way to expose conflicts in resource creation. If any matching entity is found, the operation is supposed a to respond with status code 412 - precondition failed.\n\n\nThe ETag, If-Match, and If-None-Match headers can be defined as follows in the API definition:\n\n\n    Etag:\n        name: Etag\n        description: |\n        The RFC7232 ETag header field in a response provides the current entity-tag for the\n        selected resource. An entity-tag is an opaque identifier for different versions of\n        a resource over time, regardless whether multiple versions are valid at the same time.\n        An entity-tag consists of an opaque quoted string, possibly prefixed by a weakness\n        indicator.\n\n        in: header\n        type: string\n        required: false\n        example: W/\nxy\n, \n5\n, \n7da7a728-f910-11e6-942a-68f728c1ba70\n\n\n    IfMatch:\n        name: If-Match\n        description: |\n        The RFC7232 If-Match header field in a request requires the server to only operate\n        on the resource that matches at least one of the provided entity-tags. This allows\n        clients express a precondition that prevent the method from being applied, if there\n        have been any changes to the resource.\n\n        in: header\n        type: string\n        required: false\n        example:  \n5\n, \n7da7a728-f910-11e6-942a-68f728c1ba70\n\n\n    IfNoneMatch:\n        name: If-None-Match\n        description: |\n        The RFC7232 If-None-Match header field in a request requires the server to only\n        operate on the resource if it does not match any of the provided entity-tags. If\n        the provided entity-tag is `*`, it is required that the resource does not exist\n        at all.\n\n        in: header\n        type: string\n        required: false\n        example: \n7da7a728-f910-11e6-942a-68f728c1ba70\n, *", 
            "title": "Caching"
        }, 
        {
            "location": "/caching/#caching-and-conditional-requests", 
            "text": "Caching is one of the most useful features built on top of HTTP's uniform interface. You can take advantage of caching to reduce end user perceived latency, to increase reliasbility, to reduce bandwidth usage and cost, and to reduce server load. They can be in server network, content delivery networks (CDNs), or in the client network (forward proxies).  It is common to use the word  cache  to refer to either an object cache (memcached) or HTTP caches. Both of these caches improve performacne and have key roles to play in the overall web service deployment architecture. But there is an important difference between the two. HTTP caches do not require clients and servers to call any special programming API to manage data in the cache, as long as you are using HTTP as defined.", 
            "title": "Caching and Conditional Requests"
        }, 
        {
            "location": "/caching/#origin-server", 
            "text": "They are slightly different - the ETag does not have any information that the client can use to determine whether or not to make a request for that file again in the future. If ETag is all it has, it will always have to make a request. However, when the server reads the ETag from the client request, the server can then determine whether to send the file (HTTP 200) or tell the client to just use their local copy (HTTP 304). An ETag is basically just a checksum for a file that semantically changes when the content of the file changes.  The Expires header is used by the client (and proxies/caches) to determine whether or not it even needs to make a request to the server at all. The closer you are to the Expires date, the more likely it is the client (or proxy) will make an HTTP request for that file from the server.  So really what you want to do is use BOTH headers - set the Expires header to a reasonable value based on how often the content changes. Then configure ETags to be sent so that when clients DO send a request to the server, it can more easily determine whether or not to send the file back.  One last note about ETag - if you are using a load-balanced server setup with multiple machines running Apache you will probably want to turn off ETag generation. This is because inodes are used as part of the ETag hash algorithm which will be different between the servers. You can configure Apache to not use inodes as part of the calculation but then you'd want to make sure the timestamps on the files are exactly the same, to ensure the same ETag gets generated for all servers.   How to set Expiration Caching Headers   Expiration caching is based on the  Cache-Control  and  Expires  headers. These headers instruct clients and caches to keep a copy of the representation returned by the server for a specific length of time.  Based on the frequency of updates, determine a time period (the  freshness lifetime ) during which caches can serve a representation. After this time, caches will consider cached representations stale.  When serving a representation, include a  Cache-Control  header with a  max-age  value (in seconds) equal to the freshness lifetime. The  Cache-Control  header is a HTTP 1.1 header. To support legacy HTTP 1.0 caches, include a  Expires  header with the expiration date-time. The expiration date-time is a time at which the server generated the representation plus the freshness lifetime. Also include a  Date  header with a date-time at which the server returned the response. Including this header helps clients compute the freshness lifetime as the difference between the values of the  Expires  and  Date  headers.  If the caches must not serve cached copies, add  Cache-Control: no-cache  to the HTTP headers. Also add a  Pragma: no-cache  to support HTTP 1.0 caches.  List of  Cache-Control  directives:   public  (default): when the request is authenticated, but you still want to allow shared caches to serve cached responses.  private : when the response is preivate to the client or user. Any client-side caches (browsers/forward proxies) can cache the representation, but sharede caches along the network must not cache it.  no-cache  and  no-store : prevents any cache from storing or serving a cached response.  max-age : the freshness lifetime in seconds.  s-maxage : life  max-age , but is meant only for shared caches. Just use  max-age .  must-revalidate : caches must check the origin server before serving stale representations.  proxy-revalidate : same as  must-revalidate  but only for shared caches.   The  Age  header is added by the cache. It indicates how long ago the cache retrieved the representation from the origin server.  The key to optimal expiration caching is calculating a resonable freshness lifetime value for the resource representation. If you gave historical information such as update logs for the representations, use them to establish a base lifetime.   When to set Expiration Caching Headers   Set expiration caching headers for responses of  GET  and  HEAD  request for all successful response codes.   Consider adding caching headers to:   300 Multiple Choices : The representation with this status may not change often.  301 Moved Permanently  404 Not Found  405 Method Not Allowed  410 Gone     When and how to use Expiration Headers in Clients    Avoid implementing support for expiration caching within clients, instead deploy a forward proxy in the client network, and avoid implementing you own caching layer in the client code.", 
            "title": "origin server"
        }, 
        {
            "location": "/caching/#conditional-request", 
            "text": "Conditional request address two programs. For  GET  request conditional request help clients and caches validate that a cached representation can still be considered fresh. For unsafe request such as  PUT ,  POST  and  DELETE  conditional requests provide concurrency control.  Not supporting conditional  GET  request reduces performance.  Not makeing unsafe requests conditional, when facing concurrency, ay affect the integrity of the application. In absence of adequate concurrency control checks, the server is susceptible to \"lost updates\" and \"stale deletes\".  Perssimistic concurrency control, the client gets a lock, obtain the current state of a resource, makes modifications, and then releases the lock. During this process the server present other clients from aquiring a lock to the same resource.  Optimistic concurrency control, the client gets a token, and attempts a write operation with the token. The operation success if the token is still valid or fails otherwise.  HTTP, being stateless, is designed for optimistic concurrency control.  Conditional  GET  request can extend the life of stale representations.   How to Generate  Last-Modified  and  ETag  Headers   Use  Last-Modified  and  ETag  response headers to drive conditional requests. Clients use the following:   If-Modified-Since  and  If-None-Match  for validating cached representations  If-Unmodified-Since  and  If-Match  as preconditions for concurrency control   a timestamp for the modifed date-time and/or a sequence number of keep track of a version.  use an MD5 hash of the representation body, or of some field of the data that changes every time the resource ip updated  make sure to use a different  ETag  value of each representation of the resource (this include different media types, etc.).  Last-Modified  has a 1 second resolution is considered a \"weak\" validator. ETag  is a strong validator since its value can change every time the entity is modified.\nEntity tag is an object hash code  You do not need to use both  Last-Modified  and  ETag  headers to support conditional requests. Use either or both consistently to support conditional requests.   How to Implement Conditional  GET  Requests in Servers   Send  If-Modified-Since  and  If-None-Match  headers based  Last-Modified  and  ETag  headers from a previous request.  Conditional requests do not cut down on the number of requests from the client, but they can reduce the number of times a server needs to send a fresh representation.  Check  If-None-Match  against  ETag , and check  If-Modified-Since  against  Last-Modified , if either checks are false or missing return the latest copy of the representation including new  ETag  and/or  Last-Modified , else return  304 Not Modified . To support validation to extend the life of a cached copy the server must return expiration headers as well.  The values of  ETag ,  If-Match , and  If-None-Match  are quoted strings.   How to Submit Conditional  GET  and  HEAD  Requests from Clients   Store  ETag  and/or  Last-Modified  along with the representation data.\nand reply them on future requests.  Include  If-Modified-Since  with the value from  Last-Modified \nInclude  If-None-Match  with the value from  ETag  Do not send conditional requests unless you have a copy of the representaton stored locally on the client.   How to Implement Conditional  PUT  Requests in Servers   If the resource exists:   If the client does not include  If-Unmodified-Since  and/or  If-Match  header return  403 Forbidden . Explain why in the body.  If the suppiled  If-Unmodified-Since  or  If-Match  do not match the server values return  412 Precondition Failed . Explain why in the body.   If the conditions match return  200 OK  or  204 No Content  and update the resource. Optionally include  Last-Modified  and/or  ETag  headers provided the response also include a  Content-Location  header with the URI of the updated resource.    How to Implement Conditional  DELETE  Requests in Servers    If the client does not include  If-Unmodified-Since  and/or  If-Match  header return  403 Forbidden . Explain why in the body.   If the suppiled  If-Unmodified-Since  or  If-Match  do not match the server values return  412 Precondition Failed . Explain why in the body.   If the conditions match return  200 OK  or  204 No Content  and delete the resource.    How to Make Unconditional  GET  Requests from Clients    HTTP 1.1 allows clients to modify expiration caching and ash for fresh representations. To get a fresh represention after you receive  412 Precondition Failed  or even after a successful  PUT  or  PATCH  to get the latest representation.  Include  Cache-Control: no-cache  and  Pragma: no-cache  in the  GET  request.  Do not make unconditional  GET  request unless necessary as the downgrade performacne and increase latency.   How to Submit Conditional  PUT  and  DELETE  Requests from Clients   Include  If-Unmodified-Since  with the stored value of  Last-Modified \nInclude  If-Match  with the stored value of  ETag \nIf the server return  412 Precondition Failed  submit an unconditional request to ontain a fresh  Last-Modified  and  ETag , verify the decision to update or delete the resource is still valid per the fresh representation, and then repeat the  PUT  or  DELETE  with the new header values.  Do not use  HEAD  to obtain fresh  Last-Modified  and  ETag  you will also new the current satet of the resource to determine if you can go ahead with the operation.   How to Make  POST  Requests Conditional  How to Generate One-Time URIs   Common methods of ETag generation include using a collision-resistant hash function of the resource's content, a hash of the last modification timestamp, or even just a revision number.", 
            "title": "Conditional Request"
        }, 
        {
            "location": "/caching/#may-consider-using-etag-together-with-if-none-match-header", 
            "text": "When creating or updating resources it may be necessary to expose conflicts and to prevent the lost update problem. This can be best accomplished by using the ETag header together with the If-Match and If-None-Match. The contents of an ETag:   header is either (a) a hash of the response body, (b) a hash of the last modified field of the entity, or   a version number or identifier of the entity version.  To expose conflicts between concurrent update operations via PUT, POST, or PATCH, the If-Match:   header can be used to force the server to check whether the version of the updated entity is conforming to the requested  . If no matching entity is found, the operation is supposed a to respond with status code 412 - precondition failed.  Beside other use cases, the If-None-Match: header with parameter * can be used in a similar way to expose conflicts in resource creation. If any matching entity is found, the operation is supposed a to respond with status code 412 - precondition failed.  The ETag, If-Match, and If-None-Match headers can be defined as follows in the API definition:      Etag:\n        name: Etag\n        description: |\n        The RFC7232 ETag header field in a response provides the current entity-tag for the\n        selected resource. An entity-tag is an opaque identifier for different versions of\n        a resource over time, regardless whether multiple versions are valid at the same time.\n        An entity-tag consists of an opaque quoted string, possibly prefixed by a weakness\n        indicator.\n\n        in: header\n        type: string\n        required: false\n        example: W/ xy ,  5 ,  7da7a728-f910-11e6-942a-68f728c1ba70 \n\n    IfMatch:\n        name: If-Match\n        description: |\n        The RFC7232 If-Match header field in a request requires the server to only operate\n        on the resource that matches at least one of the provided entity-tags. This allows\n        clients express a precondition that prevent the method from being applied, if there\n        have been any changes to the resource.\n\n        in: header\n        type: string\n        required: false\n        example:   5 ,  7da7a728-f910-11e6-942a-68f728c1ba70 \n\n    IfNoneMatch:\n        name: If-None-Match\n        description: |\n        The RFC7232 If-None-Match header field in a request requires the server to only\n        operate on the resource if it does not match any of the provided entity-tags. If\n        the provided entity-tag is `*`, it is required that the resource does not exist\n        at all.\n\n        in: header\n        type: string\n        required: false\n        example:  7da7a728-f910-11e6-942a-68f728c1ba70 , *", 
            "title": "MAY: Consider using ETag together with If-(None-)Match header"
        }, 
        {
            "location": "/clients/", 
            "text": "Resource Identifiers\n\n\nWhen using URIs in clients: \n\n\n\n\nDO\n update local copies of old URIs when receiving \n301 Moved Permanently\n.\n\n\nDO\n verify that the \nLocation\n URI maps to a trusted server.\n\n\nDO NOT\n disable support of redirects in client applications. Instead, consider a sensible limit on the number of redirects a client can follow. Disabling redirects altogether will break the client when the server change URIs.\n\n\n\n\nMethods\n\n\nWhen using methods in clients:\n\n\n\n\nDO\n treat \nGET\n, \nOPTIONS\n, and \nHEAD\n as safe operations, and send as required. Include \nIf-Unmodified-Since\n and/or \nIf-Match\n conditional headers, if applicable.\n\n\nDO\n resubmit \nGET\n, \nPUT\n, and \nDELETE\n requests, in case of failures, to confirm.\n\n\nDO\n implement retry logic, whenever you encounter a failure for an idempotent method.\n\n\nDO\n submit a \nPOST\n request with a representation of the resource to be created to the factory resource.\n\n\nDO NOT\n repeat \nPOST\n requests unless the documentation states that is idempotent.\n\n\nDO NOT\n treat various HTTP-level errors as failures (network or software) or like exceptions.\n\n\n\n\nRepresentations\n\n\nWhen using HTTP Headers in clients:\n\n\n\n\nDO\n return \n400 Bad Request\n on servers, when you receive a representation with no \nContent-Type\n. Avoid guessing the type of the representation. \nDoes it belong here?\n\n\nDO\n let your network library deal with uncompressing compressed representations (\nContent-Encoding\n)\n\n\nDO\n read and store the value of \nContent-Language\n.\n\n\nDO NOT\n use \nContent-Encoding\n in HTTP requests, unless you know out of band that the target server supports a particular encoding method.\n\n\nDO NOT\n check for the presence of the \nContent-Length\n header without first confirming the absence of \nTransfer-Encoding: chunked\n\n\n\n\nErrors\n\n\n\n\nEven though they might not be documented - they may very much occur in production!\n\n\nClients should be prepared for unexpected response codes. In case of doubt handle them like they would handle the corresponding x00 code.\n\n\nAdding new response codes (specially error responses) should be considered a compatible API evolution.\n\n\n\n\nWhen treating errors in clients:\n\n\n\n\nDO\n treat \n400 Bad Request\n by looking into the body of the error representation for hints for the root cause of the problem.\n\n\nDO\n retry the request on \n401 Unauthorized\n responses with the \nAuthorization\n header containing the credentials. If the client is user-facing, prompt the user to supply credentials. In other cases, obtain the necessary security credentials.\n\n\nDO\n clean up client stored data on \n404 Not Found\n.\n\n\nDO\n look for the \nAllow\n header for valid methods on \n405 Not Allowed\n.\n\n\nDO\n treat \n406 Not Acceptable\n. See \nContent Negotiation\n.\n\n\nDO\n treat \n409 Conflict\n by looking for the conflicts listed in the body of the representation.\n\n\nDO\n treat \n410 Gone\n the same as \n404 Not Found\n.\n\n\nDO\n treat \n412 Precondition Failed\n. See \nCaching\n.\n\n\nDO\n look for hints on valid size in the body of the error on \n413 Request Entity Too Large\n.\n\n\nDO\n see the body of the representation to learn the supported media types for the request on \n415 Unsupported Media Type\n.\n\n\nDO\n log the error, and then notify the server developers of \n500 Internal Server Error\n.\n\n\nDO\n check the response of \n503 Service Unavailable\n for a \nRetry-After\n header, avoid retrying until that period of time (back-off logic).\n\n\nDO NOT\n repeat the request on \n403 Forbidden\n.\n\n\nDO NOT\n treat HTTP errors as I/O or network exceptions. Treat them as first-class application objects.\n\n\n\n\nHypermedia\n\n\nWhen using links in clients:\n\n\n\n\nDO\n extract URIs and URI templates from links based on known link relation types. These links along with other resource data constitute the current state of the application.\n\n\nDO\n store the URIs and the relation type along with other representation data, if the application is long running.\n\n\nDO\n make flow decisions based on the presence or absence of links.\n\n\nDO\n store the knowledge of whether a representation contains a given link.\n\n\nDO\n check the documentation of the link relation to learn any associated business rules regarding authentication, permanence of the URI, methods, and media types supported, etc.\n\n\n\n\nContent Negotiation\n\n\n\n\nDO\n add an \nAccept\n header with a comma-separated list of media type preferences. If the client prefers one media type over the other, add a \nq\n parameter with each media type.\n\n\nDO\n add \n*;q=0.0\n in the \nAccept\n header to indicate to the server it cannot process anything other than the media types listed in the \nAccept\n header, if the client can process only certain formats.\n\n\nDO\n add an \nAccept-Language\n header for the preferred language of the representation.\n\n\nDO\n add an \nAccept-Charset\n header with the preferred character set, if the client can process characters of a specific character set only, if not, avoid adding this header.\n\n\n\n\nDO\n add an \nAccept-Encoding\n header listing the supported encodings, if the client is able to decompress representations compressed encoding such as \ngzip\n, \ncompress\n, or \ndeflate\n, if not, skip this header.\n\n\n\n\n\n\nDO NOT\n assume that servers support content negotiation, and be prepared to receive a representation that does not meet the \nAccept-*\n headers.\n\n\n\n\n\n\nExtensibility\n\n\nWhen implementing clients to support extensibility:\n\n\n\n\nDO\n store everything, if the client is capable of storing the complete representation locally.\n\n\nDO NOT\n assume that the representation is of a fixed media type, character encoding, content language, or content encoding.\n\n\n\n\n\n\nComplement with an SDK\n\n\nIt's a common question for API providers - do you need to complement your API with code libraries and software development kits (SDKs)?\nIf your API follows good design practices, is self consistent, standards-based, and well documented, developers may be able to get rolling without a client SDK. Well-documented code samples are also a critical resource.\nOn the other hand, what about the scenario in which building a UI requires a lot of domain knowledge? This can be a challenging problem for developers even when building UI and apps on top of APIs with pretty simple domains \u2013 think about the Twitter API with it's primary object of 140 characters of text.\nYou shouldn't change your API to try to overcome the domain knowledge hurdle. Instead, you can complement your API with code libraries and a software development kit (SDK).\nIn this way, you don't overburden your API design. Often, a lot of what's needed is on the client side and you can push that burden to an SDK.\nThe SDK can provide the platform-specific code, which developers use in their apps to invoke API operations - meaning you keep your API clean.\nOther reasons you might consider complementing your API with an SDK include the following:\nSpeed adoption on a specific platform. (For example Objective C SDK for iPhone.)\nMany experienced developers are just starting off with objective C+ so an SDK might be helpful.\nSimplify integration effort required to work with your API - If key use cases are complex or need to be complemented by standard on-client processing.\nAn SDK can help reduce bad or inefficient code that might slow down service for everyone.\nAs a developer resource - good SDKs are a forcing function to create good source code examples and documentation. \nTo market your API to a specific community - you upload the SDK to a samples or plugin page on a platform's existing developer community.\nLast but not least, keep in mind that SDKs or code wrappers/libraries can be extremely helpful.\nWhat SDKs/ Code Wrappers offer is a quick, plug and play way for developers to incorporate your API, while also (hopefully) handling error checks/ responses.\n\n\nBuilding an SDK Doesn't Fix Everything\n\n\nHowever, if you are building a full out SDK instead of a language wrapper that utilizes the hypermedia to handle responses, remember that you are adding a whole new layer of complexity to your API ecosystem \u2013 that you will have to maintain.\nThe downside is the more complex your SDK becomes, the more tightly coupled it usually is to your API, making any updates to your API a manual and complex process.\nThis means that any new features you roll out will receive rather slow adoption, and you may find yourself providing support to your developers on why they can't do something with your SDK.\nWhen building your SDK you should try to keep it as decoupled from your API as possible, relying on dynamic responses and calls while also following the best coding practices for that language (be sure to watch Keith Casey's SPOIL talk or read about it here).\n\n\nAnother option is to utilize a SDK building service such as APIMatic.io or REST United, which automatically generates SDKs for your API based on your RAML, Swagger, or API Blueprint spec.\nThis allows you to offer SDKs, automatically have them update when adding new features (although clients will still need to download the updated version), and offer them without adding any additional workload on your end.\n\n\nBut again, regardless of whether or not you provide an SDK/ Code Library, you will still want to have multiple code examples in your documentation to help developers who want to utilize your API to its fullest capacity, without relying on additional third party libraries to do so.\n\n\nRemember that having an SDK doesn't replace documentation, if anything \u2013 it creates the need for more.", 
            "title": "Clients"
        }, 
        {
            "location": "/clients/#resource-identifiers", 
            "text": "When using URIs in clients:    DO  update local copies of old URIs when receiving  301 Moved Permanently .  DO  verify that the  Location  URI maps to a trusted server.  DO NOT  disable support of redirects in client applications. Instead, consider a sensible limit on the number of redirects a client can follow. Disabling redirects altogether will break the client when the server change URIs.", 
            "title": "Resource Identifiers"
        }, 
        {
            "location": "/clients/#methods", 
            "text": "When using methods in clients:   DO  treat  GET ,  OPTIONS , and  HEAD  as safe operations, and send as required. Include  If-Unmodified-Since  and/or  If-Match  conditional headers, if applicable.  DO  resubmit  GET ,  PUT , and  DELETE  requests, in case of failures, to confirm.  DO  implement retry logic, whenever you encounter a failure for an idempotent method.  DO  submit a  POST  request with a representation of the resource to be created to the factory resource.  DO NOT  repeat  POST  requests unless the documentation states that is idempotent.  DO NOT  treat various HTTP-level errors as failures (network or software) or like exceptions.", 
            "title": "Methods"
        }, 
        {
            "location": "/clients/#representations", 
            "text": "When using HTTP Headers in clients:   DO  return  400 Bad Request  on servers, when you receive a representation with no  Content-Type . Avoid guessing the type of the representation.  Does it belong here?  DO  let your network library deal with uncompressing compressed representations ( Content-Encoding )  DO  read and store the value of  Content-Language .  DO NOT  use  Content-Encoding  in HTTP requests, unless you know out of band that the target server supports a particular encoding method.  DO NOT  check for the presence of the  Content-Length  header without first confirming the absence of  Transfer-Encoding: chunked", 
            "title": "Representations"
        }, 
        {
            "location": "/clients/#errors", 
            "text": "Even though they might not be documented - they may very much occur in production!  Clients should be prepared for unexpected response codes. In case of doubt handle them like they would handle the corresponding x00 code.  Adding new response codes (specially error responses) should be considered a compatible API evolution.   When treating errors in clients:   DO  treat  400 Bad Request  by looking into the body of the error representation for hints for the root cause of the problem.  DO  retry the request on  401 Unauthorized  responses with the  Authorization  header containing the credentials. If the client is user-facing, prompt the user to supply credentials. In other cases, obtain the necessary security credentials.  DO  clean up client stored data on  404 Not Found .  DO  look for the  Allow  header for valid methods on  405 Not Allowed .  DO  treat  406 Not Acceptable . See  Content Negotiation .  DO  treat  409 Conflict  by looking for the conflicts listed in the body of the representation.  DO  treat  410 Gone  the same as  404 Not Found .  DO  treat  412 Precondition Failed . See  Caching .  DO  look for hints on valid size in the body of the error on  413 Request Entity Too Large .  DO  see the body of the representation to learn the supported media types for the request on  415 Unsupported Media Type .  DO  log the error, and then notify the server developers of  500 Internal Server Error .  DO  check the response of  503 Service Unavailable  for a  Retry-After  header, avoid retrying until that period of time (back-off logic).  DO NOT  repeat the request on  403 Forbidden .  DO NOT  treat HTTP errors as I/O or network exceptions. Treat them as first-class application objects.", 
            "title": "Errors"
        }, 
        {
            "location": "/clients/#hypermedia", 
            "text": "When using links in clients:   DO  extract URIs and URI templates from links based on known link relation types. These links along with other resource data constitute the current state of the application.  DO  store the URIs and the relation type along with other representation data, if the application is long running.  DO  make flow decisions based on the presence or absence of links.  DO  store the knowledge of whether a representation contains a given link.  DO  check the documentation of the link relation to learn any associated business rules regarding authentication, permanence of the URI, methods, and media types supported, etc.", 
            "title": "Hypermedia"
        }, 
        {
            "location": "/clients/#content-negotiation", 
            "text": "DO  add an  Accept  header with a comma-separated list of media type preferences. If the client prefers one media type over the other, add a  q  parameter with each media type.  DO  add  *;q=0.0  in the  Accept  header to indicate to the server it cannot process anything other than the media types listed in the  Accept  header, if the client can process only certain formats.  DO  add an  Accept-Language  header for the preferred language of the representation.  DO  add an  Accept-Charset  header with the preferred character set, if the client can process characters of a specific character set only, if not, avoid adding this header.   DO  add an  Accept-Encoding  header listing the supported encodings, if the client is able to decompress representations compressed encoding such as  gzip ,  compress , or  deflate , if not, skip this header.    DO NOT  assume that servers support content negotiation, and be prepared to receive a representation that does not meet the  Accept-*  headers.", 
            "title": "Content Negotiation"
        }, 
        {
            "location": "/clients/#extensibility", 
            "text": "When implementing clients to support extensibility:   DO  store everything, if the client is capable of storing the complete representation locally.  DO NOT  assume that the representation is of a fixed media type, character encoding, content language, or content encoding.", 
            "title": "Extensibility"
        }, 
        {
            "location": "/clients/#complement-with-an-sdk", 
            "text": "It's a common question for API providers - do you need to complement your API with code libraries and software development kits (SDKs)?\nIf your API follows good design practices, is self consistent, standards-based, and well documented, developers may be able to get rolling without a client SDK. Well-documented code samples are also a critical resource.\nOn the other hand, what about the scenario in which building a UI requires a lot of domain knowledge? This can be a challenging problem for developers even when building UI and apps on top of APIs with pretty simple domains \u2013 think about the Twitter API with it's primary object of 140 characters of text.\nYou shouldn't change your API to try to overcome the domain knowledge hurdle. Instead, you can complement your API with code libraries and a software development kit (SDK).\nIn this way, you don't overburden your API design. Often, a lot of what's needed is on the client side and you can push that burden to an SDK.\nThe SDK can provide the platform-specific code, which developers use in their apps to invoke API operations - meaning you keep your API clean.\nOther reasons you might consider complementing your API with an SDK include the following:\nSpeed adoption on a specific platform. (For example Objective C SDK for iPhone.)\nMany experienced developers are just starting off with objective C+ so an SDK might be helpful.\nSimplify integration effort required to work with your API - If key use cases are complex or need to be complemented by standard on-client processing.\nAn SDK can help reduce bad or inefficient code that might slow down service for everyone.\nAs a developer resource - good SDKs are a forcing function to create good source code examples and documentation. \nTo market your API to a specific community - you upload the SDK to a samples or plugin page on a platform's existing developer community.\nLast but not least, keep in mind that SDKs or code wrappers/libraries can be extremely helpful.\nWhat SDKs/ Code Wrappers offer is a quick, plug and play way for developers to incorporate your API, while also (hopefully) handling error checks/ responses.", 
            "title": "Complement with an SDK"
        }, 
        {
            "location": "/clients/#building-an-sdk-doesnt-fix-everything", 
            "text": "However, if you are building a full out SDK instead of a language wrapper that utilizes the hypermedia to handle responses, remember that you are adding a whole new layer of complexity to your API ecosystem \u2013 that you will have to maintain.\nThe downside is the more complex your SDK becomes, the more tightly coupled it usually is to your API, making any updates to your API a manual and complex process.\nThis means that any new features you roll out will receive rather slow adoption, and you may find yourself providing support to your developers on why they can't do something with your SDK.\nWhen building your SDK you should try to keep it as decoupled from your API as possible, relying on dynamic responses and calls while also following the best coding practices for that language (be sure to watch Keith Casey's SPOIL talk or read about it here).  Another option is to utilize a SDK building service such as APIMatic.io or REST United, which automatically generates SDKs for your API based on your RAML, Swagger, or API Blueprint spec.\nThis allows you to offer SDKs, automatically have them update when adding new features (although clients will still need to download the updated version), and offer them without adding any additional workload on your end.  But again, regardless of whether or not you provide an SDK/ Code Library, you will still want to have multiple code examples in your documentation to help developers who want to utilize your API to its fullest capacity, without relying on additional third party libraries to do so.  Remember that having an SDK doesn't replace documentation, if anything \u2013 it creates the need for more.", 
            "title": "Building an SDK Doesn't Fix Everything"
        }, 
        {
            "location": "/content-negotiation/", 
            "text": "Content Negotiation (conneg)\n\n\nThere are two types of content negotiation:\n\n\n\n\nServer-driven\n negotiation, uses request HTTP headers to select a variant.\n\n\nAgent-driven\n negotiation, uses a distinct URI for each variant.\n\n\n\n\nServer-Driven Negotiation\n\n\n\n\nDO\n support multiple variants only when your clients need them.\n\n\nDO\n support multiple variants only when each variant contains the same information.\n\n\nDO NOT\n use server-driven negotiation when the information content is different, use \nAgent-Driven Content Negotiation\n instead.\n\n\n\n\n\n\nIndicating Client Preferences\n\n\nIt is important for the client to indicate its preferences and capabilities to the server, including:\n\n\n\n\nrepresentation formats\n\n\nlanguages\n\n\ncharacter encoding\n\n\nsupport for compression.\n\n\n\n\nEven if you know this information out of band, clearly indicating the client's preferences and capabilities can help in the face of change. It is better to ask for a specific representation instead of getting a default one, because the default can change.\n\n\n\n\nContent Type Negotiation\n\n\ncontent negotiation (include or exclude and force to e.g. json)?\n\n\n\n\nDO\n return a representation using the default format, if the request has no \nAccept\n header.\n\n\nDO\n parse the \nAccept\n header, sort the values of media types by the \nq\n parameters in descending order, if the request has an \nAccept\n header, then select a media type from the list that the server supports.\n\n\nDO\n return a representation using the default format, if the server does not support any format in the list, and the \nAccept\n header does not contain \n*;q=0.0\n.\nIs this correct for the Content-Type HTTP header?\n\n\nDO\n handle \ncontent negotiation failures\n to determine an appropriate response.\n\n\nCONSIDER\n including a \nVary\n (see \nVary\n) response header.\n\n\nCONSIDER\n using \nagent-driven negotiation\n, if the server starts out ignoring \nAccept\n, and, for example, returns \nContent-Type: application/xml\n for \nAccept: application/json\n requests. Later on , adding content negotiation (\nContent-Type: application/json\n) will likely break compatibility for working clients.\n\n\n\n\nLanguage Negotiation\n\n\n\n\nDO\n return a representation with all human-readable text in a default language, if the request has no \nAccept-Language\n header.\n\n\nDO\n parse the \nAccept-Language\n header, sort the languages by the \nq\n parameters in descending order, and select the first language in the list that the server can support, if the request has an \nAccept-Language\n header\n\n\nDO\n use a default language for the response, if the server does not support any languages in the list, and the \nAccept-Language\n header does not contain \n*;q=0.0\n.\n\n\nCONSIDER\n including a \nVary\n (see \nThe Vary Header\n) response header.\n\n\n\n\n\n\nTip\n\n\nThis approach is best suited when representations in different languages differ only in terms of the language used for any human-readable text. If the differences between representations are more significant, use other means of localization such as the client's IP address or region/language-specific URIs.\n\n\n\n\nCharacter Encoding Negotiation\n\n\n\n\nDO\n encode the textual representation of the response using the encoding the client ask for via the \nAccept-Charset\n header. Encoding the response using that encoding promotes interoperability.\n\n\nDO\n parse the header, sort the character set by the \nq\n parameters in descending order, and select the first character set that the server can support for encoding.\n\n\nDO\n return a representation using \nUTF-8\n encoding, if the request has no \nAccept-Charset\n header.\n\n\nDO\n return a representation using \nUTF-8\n encoding, if the server does not support any requested character set and the \nAccept-Charset\n header does not contain \n*;q=0.0\n.\n\n\nDO\n include the \ncharset\n parameter in the \nContent-Type\n header, in all cases, if the media type is textual and allows a \ncharset\n parameter.\n\n\nCONSIDER\n including a \nVary\n (see \nThe Vary Header\n) response header.\n\n\nAVOID\n using \ntext/xml\n since its default encoidng is \nus-ascii\n.\n\n\n\n\nSupporting Compression\n\n\nTo support compression or \ncontent encoding\n:\n\n\n\n\nDO\n use the compression technique from the \nAccept-Encoding\n header, if the server is capable of compressing the response body.\n\n\nDO\n parse the header, sort the character set by the \nq\n parameters in descending order, and select the first content encoding the server supports.\n\n\nDO\n ignore this header, if no encoding in this header matches the server's supported encodings.\n\n\nCONSIDER\n including a \nVary\n (see \nThe Vary Header\n) response header.\n\n\nCONSIDER\n brotli (\nbr\n).\n\n\nDO NOT\n compress representations, if the request has no \nAccept-Encoding\n header.\n\n\n\n\nThe \nVary\n Header\n\n\nWhen a server uses content negotiation to select a representation, the same URI can yield different representations based on \nAccept-*\n headers. The \nVary\n header tells clients which request headers the server used when selecting a representation. Caches may use the \nVary\n header as part of cache keys to maintain variants of a resource.\n\n\n\n\nCONSIDER\n including a \nVary\n header whenever multiple representations are available for a resource. The value of this header is a comma-separated list of \nrequest headers\n the server used when choosing representation.\n\n\nCONSIDER\n including a \nVary\n header with a value of \n*\n, if the server uses information other than the headers in the request, such as a client's IP address, time of day, user personalization, etc.\n\n\n\n\nNegotiation Failures\n\n\n\n\nDO\n return \n406 Not Acceptable\n with either the body of the representation containing the list of representations, or a \nLink\n in the header, when the server cannot serve a representation that meets the client's preferences and if the client explicitly included a \n*;q=0.0\n.\n\n\nDO\n serve the representation without applying any content encoding, if the server is unable to support the requested \nAccept-Encoding\n value.\n\n\n\n\n\n\nWarning\n\n\nServers are free to serve any available representation for a given resource. However, clients may not be able to handle arbitrary media types.\n\n\n\n\nAgent-Driven Content Negotiation\n\n\nAlthough server-driven content negotiation is built into HTTP it does not include elements such as currency units, distance units, date formats, and other regional flavors for any human-readable text in representations.\n\n\nIn some cases, because of complex localization requirements, the server may decide to maintain different resources for different locales.\n\n\n\n\nInfo\n\n\nAgent-driven negotiation simply mean providing distinct URIs for each variant and allow the client to use that URI to select the desired representation.\n\n\n\n\n\n\nDO\n use out-of-band information from the server to determine which URI to use. If the representation exists, the server returns it, if not, it return \n404 Not Found\n.\n\n\nCONSIDER\n using agent-driven negotiation, when the client cannot communicate its preferences using \nAccept-*\n headers, using one or more of these common approaches:\n\n\nQuery parameters, like \nhttps://www.example.org/status?format={format}\n\n\nURI extensions, appending a dot (\n.\n) and a shorthand media type to the base URI. Like \nhttps://www.example.org/status.json\n\n\nSubdomains, like \nhttps://dk.example.org/status\n\n\n\n\n\n\nCONSIDER\n letting the server advertise alternatives using links with the \nalternate\n link relation type.\n\n\n\n\nAlthough it is possible to implement agent-driven negotiation for all \nAccept-*\n headers, in practice it is most commonly used for media types and languages.", 
            "title": "Content Negotiation (conneg)"
        }, 
        {
            "location": "/content-negotiation/#content-negotiation-conneg", 
            "text": "There are two types of content negotiation:   Server-driven  negotiation, uses request HTTP headers to select a variant.  Agent-driven  negotiation, uses a distinct URI for each variant.", 
            "title": "Content Negotiation (conneg)"
        }, 
        {
            "location": "/content-negotiation/#server-driven-negotiation", 
            "text": "DO  support multiple variants only when your clients need them.  DO  support multiple variants only when each variant contains the same information.  DO NOT  use server-driven negotiation when the information content is different, use  Agent-Driven Content Negotiation  instead.    Indicating Client Preferences  It is important for the client to indicate its preferences and capabilities to the server, including:   representation formats  languages  character encoding  support for compression.   Even if you know this information out of band, clearly indicating the client's preferences and capabilities can help in the face of change. It is better to ask for a specific representation instead of getting a default one, because the default can change.", 
            "title": "Server-Driven Negotiation"
        }, 
        {
            "location": "/content-negotiation/#content-type-negotiation", 
            "text": "content negotiation (include or exclude and force to e.g. json)?   DO  return a representation using the default format, if the request has no  Accept  header.  DO  parse the  Accept  header, sort the values of media types by the  q  parameters in descending order, if the request has an  Accept  header, then select a media type from the list that the server supports.  DO  return a representation using the default format, if the server does not support any format in the list, and the  Accept  header does not contain  *;q=0.0 . Is this correct for the Content-Type HTTP header?  DO  handle  content negotiation failures  to determine an appropriate response.  CONSIDER  including a  Vary  (see  Vary ) response header.  CONSIDER  using  agent-driven negotiation , if the server starts out ignoring  Accept , and, for example, returns  Content-Type: application/xml  for  Accept: application/json  requests. Later on , adding content negotiation ( Content-Type: application/json ) will likely break compatibility for working clients.", 
            "title": "Content Type Negotiation"
        }, 
        {
            "location": "/content-negotiation/#language-negotiation", 
            "text": "DO  return a representation with all human-readable text in a default language, if the request has no  Accept-Language  header.  DO  parse the  Accept-Language  header, sort the languages by the  q  parameters in descending order, and select the first language in the list that the server can support, if the request has an  Accept-Language  header  DO  use a default language for the response, if the server does not support any languages in the list, and the  Accept-Language  header does not contain  *;q=0.0 .  CONSIDER  including a  Vary  (see  The Vary Header ) response header.    Tip  This approach is best suited when representations in different languages differ only in terms of the language used for any human-readable text. If the differences between representations are more significant, use other means of localization such as the client's IP address or region/language-specific URIs.", 
            "title": "Language Negotiation"
        }, 
        {
            "location": "/content-negotiation/#character-encoding-negotiation", 
            "text": "DO  encode the textual representation of the response using the encoding the client ask for via the  Accept-Charset  header. Encoding the response using that encoding promotes interoperability.  DO  parse the header, sort the character set by the  q  parameters in descending order, and select the first character set that the server can support for encoding.  DO  return a representation using  UTF-8  encoding, if the request has no  Accept-Charset  header.  DO  return a representation using  UTF-8  encoding, if the server does not support any requested character set and the  Accept-Charset  header does not contain  *;q=0.0 .  DO  include the  charset  parameter in the  Content-Type  header, in all cases, if the media type is textual and allows a  charset  parameter.  CONSIDER  including a  Vary  (see  The Vary Header ) response header.  AVOID  using  text/xml  since its default encoidng is  us-ascii .", 
            "title": "Character Encoding Negotiation"
        }, 
        {
            "location": "/content-negotiation/#supporting-compression", 
            "text": "To support compression or  content encoding :   DO  use the compression technique from the  Accept-Encoding  header, if the server is capable of compressing the response body.  DO  parse the header, sort the character set by the  q  parameters in descending order, and select the first content encoding the server supports.  DO  ignore this header, if no encoding in this header matches the server's supported encodings.  CONSIDER  including a  Vary  (see  The Vary Header ) response header.  CONSIDER  brotli ( br ).  DO NOT  compress representations, if the request has no  Accept-Encoding  header.", 
            "title": "Supporting Compression"
        }, 
        {
            "location": "/content-negotiation/#the-vary-header", 
            "text": "When a server uses content negotiation to select a representation, the same URI can yield different representations based on  Accept-*  headers. The  Vary  header tells clients which request headers the server used when selecting a representation. Caches may use the  Vary  header as part of cache keys to maintain variants of a resource.   CONSIDER  including a  Vary  header whenever multiple representations are available for a resource. The value of this header is a comma-separated list of  request headers  the server used when choosing representation.  CONSIDER  including a  Vary  header with a value of  * , if the server uses information other than the headers in the request, such as a client's IP address, time of day, user personalization, etc.", 
            "title": "The Vary Header"
        }, 
        {
            "location": "/content-negotiation/#negotiation-failures", 
            "text": "DO  return  406 Not Acceptable  with either the body of the representation containing the list of representations, or a  Link  in the header, when the server cannot serve a representation that meets the client's preferences and if the client explicitly included a  *;q=0.0 .  DO  serve the representation without applying any content encoding, if the server is unable to support the requested  Accept-Encoding  value.    Warning  Servers are free to serve any available representation for a given resource. However, clients may not be able to handle arbitrary media types.", 
            "title": "Negotiation Failures"
        }, 
        {
            "location": "/content-negotiation/#agent-driven-content-negotiation", 
            "text": "Although server-driven content negotiation is built into HTTP it does not include elements such as currency units, distance units, date formats, and other regional flavors for any human-readable text in representations.  In some cases, because of complex localization requirements, the server may decide to maintain different resources for different locales.   Info  Agent-driven negotiation simply mean providing distinct URIs for each variant and allow the client to use that URI to select the desired representation.    DO  use out-of-band information from the server to determine which URI to use. If the representation exists, the server returns it, if not, it return  404 Not Found .  CONSIDER  using agent-driven negotiation, when the client cannot communicate its preferences using  Accept-*  headers, using one or more of these common approaches:  Query parameters, like  https://www.example.org/status?format={format}  URI extensions, appending a dot ( . ) and a shorthand media type to the base URI. Like  https://www.example.org/status.json  Subdomains, like  https://dk.example.org/status    CONSIDER  letting the server advertise alternatives using links with the  alternate  link relation type.   Although it is possible to implement agent-driven negotiation for all  Accept-*  headers, in practice it is most commonly used for media types and languages.", 
            "title": "Agent-Driven Content Negotiation"
        }, 
        {
            "location": "/documentation-and-discovery/", 
            "text": "Documentation and Discovery\n\n\nERRORS\n\n\nService providers should differentiate between technical and functional errors.\n\n\nIn most cases it's not useful to document technical errors that are not in control of the service provider unless the status code convey application-specific semantics.\n\n\nFunctional errors on the other hand, that convey domain-specific semantics, must be documented and are strongly encouraged to be expressed with Problem types.\n\n\nSHOULD:: Provide User Manual Documentation\n\n\nIn addition to the API as OpenAPI Reference Definition, it's good practice to provide an API User Manual documentation to improve client developer experience, especially of engineers that are less experienced in using this API. A helpful API User Manual typically describes the following API aspects:\n\n\n\n\nAPI's scope, purpose and use cases\n\n\nconcrete examples of API usage\n\n\nedge cases, error situation details and repair hints\n\n\narchitecture context and major dependencies - including figures and sequence flows\n\n\n\n\nhow to document api\u2019s\n\n\n\n\nswagger\n\n\nfor internal developers (readme.md in the repo)\n\n\n\n\nAPI documentation (\nhttps://apihandyman.io/the-data-the-hypermedia-and-the-documentation/\n)\n\n\n\n\nMachine readable documentation\n\n\nRAML, Swagger and Blueprint.\n\n\nNone of them, for now, handles hypermedia APIs definition.\n\n\nALPS\n\n\n\n\n\n\nHuman readable documentation\n\n\n\n\nDocumentation: \nhttps://blog.smartbear.com/documentation/the-utopia-of-api-documentation/\n\n\nFor some more or less agreed-upon qualities of good API documentation. It must be:\n\n\n\n\nadapted for audience \u2014 like all good marketing and customer support, perhaps multiple documentation depending on the audience\u2019s needs\n\n\nDX-first \u2014 made for humans, by humans\n\n\nmachine-readable\n\n\nGoogle-readable \u2014 search engine optimization matters when most people are typing \u201cX API\u201d into Google\n\n\nwell-organized like a reference guide or table of contents\n\n\nentwined with the API itself \u2014 dual-screens or opening in new window, allowing users to try something out right away\n\n\nnot a burden to create\n\n\nwith pricing and usage policies\n\n\nwith contact information\n\n\nadapted to the learner or user\n\n\nriddled with use cases and code examples\n\n\nmade up of everything you could need to use the API\n\n\npaired with a story \u2014 why you are doing this to achieve that\n\n\neasy to produce, publish and maintain\n\n\nadapted to what kind of software is being documented, like SaaS versus platform\n\n\nadapted to audience to the people that will use it \u2014 end user versus inside your company\n\n\nadapted to context \u2014 when in the discovery process and how people will use it\n\n\nequipped with some sort of way to collect user feedback on how you can further improve it\n\n\neasily found, whether within the developer portal or prominently placed on your website\n\n\n\n\n\n\n\u201cIf all your APIs are true REST APIs and you always them design them the same way, you lessen the need for documentation. If you write documentation using command and shared structures, templates, and common and shared vocabulary and concepts, they become easier to write, read, understand.\u201d\n\n\nDocumentation and its subjects are analyzed to check that they are consistent with each other. For example, if you have an API descriptor, the system checks that the API is conforming to that descriptor. This already exists with ReadyAPI from SmartBear. You can take an API descriptor in Swagger, and ReadyAPI will create the basic testing to check that the implementation for the API is correct compared to the API descriptor,\u201d\n\n\nremember that Swagger isn\u2019t the final piece of the puzzle. It\u2019ll get down your specs and build the perimeter of your API, but Swagger alone does not make complete API documentation. While formats like Swagger and RAML can automate the raw specification, you can also try a tool like LucyBot, to make Swagger more human-readable.\n\n\n\n\n\n\nAn API is only as good as its documentation.\n\n\nThe docs should be easy to find and publically accessible.\n\n\nWhen the docs are hidden inside a PDF file or require signing in, they're not only difficult to find but also not easy to search.\nThe docs should show examples of complete request/response cycles. (Pastable examples)\n\n\nThe documentation must include any deprecation schedules and details surrounding externally visible API updates. Updates should be delivered via a blog (i.e. a changelog) or a mailing list (preferably both!).\n\n\n\n\nWhen building RESTful web services, you need to address two kinds of discoverability. These are design-time dicoverability and runtime discoverability.\nDesign-time discoverability helps others design and build clients. It describes all the essentials that client developer teams and administrators need to know in order to build and launch clients.\nRuntime discoverability helps maintain loose coupling between clients and severs and enables plung-and-play style automation. Runtime discovery invlolves HTTP's uniforma interface, mean types, links, and link relations. This chapter is about design-time discoverability.\n\n\nDesign-time dicoverability simply mean describing you web service in prose, whether such prove is generated by some tools or created manually by the designers or developers of the web service. Client developers can consult this prose to understand the \"semantics\" of the resources, media types, link relations, and so on, and implement clients.\n\n\nThe best way to promote design- and development-time dicoverability is to unambiguously document the information needed to implement clients.\n\n\nFully describe the following in human-readable documentation:\n\n\n\n\nAll resources and methods supported for each resource.\n\n\nMedia types and representation formats for resources in requests and responses.\n\n\nEach link relation used, its business significance, HTTP method to be used, and resource that the link identifies.\n\n\nAll fixed URIs that are not supported via links.\n\n\nQuery parameters used for all fixed URIs.\n\n\nURI templates and token substitution rules.\n\n\nAuthenticaton and security credentials for accessing resources.\n\n\n\n\nFor XML representations, if your clients and servers are capable of supporting XML schemas, use a schema language as a \"convention\" to describe the structure of XML documents used for representation un requests and responses. For other formats, use conventions to describe representations in prose.\n\n\nNo machine-readable description can replace human-readable documentation. Documenting your web service in human-readble format such as HTML is the most useful way to enable design-time dicovery. When documenting your service, include all the information necessary to implement a client.", 
            "title": "Documentation and discovery"
        }, 
        {
            "location": "/documentation-and-discovery/#documentation-and-discovery", 
            "text": "", 
            "title": "Documentation and Discovery"
        }, 
        {
            "location": "/documentation-and-discovery/#errors", 
            "text": "Service providers should differentiate between technical and functional errors.  In most cases it's not useful to document technical errors that are not in control of the service provider unless the status code convey application-specific semantics.  Functional errors on the other hand, that convey domain-specific semantics, must be documented and are strongly encouraged to be expressed with Problem types.", 
            "title": "ERRORS"
        }, 
        {
            "location": "/documentation-and-discovery/#should-provide-user-manual-documentation", 
            "text": "In addition to the API as OpenAPI Reference Definition, it's good practice to provide an API User Manual documentation to improve client developer experience, especially of engineers that are less experienced in using this API. A helpful API User Manual typically describes the following API aspects:   API's scope, purpose and use cases  concrete examples of API usage  edge cases, error situation details and repair hints  architecture context and major dependencies - including figures and sequence flows   how to document api\u2019s   swagger  for internal developers (readme.md in the repo)   API documentation ( https://apihandyman.io/the-data-the-hypermedia-and-the-documentation/ )   Machine readable documentation  RAML, Swagger and Blueprint.  None of them, for now, handles hypermedia APIs definition.  ALPS    Human readable documentation   Documentation:  https://blog.smartbear.com/documentation/the-utopia-of-api-documentation/  For some more or less agreed-upon qualities of good API documentation. It must be:   adapted for audience \u2014 like all good marketing and customer support, perhaps multiple documentation depending on the audience\u2019s needs  DX-first \u2014 made for humans, by humans  machine-readable  Google-readable \u2014 search engine optimization matters when most people are typing \u201cX API\u201d into Google  well-organized like a reference guide or table of contents  entwined with the API itself \u2014 dual-screens or opening in new window, allowing users to try something out right away  not a burden to create  with pricing and usage policies  with contact information  adapted to the learner or user  riddled with use cases and code examples  made up of everything you could need to use the API  paired with a story \u2014 why you are doing this to achieve that  easy to produce, publish and maintain  adapted to what kind of software is being documented, like SaaS versus platform  adapted to audience to the people that will use it \u2014 end user versus inside your company  adapted to context \u2014 when in the discovery process and how people will use it  equipped with some sort of way to collect user feedback on how you can further improve it  easily found, whether within the developer portal or prominently placed on your website    \u201cIf all your APIs are true REST APIs and you always them design them the same way, you lessen the need for documentation. If you write documentation using command and shared structures, templates, and common and shared vocabulary and concepts, they become easier to write, read, understand.\u201d  Documentation and its subjects are analyzed to check that they are consistent with each other. For example, if you have an API descriptor, the system checks that the API is conforming to that descriptor. This already exists with ReadyAPI from SmartBear. You can take an API descriptor in Swagger, and ReadyAPI will create the basic testing to check that the implementation for the API is correct compared to the API descriptor,\u201d  remember that Swagger isn\u2019t the final piece of the puzzle. It\u2019ll get down your specs and build the perimeter of your API, but Swagger alone does not make complete API documentation. While formats like Swagger and RAML can automate the raw specification, you can also try a tool like LucyBot, to make Swagger more human-readable.    An API is only as good as its documentation.  The docs should be easy to find and publically accessible.  When the docs are hidden inside a PDF file or require signing in, they're not only difficult to find but also not easy to search.\nThe docs should show examples of complete request/response cycles. (Pastable examples)  The documentation must include any deprecation schedules and details surrounding externally visible API updates. Updates should be delivered via a blog (i.e. a changelog) or a mailing list (preferably both!).   When building RESTful web services, you need to address two kinds of discoverability. These are design-time dicoverability and runtime discoverability.\nDesign-time discoverability helps others design and build clients. It describes all the essentials that client developer teams and administrators need to know in order to build and launch clients.\nRuntime discoverability helps maintain loose coupling between clients and severs and enables plung-and-play style automation. Runtime discovery invlolves HTTP's uniforma interface, mean types, links, and link relations. This chapter is about design-time discoverability.  Design-time dicoverability simply mean describing you web service in prose, whether such prove is generated by some tools or created manually by the designers or developers of the web service. Client developers can consult this prose to understand the \"semantics\" of the resources, media types, link relations, and so on, and implement clients.  The best way to promote design- and development-time dicoverability is to unambiguously document the information needed to implement clients.  Fully describe the following in human-readable documentation:   All resources and methods supported for each resource.  Media types and representation formats for resources in requests and responses.  Each link relation used, its business significance, HTTP method to be used, and resource that the link identifies.  All fixed URIs that are not supported via links.  Query parameters used for all fixed URIs.  URI templates and token substitution rules.  Authenticaton and security credentials for accessing resources.   For XML representations, if your clients and servers are capable of supporting XML schemas, use a schema language as a \"convention\" to describe the structure of XML documents used for representation un requests and responses. For other formats, use conventions to describe representations in prose.  No machine-readable description can replace human-readable documentation. Documenting your web service in human-readble format such as HTML is the most useful way to enable design-time dicovery. When documenting your service, include all the information necessary to implement a client.", 
            "title": "SHOULD:: Provide User Manual Documentation"
        }, 
        {
            "location": "/examples/", 
            "text": "Examples\n\n\n\n\nHere is some \nincorrect\n Markdown.  I am adding this\n here\n.  Here is some more \ntext\n that I am removing\ntext.  And here is even more \ntext that I \n am \nadding.\n  \nParagraph was deleted and replaced with some spaces.\n  \n\n\n\n\nSpaces were removed and a paragraph was added.\n\n\nAnd here is a comment on \nsome\n text\nThis works quite well. I just wanted to comment on it.\n. Substitutions \nis\nare\n great!\n\n\nGeneral block handling.\n\n\n\n\n\n\ntest remove\n\n\ntest remove\n\n\ntest remove\n\n\ntest remove\n\n\n\n\n\n\ntest remove\n\n\n\n\n\n\n\n\n\n\ntest add\n\n\ntest add\n\n\ntest add\n\n\ntest add\n\n\n\n\n\n\ntest add\n\n\n\n\n\n\n\n\nH\n2\nO\n\n\nH\nthis is a test\n\n\n\n\n Lorem ipsum dolor sit amet, consectetur adipiscing elit\n\n\n Nulla lobortis egestas semper\n\n\n Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est\n\n\n Vestibulum convallis sit amet nisi a tincidunt\n\n\n In hac habitasse platea dictumst\n\n\n In scelerisque nibh non dolor mollis congue sed et metus\n\n\n Sed egestas felis quis elit dapibus, ac aliquet turpis mattis\n\n\n Praesent sed risus massa\n\n\n\n\n\n\n Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque\n\n\n Nulla vel eros venenatis, imperdiet enim id, faucibus nisi\n\n\n\n\nLorem ipsum\n1\n dolor sit amet, consectetur adipiscing elit.\n2\n\n\n\n\nNote\n\n\nthis is a test\n\n\npublic\n \nvoid\n \nreadonly\n \nstatic\n\n\n\n\n\n\n\npublic\n \nstatic\n \nreadonly\n \nstring\n \nName\n \n=\n \nNoName\n;\n\n\nSome file.\n\n\nimport foo.bar\n\nimport boo.baz\n\nimport foo.bar.baz\n\n\n\n\nimport\n \nfoo.bar\n\n\n\n\n\n \n \n \n \n \n \n \n \n \n \n 1\nst\n 2\nnd\n 3\nrd\n\n\n Bubble sort \n\n\ndef\n \nbubble_sort\n(\nitems\n):\n\n\n    \nfor\n \ni\n \nin\n \nrange\n(\nlen\n(\nitems\n)):\n\n\n        \nfor\n \nj\n \nin\n \nrange\n(\nlen\n(\nitems\n)\n \n-\n \n1\n \n-\n \ni\n):\n\n\n            \nif\n \nitems\n[\nj\n]\n \n \nitems\n[\nj\n \n+\n \n1\n]:\n\n                \nitems\n[\nj\n],\n \nitems\n[\nj\n \n+\n \n1\n]\n \n=\n \nitems\n[\nj\n \n+\n \n1\n],\n \nitems\n[\nj\n]\n\n\n\n\n\n\n\nNote\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nSeealso\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nPhasellus posuere in sem ut cursus\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\nPhasellus posuere in sem ut cursus\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\nAbstract\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nSummary\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nTldr\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nTodo\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nInfo\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nTip\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nHint\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nImportant\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nSuccess\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nCheck\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nDone\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nQuestion\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nHelp\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nFaq\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nWarning\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nCaution\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nAttention\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nFailure\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nFail\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nMissing\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nDanger\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nError\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nBug\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nExample\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nSnippet\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nQuote\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nCite\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit.\n\n\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.", 
            "title": "Examples"
        }, 
        {
            "location": "/examples/#examples", 
            "text": "Here is some  incorrect  Markdown.  I am adding this  here .  Here is some more  text\n that I am removing text.  And here is even more  text that I \n am  adding.    Paragraph was deleted and replaced with some spaces.      Spaces were removed and a paragraph was added.  And here is a comment on  some\n text This works quite well. I just wanted to comment on it. . Substitutions  is are  great!  General block handling.    test remove  test remove  test remove  test remove    test remove      test add  test add  test add  test add    test add     H 2 O  H this is a test    Lorem ipsum dolor sit amet, consectetur adipiscing elit   Nulla lobortis egestas semper   Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est   Vestibulum convallis sit amet nisi a tincidunt   In hac habitasse platea dictumst   In scelerisque nibh non dolor mollis congue sed et metus   Sed egestas felis quis elit dapibus, ac aliquet turpis mattis   Praesent sed risus massa     Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque   Nulla vel eros venenatis, imperdiet enim id, faucibus nisi   Lorem ipsum 1  dolor sit amet, consectetur adipiscing elit. 2   Note  this is a test  public   void   readonly   static    public   static   readonly   string   Name   =   NoName ;  Some file.  import foo.bar import boo.baz import foo.bar.baz  import   foo.bar                        1 st  2 nd  3 rd   Bubble sort   def   bubble_sort ( items ):       for   i   in   range ( len ( items )):           for   j   in   range ( len ( items )   -   1   -   i ):               if   items [ j ]     items [ j   +   1 ]: \n                 items [ j ],   items [ j   +   1 ]   =   items [ j   +   1 ],   items [ j ]    Note  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Seealso  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Phasellus posuere in sem ut cursus  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.   Phasellus posuere in sem ut cursus Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.  Abstract  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Summary  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Tldr  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Todo  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Info  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Tip  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Hint  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Important  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Success  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Check  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Done  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Question  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Help  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Faq  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Warning  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Caution  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Attention  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Failure  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Fail  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Missing  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Danger  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Error  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Bug  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Example  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Snippet  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Quote  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Cite  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.        Lorem ipsum dolor sit amet, consectetur adipiscing elit.    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.", 
            "title": "Examples"
        }, 
        {
            "location": "/http/", 
            "text": "HTTP\n\n\nWhen designing a RESTful API delivered over HTTP, it is important to maintain a high degree of visibility. This will let the API benefit from existing software and infrastructure for features that you would otherwise have to build yourself.\n\n\n\n\nVisibility in the context of HTTP\n\n\nVisibility simply means that one component of an architecture can monitor (and even participate in) the interaction between other components of the same architecture.\n\n\n\n\nLuckily HTTP is an application-level protocol designed to keep communication between clients and servers visible.\n\n\nHTTP defines operations for transferring representations between clients and servers, eliminating the need for application-specific operations (e.g. \ncreateBooking\n, \nchangeBooking\n, etc.).\n\n\n\n\nTip\n\n\nUsing the capabilities of HTTP means that caches, proxies, firewalls, etc., can monitor and participate in the protocol.\n\n\n\n\nVisibility\n\n\nFor better visibility:\n\n\n\n\nDO\n make interactions stateless.\n\n\nDO\n use HTTP methods.\n\n\nDO\n use appropriate headers to describe requests and responses.\n\n\nDO\n use appropriate status codes and messages.\n\n\nDO NOT\n change syntax and meaning, specified by HTTP, from application to application nor from resource to resource.\n\n\n\n\n\n\nWarning\n\n\nKeep in mind that focusing solely on visibility may create too fine-grained resources, and poor separation of concern between clients and servers. Trading visibility for other benefits is not necessarily bad.\n\n\n\n\nConsider trading visibility:\n\n\n\n\nwhen multiple resources share data\n\n\nwhen operations modifies multiple resources\n\n\nfor better abstraction and loose coupling\n\n\nfor network efficiency\n\n\nfor better resource granularity\n\n\nor simply for pure client convenience", 
            "title": "HTTP"
        }, 
        {
            "location": "/http/#http", 
            "text": "When designing a RESTful API delivered over HTTP, it is important to maintain a high degree of visibility. This will let the API benefit from existing software and infrastructure for features that you would otherwise have to build yourself.   Visibility in the context of HTTP  Visibility simply means that one component of an architecture can monitor (and even participate in) the interaction between other components of the same architecture.   Luckily HTTP is an application-level protocol designed to keep communication between clients and servers visible.  HTTP defines operations for transferring representations between clients and servers, eliminating the need for application-specific operations (e.g.  createBooking ,  changeBooking , etc.).   Tip  Using the capabilities of HTTP means that caches, proxies, firewalls, etc., can monitor and participate in the protocol.", 
            "title": "HTTP"
        }, 
        {
            "location": "/http/#visibility", 
            "text": "For better visibility:   DO  make interactions stateless.  DO  use HTTP methods.  DO  use appropriate headers to describe requests and responses.  DO  use appropriate status codes and messages.  DO NOT  change syntax and meaning, specified by HTTP, from application to application nor from resource to resource.    Warning  Keep in mind that focusing solely on visibility may create too fine-grained resources, and poor separation of concern between clients and servers. Trading visibility for other benefits is not necessarily bad.   Consider trading visibility:   when multiple resources share data  when operations modifies multiple resources  for better abstraction and loose coupling  for network efficiency  for better resource granularity  or simply for pure client convenience", 
            "title": "Visibility"
        }, 
        {
            "location": "/hypermedia/", 
            "text": "Hypermedia\n\n\nWhat is Hypermedia?\n\n\nOne of the challenges to implementing and correctly using hypermedia in your REST API is first understanding what hypermedia is, and what it means to use hypermedia as the engine of application state (HATEOAS).\nThe term \"hypermedia\" was coined back in 1965 by Ted Nelson, and over the years has dominated the technology industry.\n\n\nHypermedia, in its most basic sense is an extension of hypertext \u2013 something you may recognize from HTML.\n\n\nHypertext is essentially text that is written in a structured format and contains relationships to other objects via links.\n\n\nIf you think of a webpage, using HTML \u2013 the Hypertext Markup Language \u2013 text is then interpreted by a browser to become a webpage, or an interactive environment capable of doing more than just providing a blob of text.\n\n\nHowever, to be truly interactive and guide the user, the crucial component of all of this is links, something we use everyday when surfing the web.\nEnter hypermedia, again just an extension of the term hypertext, hypermedia includes images, video, audio, text, and links.\n\n\nIn a REST API, this means that your API is able to function similarly to a webpage, providing the user with guidance on what type of content they can retrieve, or what actions they can perform, as well as the appropriate links to do so.\nEssentially, the easiest way to take advantage of hypermedia in your API is to provide valuable information to direct the user or client to the next possible actions they can take based on the object (whether it be a collection, or item within the resource) or \"page\" they are on via links.\nAnother way to think of it is to bring back the Hypercard application from the early Apple days (we're talking Macintosh Classic).\n\n\nWith this application you could create \"cards\" or slides with links that performed different functions.\n\n\nClicking on link might play a sound, another a video, or another would take you to a different card.\n\n\nOn each card you were presented with certain links (whether in the form of a button or text) for the available actions to you on this card.\n\n\nThis is exactly how hypertext links work within RESTful APIs\u2013 they are designed to take you to the other components of the API, your other \"cards.\"\nBy adding these links, because REST is stateless, we are providing the client with a method for determining the state of the current item/ collection that they are on, as well as giving them the roadmap or engine for what they can do with it.\n\n\nIn other words, we are using Hypermedia as the Engine of the Application's State, or implementing HATEOAS.\n\n\nThe HATEOAS Debate\n\n\nCurrently, there is a lot of disagreement around hypermedia's place in RESTful APIs\u2013 with Dr. Roy Fielding saying it is critical to REST, and without it your API cannot be RESTful; and hypermedia skeptics arguing that you are doing nothing more than bloating your API and making it more difficult to use under the guise of usability.\nThis means you will find many different stances on the web today, ranging from Peter Williams explanation of how hypermedia has helped him, Jeff Krupp's rant against hypermedia, and even Kin Lane's summary of the whole debate.\nBut what it really comes down to isn't what do others think about hypermedia, as most major frameworks for building APIs now include hypermedia specs such as HAL, JSON-LD, JSON API, Siren, or Collection+JSON, but rather what benefit does hypermedia offer- and is that benefit enough to outweigh the cost/ disadvantages of incorporating hypermedia.\n\n\nThe Claims For and Against Hypermedia\n\n\nSome of the most common arguments for and against hypermedia include:\n\n\nHypermedia creates more work\n\n\nThis is absolutely true.\n\n\nAdding hypermedia or hypertext links to your API output does require more work \u2013 and more thought to go into your API.\n\n\nGoing back to the Planning Your API post in this series, hypermedia explains how your API works together, what resources work with which, and what you can do with a collection, or specific items in that collection.\n\n\nThis will add to both the workload and the time it takes to build your API.\n\n\nHowever, by having these relationships already drawn out as suggested, the additional time required will be minimal.\n\n\nHypermedia will require more Data-Transfer\n\n\nAgain, absolutely true.\n\n\nBy adding the links to your response you are increasing the amount of data that needs to be sent back, and slowly down the responses ever so slightly.\n\n\nHowever, for MOST APIs the amount of data being added will be minimal and the data/ time difference result will realistically be unnoticeable.\n\n\nWhat you will do, however, is help avoid unnecessary calls that are not accessible to a particular item, but may be available to other items.\n\n\nSee the next section for more on this.\n\n\nYou are creating an API for a client that doesn't exist\n\n\nAnother argument against APIs is that unlike web browsers, there are no browsers for APIs.\n\n\nLikewise a valid argument, however, one I personally believe falls short as like the web we are seeing advances in APIs and recently an explosion of API exploration tools ranging from API Consoles to the API Notebook.\n\n\nAs more and more APIs are developed there will be more and more emphasis on being able to explore them pragmatically.\nAnother reason I believe this argument falls short is that by utilizing hypermedia you allow the developers USING your API to build their systems around the information you provide them, creating a more dynamic application that relies on the available actions YOU return to them instead of creating rigidity by hardcoding what actions the user can take from their application in relation to your API and returning errors when those actions fail because they simply were not available to begin with.\nFor example, for one user you may be able to:\nEdit\nSuspend\nDelete\nBut for another user who has been suspended, maybe you can only:\nRestore\nDelete\nBecause this is dynamic data the developer has no way to determine what actions are available and which ones are not, unless they dig through and try to decipher the user's data which has been returned- making assumptions about your architectures rules which may or may not be correct, and may change with future development.\n\n\nHypertext links in this case allow the developer to rely on YOUR rules and architecture, rather than trying to mimic it with their own.\n\n\nNobody knows how to use Hypermedia\n\n\nThere is some truth into this.\n\n\nDespite existing since 1965, many developers are flustered when first running into hypermedia, choosing to ignore it or misunderstanding how to use it (i.e.\n\n\nhard-coding the links).\n\n\nWhat can help with this, however, is more APIs taking advantage of hypermedia (as being encouraged in the most popular development frameworks), and simple explanations within documentation explaining how the hypertext links work (just as we had to explain how to do a GET, POST, PUT, PATCH, and DELETE when REST first came out).\n\n\nHowever, unlike many specs and challenges out there, utilizing hypermedia from a client has a very fast learning curve, and most developers are able to implement it quickly and without any real issue once they understand what it is designed to do.\n\n\nAnd once implemented correctly, many developers appreciate knowing that as resource URIs change or additional query parameters are required of them, that their application will be able to \"automatically upgrade\" to these new requirements without any work or concern on their part.\n\n\nHypermedia makes your API MORE Flexible\n\n\nAbsolutely true.\n\n\nBy adding Hypermedia you are able to add new features more seamlessly- making them immediately available to your users.\n\n\nIt also gives you the power to change certain aspects of your API (i.e.\n\n\nchanging resources, requiring additional GET parameters) without necessarily breaking backwards compatibility IF implemented correctly by your users.\n\n\nHypermedia prevents APIs from breaking\n\n\nAbsolutely false.\n\n\nAs mentioned above, Hypermedia does make your API more flexible, but does not excuse poor design or allow you to break backwards compatibility.\n\n\nOne of the reasons for this, is even if you have a purely hypermedia driven API, such as Stormpath's, developers will still hardcode certain URLs to avoid having to make multiple calls.\n\n\nFor example, they may access the /users resource directly to get a list of all users instead of starting from the gateway or entry point of your API and working up to that point through multiple calls.\n\n\nWhile this technique does save you (and them) multiple API calls, it does limit your ability to change common or most frequently used resource URIs.\nHypertext links also do nothing for backwards incompatible changes in data\u2013 although you could hypothetically use them as a form of versioning.\n\n\nHypermedia replaces Documentation\n\n\nHypermedia does increase discoverability of your API's resources and methods, however, it does not replace documentation as it doesn't provide method information, schemas, or examples.\n\n\nDocumentation also serves as a preview to your API, letting developers understand how it works, and potentially make sample calls using an API Console before implementing it into their application.\n\n\nHypermedia also does not play a solid role in debugging the implementation of the API when things go wrong.\n\n\nFor this reason, having well written, informative documentation is vital to any API.\n\n\nIn fact, many RESTful hypermedia specs including HAL grant you the ability to embed documentation links for quick reference by developers.\n\n\nHypermedia is a Best Practice\n\n\nWhere hypermedia shines is in its ability to create a flexible API that provides dynamic data for developers based on your architecture and not their own.\n\n\nIn essence, it provides a shortcut for developers that allows them to utilize your API to its fullest without having to rely solely on documentation and writing rules that may or may not not be consistent with those in your application.\n\n\nLike when building a simple website, one may not see the advantage of Hypermedia right away, but as your API grows and becomes more complex you will find that it becomes a powerful convenience layer, one that will help developers better understand and navigate your API, and one that may prevent you from having to version your API for certain changes that would otherwise be backwards incompatible \u2014 if implemented correctly by your users.\n\n\nAs Peter Williams explains in his post, hypermedia turned out to be a saving grace.\n\n\nAnd as a key component of REST as defined by Dr. Roy Fielding, it remains a best practice to implement.\n\n\nIn Summary\n\n\nHypermedia is often misunderstood in regards to APIs, but essentially it functions exactly like links on a webpage.\n\n\nAnd while the technology is both praised and criticized, it does provide an array of short and long-term gains.\n\n\nThese gains, I believe, become more and more noticeable the larger and more complex your API becomes.\n\n\nHowever, the best features of utilizing HATEOAS, in my opinion, are yet to be seen as technology and API exploration tools continue to advance.\nBe sure to join us next week as we take a look at implementing hypermedia into your API and the current specs out there to help you do so.\n\n\nThe Harsh Reality of the State of Hypermedia Specs\n\n\nHypermedia sounds great in theory, but theory only goes so far.\n\n\nWhere hypermedia really shines, or completely fails, is in implementation.\n\n\nUnfortunately, as hypermedia is still a relatively new aspect of web based APIs, there isn't one specified way of doing things.\n\n\nIn fact, you'll find that even some of the most popular APIs operate completely differently from each other.\nAfter all, there are several different hypermedia formats available for API providers to choose from.\n\n\nJust for starters there is HAL, Collection+JSON, JSON-LD, JSON API, and Siren! But the list doesn't stop there, as some popular APIs have even elected to create their own format.\nFor example, while PayPal's API closely mimics the JSON API format, it goes a step further and adds a method property (not part of the JSON API spec), creating a more flexible spec and transforming it from being resource driven to being action driven:\nThis has the potential to let developers create a more agile client based on the actions (and methods) available to them.\n\n\nHowever, for developers not familiar with PayPal's format, but familiar with JSON API this may cause slight confusion (although it should be quickly remedied by reading their docs).\nVerticalResponse, on the other hand, has taken a different, albeit interesting approach.\n\n\nFor their API they likewise start with the basic JSON API format, but for some reason decided against the universally accepted \"href\" or Hypertext Reference property, instead opting to use \"url\" or the uniform resource locator as the link URI identifier:\nPersonally, I would recommend staying with the uniform \"href\" attribute as it denotes a reference to a hypertext link and is not as exclusive as an URL- which is not (although it commonly is) to be confused with URI.\n\n\nBut you can read more on that here.\nOn the other hand, Amazon's AppStream API, Clarify, Microsoft's Lync, and FoxyCart all prefer to follow HAL or the Hypertext Application Language format.\n\n\nHAL provides a simple format for nest-able links, but like other specs omits the methods property as included by PayPal, making theirs truly unique in that sense:\nHowever FoxyCart takes it one step further, not only taking advantage of hypermedia, but offering multiple formats for their clients to choose from, including HAL+JSON, HAL+XML, and Siren.\nThis, however, highlights once again one of the biggest challenges with hypermedia driven APIs, the abundance of ideas and specs available for execution.\n\n\nWhile on one-hand I believe that by supporting both XML and JSON, as well as having multiple JSON formats FoxyCart is by far the most flexible (format wise) of the APIs, not having a singular standard for each language does present the challenge of forcing developers (and hypermedia clients) to support multiple formats (as they integrate more and more hypermedia APIs), while also having the understanding that not one format meets every API's needs.\nThe good news, is that despite these growing pains, we are starting to see companies adopting certain specs over others, while also identifying areas for improvement (such as with PayPal's adding of methods to JSON API).\n\n\nNext week we'll take a look at some of the most popular formats out there in-depth, keying in on the strengths and weaknesses of each.\nBut it's important that as you build your API, you understand WHY you are building it the way you are.\n\n\nAnd this extends into how you build your hypermedia links, and whether or not you choose to take advantage of a standardized format (recommended), or venture off on your own to meet your developers' needs.\n\n\nOne of the best ways to do this is to explore what others have done with their APIs, and learn from their successes, and their mistakes.\nIt's also important to consider where technology is going.\n\n\nAnd as more and more formats become available and change in popularity, it may be smart to follow FoxyCart's lead \u2013 taking advantage of the spec that best meets your developers' needs, but also keeping the link format decoupled enough from your data that you are able to return multiple formats based on the content-type received.\n\n\nSomething that will allow you to take advantage of this best practice, while also being prepared for whatever the future may hold.\n\n\nSpecs\n\n\nWhat essentially every hypertext linking spec does provide is a name for the link and a hypertext reference, but outside of that, it's a crapshoot.\n\n\nAs such, it's important to understand the different specs that are out there, which ones are leading the industry, and which ones meet your needs.\n\n\nWe may not be able to get it down to one spec, but at least we'll be able to provide our users with a uniform response that they can easily incorporate into their application:\n\n\nCollection+JSON\n\n\nCollection+JSON is a JSON-based read/write hypermedia-type designed by Mike Amundsen back in 2011 to support the management and querying of simple collections.\n\n\nIt's based on the Atom Publication and Syndication specs, defining both in a single spec and supporting simple queries through the use of templates.\n\n\nWhile originally widely used among APIs, Collection+JSON has struggled to maintain its popularity against JSON API and HAL.\nStrengths: strong choice for collections, templated queries, early wide adoption, recognized as a standard Weaknesses: JSON only, lack of identifier for documentation, more complex/ difficult to implement\n\n\nJSON API\n\n\nJSON API is a newer spec created in 2013 by Steve Klabnik and Yahuda Klaz.\n\n\nIt was designed to ensure separation between clients and servers (an important aspect of REST) while also minimizing the number of requests without compromising readability, flexibility, or discovery.\n\n\nJSON API has quickly become a favorite receiving wide adoption and is arguably one of the leading specs for JSON based RESTful APIs.\n\n\nJSON API currently bares a warning that it is a work in progress, and while widely adopted not necessarily stable.\nStrengths: simple versatile format, easy to read/ implement, flat link grouping, URL templating, wide adoption, strong community, recognized as a hypermedia standard\nWeaknesses: JSON only, lack of identifier for documentation, still a work in progress\n\n\nHAL\n\n\nHAL is an older spec, created in 2011 by Mike Kelly to be easily consumed across multiple formats including XML and JSON.\n\n\nOne of the key strengths of HAL is that it is nestable, meaning that _links can be incorporated within each item of a collection.\n\n\nHAL also incorporates CURIEs, a feature that makes it unique in that it allows for inclusion of documentation links in the response \u2013 albeit they are tightly coupled to the link name.\n\n\nHAL is one of the most supported and most widely used hypermedia specs out there today, and is surrounded by a strong and vocal community.\nStrengths: dynamic, nestable, easy to read/ implement, multi-format, URL templating, inclusion of documentation, wide adoption, strong community, recognized as a standard hypermedia spec, RFC proposed Weaknesses: JSON/XML formats architecturally different, CURIEs are tightly coupled\n\n\nJSON-LD\n\n\nJSON-LD is a lightweight spec focused on machine to machine readable data.\n\n\nBeyond just RESTful APIs, JSON-LD was also designed to be utilized within non-structured or NoSQL databases such as MongoDB or CouchDB.\n\n\nDeveloped by the W3C JSON-LD Community group, and formally recommended by W3C as a JSON data linking spec in early 2014, the spec has struggled to keep pace with JSON API and HAL.\n\n\nHowever, it has built a strong community around it with a fairly active mailing list, weekly meetings, and an active IRC channel.\nStrengths: strong format for data linking, can be used across multiple data formats (Web API \n Databases), strong community, large working group, recognized by W3C as a standard\nWeaknesses: JSON only, more complex to integrate/ interpret, no identifier for documentation\n\n\nSiren\n\n\nCreated in 2012 by Kevin Swiber, Siren is a more descriptive spec made up of classes, entities, actions, and links.\n\n\nIt was designed specifically for Web API clients in order to communicate entity information, actions for executing state transitions, and client navigation/ discoverability within the API.\n\n\nSiren was also designed to allow for sub-entities or nesting, as well as multiple formats including XML \u2013 although no example or documentation regarding XML usage is provided.\n\n\nDespite being well intentioned and versatile, Siren has struggled to gain the same level of attention as JSON API and HAL.\n\n\nSiren is still listed as a work in progress.\nStrengths: provides a more verbose spec, query templating, incorporates actions, multi-format\nWeaknesses: poor adoption, lacks documentation, work in progress\n\n\nOther Specs\n\n\nAlong with some of the leading specs mentioned above, new specs are being created every day including UBER, Mason, Yahapi, and CPHL.\n\n\nThis presents a very interesting question, and that is are we reinventing the wheel, or is there something missing in the above specs.\n\n\nI believe the answer is a combination of both, with developers being notorious for reinventing the wheel, but also because each developer looks at the strengths and weaknesses of other specs and envisions a better way of doing things.\nYou may recognize this issue from the last post, where some specs were modified by the companies using them to meet their individual needs.\n\n\nFor example, PayPal wanted to include methods in their response, but you'll notice that only Siren of the above include methods in the link definition.\n\n\nThe Future of Specs\n\n\nGiven that new specs are being created every day, each with different ideas and in different formats, it's extremely important to keep your system as decoupled and versatile as possible, and it will be very interesting to see what the future of hypermedia specs will look like.\nIn the mean-time, it's best to choose the spec that meets your needs, while also being recognized as a standard for easy integration by developers.\n\n\nOf the specs above, I would personally recommend sticking with HAL or JSON API, although each has its own strengths and weaknesses, and I believe that universal spec of the future has yet to be created.\n\n\nBut by adhering to these common specs while the new specs battle things out, I think we will finally find that standard method of road signs, detours, and a single solution to provide API clients with a standardized GPS system.\nFor more on the different specs, I highly recommend reading Kevin Sookocheff's review.\n\n\nI'd also love to hear your thoughts in the comments below.\n\n\nLinking and Application State\n\n\n\n\n\n!--\nHATEOS / HAL / JSONAPI etc.\n--\n\n\nA link provides a mean to navigate from one resource to another.\n\nApplication state is the state the server needs to maintain between each request for each client. Keeping state in clients does not mean serializing session state into URIs or HTML forms.\n\nIf the amount of data is small, the best place to maintain application state is within links in representations of resources, where the server can encode the state within the URI itself. However, the server can stores data in a durable storage and encodes its primary key in the URI. Use a combination of both approaches for managing application state to strike a balance between network performance, scalability and reliability.\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/xml;charset=UTF-8\n\n\nquote xmlns:atom=\nhttp://www.w3.org/2005/Atom\n\n    \ndriver\n...\n/driver\n\n    \nvehicle\n...\n/vehicle\n\n    \noffer\n\n        \nvalid-until\n2009-10-02\n/valid-until\n\n        \natom:link href=\nhttp://www.example.org/quotes/buy?quote=abc1234\n rel=\nhttp://www.example.org/rels/quotes/buy\n /\n\n    \n/offer\n\n\n/quote\n\n```\n\n\n\n\n\n\n\nDO\n encode application state into URIs, and include those URIs into representations via links.\n\n\nDO\n store the application state in a durable storage, and encode a reference to that state in URIs, if the state is large or cannot be transported to the clients for security or privacy reasons.\n\n\nDO\n make sure to add checks (such as signatures) to detect/prevent tampering of state, when using application state in links.\n\n\n\n\n\n\n\n#### *Links in XML Representations*\n\n*[Atom](http://www.w3.org/2005/Atom)*\n\n\n\n\n\nMUST: Use Common Hypertext Controls\n\n\nWhen embedding links to other resources into representations you must use the common hypertext control object. It contains at least one attribute:\n\n\nhref: The URI of the resource the hypertext control is linking to. All our API are using HTTP(s) as URI scheme.\nIn API that contain any hypertext controls, the attribute name href is reserved for usage within hypertext controls.\n\n\nThe schema for hypertext controls can be derived from this model:\n\n\nHttpLink:\n  description: A base type of objects representing links to resources.\n  type: object\n  properties:\n    href:\n      description: Any URI that is using http or https protocol\n      type: string\n      format: uri\n  required: [ \"href\" ]\nThe name of an attribute holding such a HttpLink object specifies the relation between the object that contains the link and the linked resource. Implementations should use names from the IANA Link Relation Registry whenever appropriate. As IANA link relation names use hyphen-case notation, while this guide enforces snake_case notation for attribute names, hyphens in IANA names have to be replaced with underscores (e.g. the IANA link relation type version-history would become the attribute version_history)\n\n\nSpecific link objects may extend the basic link type with additional attributes, to give additional information related to the linked resource or the relationship between the source resource and the linked one.\n\n\nE.g. a service providing \"Person\" resources could model a person who is married with some other person with a hypertext control that contains attributes which describe the other person (id, name) but also the relationship \"spouse\" between between the two persons (since):\n\n\n{\n  \"id\": \"446f9876-e89b-12d3-a456-426655440000\",\n  \"name\": \"Peter Mustermann\",\n  \"spouse\": {\n    \"href\": \"https://...\",\n    \"since\": \"1996-12-19\",\n    \"id\": \"123e4567-e89b-12d3-a456-426655440000\",\n    \"name\": \"Linda Mustermann\"\n  }\n}\nHypertext controls are allowed anywhere within a JSON model. While this specification would allow HAL, we actually don't recommend/enforce the usage of HAL anymore as the structural separation of meta-data and data creates more harm than value to the understandability and usability of an API.\n\n\nLinks in JSON Representations\n\n\n## What about attribute names?\n\nIn the previous section, we talked about formats - supporting multiple formats and working with JSON as the default.\n\nThis time, let\ns talk about what happens when a response comes back.\n\nYou have an object with data attributes on it. How should you name the attributes?\n\nHere are API responses from a few leading APIs:\n\nTwitter\n\n\ncreated_at\n: \nThu Nov 03 05:19;38 +0000 2011\n\n\nBing\n\n\nDateTime\n: \n2011-10-29T09:35:00Z\n\n\nFoursquare\n\n\ncreatedAt\n: 1320296464\n\nThey each use a different code convention. Although the Twitter approach is familiar to me as a Ruby on Rails developer, we think that Foursquare has the best approach.\n\nHow does the API response get back in the code? You parse the response (JSON parser); what comes back populates the Object. It looks like this\n\nvar myObject = JSON.parse(response);\n\nIf you chose the Twitter or Bing approach, your code looks like this. Its not JavaScript convention and looks weird - looks like the name of another object or class in the system, which is not correct.\n\ntiming = myObject.created_at;\n\ntiming - myObject.DateTime;\n\nRecommendations\n\n* Use JSON as default\n\n* Follow JavaScript conventions for naming attributes\n\n- Use medial capitalization (aka CamelCase)\n\n- Use uppercase or lowercase depending on type of object\n\nThis results in code that looks like the following, allowing the JavaScript developer to write it in a way that makes sense for JavaScript.\n\n\ncreatedAt\n: 1320296464\n\ntiming = myObject.createdAt;\n\n\n\n\n\n\n\nDO\n use a \nlink\n property or a \nlinks\n property to include several links as an array whose value is a link object or a link object array.\n\n\nDO\n include \nhref\n and \nrel\n properties in each link object\n\n\n\n\nExamples:\n\n\n{\n\n    \nlink\n:\n \n{\n\n        \nrel\n:\n \nalternate\n,\n\n        \nhref\n:\n \nhttp://www.example.org/customers?format=json\n\n    \n}\n\n\n}\n\n\n\n\n\n{\n\n    \nlink\n:\n \n{\n\n        \nalternate\n:\n \nhttp://www.example.org/customers?format=json\n\n    \n}\n\n\n}\n\n\n\n\n\n{\n\n    \nlinks\n:\n \n[{\n\n        \nrel\n:\n \nalternate\n,\n\n        \nhref\n:\n \nhttp://www.example.org/customers?format=json\n\n    \n},\n\n    \n{\n\n        \nrel\n:\n \nhttp://www.example.org/rels/owner\n,\n\n        \nhref\n:\n \n...\n\n    \n}]\n\n\n}\n\n\n\n\n\n{\n\n    \nlinks\n:\n \n{\n\n        \nalternate\n:\n \nhttp://www.example.org/customers?format=json\n\n        \nhttp://www.example.org/rels/owner\n:\n \nhttp://www.example.org/owner\n\n    \n}\n\n\n}\n\n\n\n\n\nLink Header\n\n\nThe \nLink\n header provides a format-independent means to convey links, which is one of the key benefits, along with visibility at the protocol level. Also the need for documentation on how to discover links in XML or JSON representations is lowered.\n\n\n# Link header format\nLink: \n{URI}\n;rel=\n{relation}\n;type=\n{media type\n};title=\n{title}\n...\n\n\n\n\n\n\nDO\n use link header when you want to convey links in a format-independent manner\n\n\nDO\n use link header when a representation format does not support links. E.g.:\n\n\nBinary format\n\n\nFormats that do not allow for easy discovery of links (e.g., plain-text documents)\n\n\nWhen your client/server software needs to add links or read links without parsing the body of representations\n\n\n\n\nLink Relation Types\n\n\n\n\nALWAYS\n supply a link relation to act as an identifier for the semantics associated with the link\n\n\nALWAYS\n use URIs (such as \nhttp://www.example.org/rels/create-po\n) to express extended link relation types\n\n\nDO\n choose unambiguous value of link relations\n\n\nDO\n use one of the \nstandard relation types\n, when appropriate\n\n\nDO\n use lowercase for all link relation types\n\n\nDO\n use multiple values in link relations, if applicable\n\n\nCONSIDER\n providing an informational resource as an HTML document at that URI, describing the semantics of the link relation type. Include details such as HTTP methods supported, formats supported, and business rules about using the link.\n\n\n\n\n\n\nLink relation types meant for public use should register that link relation per the process outlined in section 6.2 of the Web Linking Internet-Draft.\n\n\n\n\nManaging Application Flow with Links\n\n\nOne of the key applications of hypermedia and links is the ability to decouple the client from learning about the rules the server uses to manage its application flow. The server can provide links containing application state, thereby using Hypermedia As The Engine Of Application State.\n\n\nThis prevents clients from having to learn and hard-code application flow, however, the mere presence of a link will not decouple the client from having to know how to prepare the data and make a request for the transition.\n\n\n\n\nDO\n design representations such that it contain links that help clients transition to all the next possible steps\n\n\nDO\n encode the state that needs to be carried forward in the links\n\n\nDO\n document how to find links and the semantics of all extended link relation types.\n\n\nDO\n, for clients, assume that absent links means the transition is not possible.\n\n\n\n\nEphemeral URIs\n\n\nDoes this belong in Resource Identifiers?\n\n\nA URI may be temporary and valid only for a single use or may expire after a fixed period of time.\n\n\n\n\nDO\n communicate ephemeral URIs via links.\n\n\nDO\n assign extended relation types for those links and document how long such URIs are valid and what the client should do after expiry.\n\n\nDO\n return appropriate \n4xx\n code when responding to expired URIs, with an instructions in the body of any actions the client can take.\n\n\n\n\nURI Template\n\n\nWhen the server does not have all the information necessary to generate a valid and complete URI for each link.\n\n\nA URI template is a string consisting of token marked off between matching braces (\n{\n and \n}\n). Clients substitute these tokens (including matching braces) with URI-safe strings to convert the template into a valid URI.\n\n\nFor simplicity limit the tokens to the following parts of URIs:\n\n\n\n\nPath segments\n\n\nValues of query parameters\n\n\nValues of matrix parameters\n\n\n\n\nTo include URI templates in a representation:\n\n\n\n\nDO\n use \nlink-template\n or \nlink-templates\n properties to convey URI templates, for JSON representations.\n\n\nDO\n document the tokens used in you URI template, since URI templates are semi-opaque and contain tokens that clients need to substitute, and you need a way to tell clients what values are valid for each token.\n\n\nCONSIDER\n using braces (\n{\n and \n}\n) to specify replacement tokens, as this a common standard in a lot of other templating system (e.g., WSDL 2.0 and WADL.\n\n\n\n\n//\n \nJSON\n \nrepresentation\n\n\n{\n\n    \nlink-templates\n:\n \n[{\n\n        \nrel\n:\n \nhttp://www.example.org/rels/customer\n,\n\n        \nhref\n:\n \nhttp://www.example.org/customer/{customer-id}\n\n    \n}]\n\n\n}", 
            "title": "Hypermedia"
        }, 
        {
            "location": "/hypermedia/#hypermedia", 
            "text": "", 
            "title": "Hypermedia"
        }, 
        {
            "location": "/hypermedia/#what-is-hypermedia", 
            "text": "One of the challenges to implementing and correctly using hypermedia in your REST API is first understanding what hypermedia is, and what it means to use hypermedia as the engine of application state (HATEOAS).\nThe term \"hypermedia\" was coined back in 1965 by Ted Nelson, and over the years has dominated the technology industry.  Hypermedia, in its most basic sense is an extension of hypertext \u2013 something you may recognize from HTML.  Hypertext is essentially text that is written in a structured format and contains relationships to other objects via links.  If you think of a webpage, using HTML \u2013 the Hypertext Markup Language \u2013 text is then interpreted by a browser to become a webpage, or an interactive environment capable of doing more than just providing a blob of text.  However, to be truly interactive and guide the user, the crucial component of all of this is links, something we use everyday when surfing the web.\nEnter hypermedia, again just an extension of the term hypertext, hypermedia includes images, video, audio, text, and links.  In a REST API, this means that your API is able to function similarly to a webpage, providing the user with guidance on what type of content they can retrieve, or what actions they can perform, as well as the appropriate links to do so.\nEssentially, the easiest way to take advantage of hypermedia in your API is to provide valuable information to direct the user or client to the next possible actions they can take based on the object (whether it be a collection, or item within the resource) or \"page\" they are on via links.\nAnother way to think of it is to bring back the Hypercard application from the early Apple days (we're talking Macintosh Classic).  With this application you could create \"cards\" or slides with links that performed different functions.  Clicking on link might play a sound, another a video, or another would take you to a different card.  On each card you were presented with certain links (whether in the form of a button or text) for the available actions to you on this card.  This is exactly how hypertext links work within RESTful APIs\u2013 they are designed to take you to the other components of the API, your other \"cards.\"\nBy adding these links, because REST is stateless, we are providing the client with a method for determining the state of the current item/ collection that they are on, as well as giving them the roadmap or engine for what they can do with it.  In other words, we are using Hypermedia as the Engine of the Application's State, or implementing HATEOAS.", 
            "title": "What is Hypermedia?"
        }, 
        {
            "location": "/hypermedia/#the-hateoas-debate", 
            "text": "Currently, there is a lot of disagreement around hypermedia's place in RESTful APIs\u2013 with Dr. Roy Fielding saying it is critical to REST, and without it your API cannot be RESTful; and hypermedia skeptics arguing that you are doing nothing more than bloating your API and making it more difficult to use under the guise of usability.\nThis means you will find many different stances on the web today, ranging from Peter Williams explanation of how hypermedia has helped him, Jeff Krupp's rant against hypermedia, and even Kin Lane's summary of the whole debate.\nBut what it really comes down to isn't what do others think about hypermedia, as most major frameworks for building APIs now include hypermedia specs such as HAL, JSON-LD, JSON API, Siren, or Collection+JSON, but rather what benefit does hypermedia offer- and is that benefit enough to outweigh the cost/ disadvantages of incorporating hypermedia.", 
            "title": "The HATEOAS Debate"
        }, 
        {
            "location": "/hypermedia/#the-claims-for-and-against-hypermedia", 
            "text": "Some of the most common arguments for and against hypermedia include:", 
            "title": "The Claims For and Against Hypermedia"
        }, 
        {
            "location": "/hypermedia/#hypermedia-creates-more-work", 
            "text": "This is absolutely true.  Adding hypermedia or hypertext links to your API output does require more work \u2013 and more thought to go into your API.  Going back to the Planning Your API post in this series, hypermedia explains how your API works together, what resources work with which, and what you can do with a collection, or specific items in that collection.  This will add to both the workload and the time it takes to build your API.  However, by having these relationships already drawn out as suggested, the additional time required will be minimal.", 
            "title": "Hypermedia creates more work"
        }, 
        {
            "location": "/hypermedia/#hypermedia-will-require-more-data-transfer", 
            "text": "Again, absolutely true.  By adding the links to your response you are increasing the amount of data that needs to be sent back, and slowly down the responses ever so slightly.  However, for MOST APIs the amount of data being added will be minimal and the data/ time difference result will realistically be unnoticeable.  What you will do, however, is help avoid unnecessary calls that are not accessible to a particular item, but may be available to other items.  See the next section for more on this.", 
            "title": "Hypermedia will require more Data-Transfer"
        }, 
        {
            "location": "/hypermedia/#you-are-creating-an-api-for-a-client-that-doesnt-exist", 
            "text": "Another argument against APIs is that unlike web browsers, there are no browsers for APIs.  Likewise a valid argument, however, one I personally believe falls short as like the web we are seeing advances in APIs and recently an explosion of API exploration tools ranging from API Consoles to the API Notebook.  As more and more APIs are developed there will be more and more emphasis on being able to explore them pragmatically.\nAnother reason I believe this argument falls short is that by utilizing hypermedia you allow the developers USING your API to build their systems around the information you provide them, creating a more dynamic application that relies on the available actions YOU return to them instead of creating rigidity by hardcoding what actions the user can take from their application in relation to your API and returning errors when those actions fail because they simply were not available to begin with.\nFor example, for one user you may be able to:\nEdit\nSuspend\nDelete\nBut for another user who has been suspended, maybe you can only:\nRestore\nDelete\nBecause this is dynamic data the developer has no way to determine what actions are available and which ones are not, unless they dig through and try to decipher the user's data which has been returned- making assumptions about your architectures rules which may or may not be correct, and may change with future development.  Hypertext links in this case allow the developer to rely on YOUR rules and architecture, rather than trying to mimic it with their own.", 
            "title": "You are creating an API for a client that doesn't exist"
        }, 
        {
            "location": "/hypermedia/#nobody-knows-how-to-use-hypermedia", 
            "text": "There is some truth into this.  Despite existing since 1965, many developers are flustered when first running into hypermedia, choosing to ignore it or misunderstanding how to use it (i.e.  hard-coding the links).  What can help with this, however, is more APIs taking advantage of hypermedia (as being encouraged in the most popular development frameworks), and simple explanations within documentation explaining how the hypertext links work (just as we had to explain how to do a GET, POST, PUT, PATCH, and DELETE when REST first came out).  However, unlike many specs and challenges out there, utilizing hypermedia from a client has a very fast learning curve, and most developers are able to implement it quickly and without any real issue once they understand what it is designed to do.  And once implemented correctly, many developers appreciate knowing that as resource URIs change or additional query parameters are required of them, that their application will be able to \"automatically upgrade\" to these new requirements without any work or concern on their part.", 
            "title": "Nobody knows how to use Hypermedia"
        }, 
        {
            "location": "/hypermedia/#hypermedia-makes-your-api-more-flexible", 
            "text": "Absolutely true.  By adding Hypermedia you are able to add new features more seamlessly- making them immediately available to your users.  It also gives you the power to change certain aspects of your API (i.e.  changing resources, requiring additional GET parameters) without necessarily breaking backwards compatibility IF implemented correctly by your users.", 
            "title": "Hypermedia makes your API MORE Flexible"
        }, 
        {
            "location": "/hypermedia/#hypermedia-prevents-apis-from-breaking", 
            "text": "Absolutely false.  As mentioned above, Hypermedia does make your API more flexible, but does not excuse poor design or allow you to break backwards compatibility.  One of the reasons for this, is even if you have a purely hypermedia driven API, such as Stormpath's, developers will still hardcode certain URLs to avoid having to make multiple calls.  For example, they may access the /users resource directly to get a list of all users instead of starting from the gateway or entry point of your API and working up to that point through multiple calls.  While this technique does save you (and them) multiple API calls, it does limit your ability to change common or most frequently used resource URIs.\nHypertext links also do nothing for backwards incompatible changes in data\u2013 although you could hypothetically use them as a form of versioning.", 
            "title": "Hypermedia prevents APIs from breaking"
        }, 
        {
            "location": "/hypermedia/#hypermedia-replaces-documentation", 
            "text": "Hypermedia does increase discoverability of your API's resources and methods, however, it does not replace documentation as it doesn't provide method information, schemas, or examples.  Documentation also serves as a preview to your API, letting developers understand how it works, and potentially make sample calls using an API Console before implementing it into their application.  Hypermedia also does not play a solid role in debugging the implementation of the API when things go wrong.  For this reason, having well written, informative documentation is vital to any API.  In fact, many RESTful hypermedia specs including HAL grant you the ability to embed documentation links for quick reference by developers.", 
            "title": "Hypermedia replaces Documentation"
        }, 
        {
            "location": "/hypermedia/#hypermedia-is-a-best-practice", 
            "text": "Where hypermedia shines is in its ability to create a flexible API that provides dynamic data for developers based on your architecture and not their own.  In essence, it provides a shortcut for developers that allows them to utilize your API to its fullest without having to rely solely on documentation and writing rules that may or may not not be consistent with those in your application.  Like when building a simple website, one may not see the advantage of Hypermedia right away, but as your API grows and becomes more complex you will find that it becomes a powerful convenience layer, one that will help developers better understand and navigate your API, and one that may prevent you from having to version your API for certain changes that would otherwise be backwards incompatible \u2014 if implemented correctly by your users.  As Peter Williams explains in his post, hypermedia turned out to be a saving grace.  And as a key component of REST as defined by Dr. Roy Fielding, it remains a best practice to implement.", 
            "title": "Hypermedia is a Best Practice"
        }, 
        {
            "location": "/hypermedia/#in-summary", 
            "text": "Hypermedia is often misunderstood in regards to APIs, but essentially it functions exactly like links on a webpage.  And while the technology is both praised and criticized, it does provide an array of short and long-term gains.  These gains, I believe, become more and more noticeable the larger and more complex your API becomes.  However, the best features of utilizing HATEOAS, in my opinion, are yet to be seen as technology and API exploration tools continue to advance.\nBe sure to join us next week as we take a look at implementing hypermedia into your API and the current specs out there to help you do so.", 
            "title": "In Summary"
        }, 
        {
            "location": "/hypermedia/#the-harsh-reality-of-the-state-of-hypermedia-specs", 
            "text": "Hypermedia sounds great in theory, but theory only goes so far.  Where hypermedia really shines, or completely fails, is in implementation.  Unfortunately, as hypermedia is still a relatively new aspect of web based APIs, there isn't one specified way of doing things.  In fact, you'll find that even some of the most popular APIs operate completely differently from each other.\nAfter all, there are several different hypermedia formats available for API providers to choose from.  Just for starters there is HAL, Collection+JSON, JSON-LD, JSON API, and Siren! But the list doesn't stop there, as some popular APIs have even elected to create their own format.\nFor example, while PayPal's API closely mimics the JSON API format, it goes a step further and adds a method property (not part of the JSON API spec), creating a more flexible spec and transforming it from being resource driven to being action driven:\nThis has the potential to let developers create a more agile client based on the actions (and methods) available to them.  However, for developers not familiar with PayPal's format, but familiar with JSON API this may cause slight confusion (although it should be quickly remedied by reading their docs).\nVerticalResponse, on the other hand, has taken a different, albeit interesting approach.  For their API they likewise start with the basic JSON API format, but for some reason decided against the universally accepted \"href\" or Hypertext Reference property, instead opting to use \"url\" or the uniform resource locator as the link URI identifier:\nPersonally, I would recommend staying with the uniform \"href\" attribute as it denotes a reference to a hypertext link and is not as exclusive as an URL- which is not (although it commonly is) to be confused with URI.  But you can read more on that here.\nOn the other hand, Amazon's AppStream API, Clarify, Microsoft's Lync, and FoxyCart all prefer to follow HAL or the Hypertext Application Language format.  HAL provides a simple format for nest-able links, but like other specs omits the methods property as included by PayPal, making theirs truly unique in that sense:\nHowever FoxyCart takes it one step further, not only taking advantage of hypermedia, but offering multiple formats for their clients to choose from, including HAL+JSON, HAL+XML, and Siren.\nThis, however, highlights once again one of the biggest challenges with hypermedia driven APIs, the abundance of ideas and specs available for execution.  While on one-hand I believe that by supporting both XML and JSON, as well as having multiple JSON formats FoxyCart is by far the most flexible (format wise) of the APIs, not having a singular standard for each language does present the challenge of forcing developers (and hypermedia clients) to support multiple formats (as they integrate more and more hypermedia APIs), while also having the understanding that not one format meets every API's needs.\nThe good news, is that despite these growing pains, we are starting to see companies adopting certain specs over others, while also identifying areas for improvement (such as with PayPal's adding of methods to JSON API).  Next week we'll take a look at some of the most popular formats out there in-depth, keying in on the strengths and weaknesses of each.\nBut it's important that as you build your API, you understand WHY you are building it the way you are.  And this extends into how you build your hypermedia links, and whether or not you choose to take advantage of a standardized format (recommended), or venture off on your own to meet your developers' needs.  One of the best ways to do this is to explore what others have done with their APIs, and learn from their successes, and their mistakes.\nIt's also important to consider where technology is going.  And as more and more formats become available and change in popularity, it may be smart to follow FoxyCart's lead \u2013 taking advantage of the spec that best meets your developers' needs, but also keeping the link format decoupled enough from your data that you are able to return multiple formats based on the content-type received.  Something that will allow you to take advantage of this best practice, while also being prepared for whatever the future may hold.", 
            "title": "The Harsh Reality of the State of Hypermedia Specs"
        }, 
        {
            "location": "/hypermedia/#specs", 
            "text": "What essentially every hypertext linking spec does provide is a name for the link and a hypertext reference, but outside of that, it's a crapshoot.  As such, it's important to understand the different specs that are out there, which ones are leading the industry, and which ones meet your needs.  We may not be able to get it down to one spec, but at least we'll be able to provide our users with a uniform response that they can easily incorporate into their application:", 
            "title": "Specs"
        }, 
        {
            "location": "/hypermedia/#collectionjson", 
            "text": "Collection+JSON is a JSON-based read/write hypermedia-type designed by Mike Amundsen back in 2011 to support the management and querying of simple collections.  It's based on the Atom Publication and Syndication specs, defining both in a single spec and supporting simple queries through the use of templates.  While originally widely used among APIs, Collection+JSON has struggled to maintain its popularity against JSON API and HAL.\nStrengths: strong choice for collections, templated queries, early wide adoption, recognized as a standard Weaknesses: JSON only, lack of identifier for documentation, more complex/ difficult to implement", 
            "title": "Collection+JSON"
        }, 
        {
            "location": "/hypermedia/#json-api", 
            "text": "JSON API is a newer spec created in 2013 by Steve Klabnik and Yahuda Klaz.  It was designed to ensure separation between clients and servers (an important aspect of REST) while also minimizing the number of requests without compromising readability, flexibility, or discovery.  JSON API has quickly become a favorite receiving wide adoption and is arguably one of the leading specs for JSON based RESTful APIs.  JSON API currently bares a warning that it is a work in progress, and while widely adopted not necessarily stable.\nStrengths: simple versatile format, easy to read/ implement, flat link grouping, URL templating, wide adoption, strong community, recognized as a hypermedia standard\nWeaknesses: JSON only, lack of identifier for documentation, still a work in progress", 
            "title": "JSON API"
        }, 
        {
            "location": "/hypermedia/#hal", 
            "text": "HAL is an older spec, created in 2011 by Mike Kelly to be easily consumed across multiple formats including XML and JSON.  One of the key strengths of HAL is that it is nestable, meaning that _links can be incorporated within each item of a collection.  HAL also incorporates CURIEs, a feature that makes it unique in that it allows for inclusion of documentation links in the response \u2013 albeit they are tightly coupled to the link name.  HAL is one of the most supported and most widely used hypermedia specs out there today, and is surrounded by a strong and vocal community.\nStrengths: dynamic, nestable, easy to read/ implement, multi-format, URL templating, inclusion of documentation, wide adoption, strong community, recognized as a standard hypermedia spec, RFC proposed Weaknesses: JSON/XML formats architecturally different, CURIEs are tightly coupled", 
            "title": "HAL"
        }, 
        {
            "location": "/hypermedia/#json-ld", 
            "text": "JSON-LD is a lightweight spec focused on machine to machine readable data.  Beyond just RESTful APIs, JSON-LD was also designed to be utilized within non-structured or NoSQL databases such as MongoDB or CouchDB.  Developed by the W3C JSON-LD Community group, and formally recommended by W3C as a JSON data linking spec in early 2014, the spec has struggled to keep pace with JSON API and HAL.  However, it has built a strong community around it with a fairly active mailing list, weekly meetings, and an active IRC channel.\nStrengths: strong format for data linking, can be used across multiple data formats (Web API   Databases), strong community, large working group, recognized by W3C as a standard\nWeaknesses: JSON only, more complex to integrate/ interpret, no identifier for documentation", 
            "title": "JSON-LD"
        }, 
        {
            "location": "/hypermedia/#siren", 
            "text": "Created in 2012 by Kevin Swiber, Siren is a more descriptive spec made up of classes, entities, actions, and links.  It was designed specifically for Web API clients in order to communicate entity information, actions for executing state transitions, and client navigation/ discoverability within the API.  Siren was also designed to allow for sub-entities or nesting, as well as multiple formats including XML \u2013 although no example or documentation regarding XML usage is provided.  Despite being well intentioned and versatile, Siren has struggled to gain the same level of attention as JSON API and HAL.  Siren is still listed as a work in progress.\nStrengths: provides a more verbose spec, query templating, incorporates actions, multi-format\nWeaknesses: poor adoption, lacks documentation, work in progress", 
            "title": "Siren"
        }, 
        {
            "location": "/hypermedia/#other-specs", 
            "text": "Along with some of the leading specs mentioned above, new specs are being created every day including UBER, Mason, Yahapi, and CPHL.  This presents a very interesting question, and that is are we reinventing the wheel, or is there something missing in the above specs.  I believe the answer is a combination of both, with developers being notorious for reinventing the wheel, but also because each developer looks at the strengths and weaknesses of other specs and envisions a better way of doing things.\nYou may recognize this issue from the last post, where some specs were modified by the companies using them to meet their individual needs.  For example, PayPal wanted to include methods in their response, but you'll notice that only Siren of the above include methods in the link definition.", 
            "title": "Other Specs"
        }, 
        {
            "location": "/hypermedia/#the-future-of-specs", 
            "text": "Given that new specs are being created every day, each with different ideas and in different formats, it's extremely important to keep your system as decoupled and versatile as possible, and it will be very interesting to see what the future of hypermedia specs will look like.\nIn the mean-time, it's best to choose the spec that meets your needs, while also being recognized as a standard for easy integration by developers.  Of the specs above, I would personally recommend sticking with HAL or JSON API, although each has its own strengths and weaknesses, and I believe that universal spec of the future has yet to be created.  But by adhering to these common specs while the new specs battle things out, I think we will finally find that standard method of road signs, detours, and a single solution to provide API clients with a standardized GPS system.\nFor more on the different specs, I highly recommend reading Kevin Sookocheff's review.  I'd also love to hear your thoughts in the comments below.", 
            "title": "The Future of Specs"
        }, 
        {
            "location": "/hypermedia/#linking-and-application-state", 
            "text": "!--\nHATEOS / HAL / JSONAPI etc.\n-- \n\nA link provides a mean to navigate from one resource to another.\n\nApplication state is the state the server needs to maintain between each request for each client. Keeping state in clients does not mean serializing session state into URIs or HTML forms.\n\nIf the amount of data is small, the best place to maintain application state is within links in representations of resources, where the server can encode the state within the URI itself. However, the server can stores data in a durable storage and encodes its primary key in the URI. Use a combination of both approaches for managing application state to strike a balance between network performance, scalability and reliability.\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/xml;charset=UTF-8 quote xmlns:atom= http://www.w3.org/2005/Atom \n     driver ... /driver \n     vehicle ... /vehicle \n     offer \n         valid-until 2009-10-02 /valid-until \n         atom:link href= http://www.example.org/quotes/buy?quote=abc1234  rel= http://www.example.org/rels/quotes/buy  / \n     /offer  /quote \n```   DO  encode application state into URIs, and include those URIs into representations via links.  DO  store the application state in a durable storage, and encode a reference to that state in URIs, if the state is large or cannot be transported to the clients for security or privacy reasons.  DO  make sure to add checks (such as signatures) to detect/prevent tampering of state, when using application state in links.    #### *Links in XML Representations*\n\n*[Atom](http://www.w3.org/2005/Atom)*", 
            "title": "Linking and Application State"
        }, 
        {
            "location": "/hypermedia/#must-use-common-hypertext-controls", 
            "text": "When embedding links to other resources into representations you must use the common hypertext control object. It contains at least one attribute:  href: The URI of the resource the hypertext control is linking to. All our API are using HTTP(s) as URI scheme.\nIn API that contain any hypertext controls, the attribute name href is reserved for usage within hypertext controls.  The schema for hypertext controls can be derived from this model:  HttpLink:\n  description: A base type of objects representing links to resources.\n  type: object\n  properties:\n    href:\n      description: Any URI that is using http or https protocol\n      type: string\n      format: uri\n  required: [ \"href\" ]\nThe name of an attribute holding such a HttpLink object specifies the relation between the object that contains the link and the linked resource. Implementations should use names from the IANA Link Relation Registry whenever appropriate. As IANA link relation names use hyphen-case notation, while this guide enforces snake_case notation for attribute names, hyphens in IANA names have to be replaced with underscores (e.g. the IANA link relation type version-history would become the attribute version_history)  Specific link objects may extend the basic link type with additional attributes, to give additional information related to the linked resource or the relationship between the source resource and the linked one.  E.g. a service providing \"Person\" resources could model a person who is married with some other person with a hypertext control that contains attributes which describe the other person (id, name) but also the relationship \"spouse\" between between the two persons (since):  {\n  \"id\": \"446f9876-e89b-12d3-a456-426655440000\",\n  \"name\": \"Peter Mustermann\",\n  \"spouse\": {\n    \"href\": \"https://...\",\n    \"since\": \"1996-12-19\",\n    \"id\": \"123e4567-e89b-12d3-a456-426655440000\",\n    \"name\": \"Linda Mustermann\"\n  }\n}\nHypertext controls are allowed anywhere within a JSON model. While this specification would allow HAL, we actually don't recommend/enforce the usage of HAL anymore as the structural separation of meta-data and data creates more harm than value to the understandability and usability of an API.", 
            "title": "MUST: Use Common Hypertext Controls"
        }, 
        {
            "location": "/hypermedia/#links-in-json-representations", 
            "text": "## What about attribute names?\n\nIn the previous section, we talked about formats - supporting multiple formats and working with JSON as the default.\n\nThis time, let s talk about what happens when a response comes back.\n\nYou have an object with data attributes on it. How should you name the attributes?\n\nHere are API responses from a few leading APIs:\n\nTwitter created_at :  Thu Nov 03 05:19;38 +0000 2011 \n\nBing DateTime :  2011-10-29T09:35:00Z \n\nFoursquare createdAt : 1320296464\n\nThey each use a different code convention. Although the Twitter approach is familiar to me as a Ruby on Rails developer, we think that Foursquare has the best approach.\n\nHow does the API response get back in the code? You parse the response (JSON parser); what comes back populates the Object. It looks like this\n\nvar myObject = JSON.parse(response);\n\nIf you chose the Twitter or Bing approach, your code looks like this. Its not JavaScript convention and looks weird - looks like the name of another object or class in the system, which is not correct.\n\ntiming = myObject.created_at;\n\ntiming - myObject.DateTime;\n\nRecommendations\n\n* Use JSON as default\n\n* Follow JavaScript conventions for naming attributes\n\n- Use medial capitalization (aka CamelCase)\n\n- Use uppercase or lowercase depending on type of object\n\nThis results in code that looks like the following, allowing the JavaScript developer to write it in a way that makes sense for JavaScript. createdAt : 1320296464\n\ntiming = myObject.createdAt;   DO  use a  link  property or a  links  property to include several links as an array whose value is a link object or a link object array.  DO  include  href  and  rel  properties in each link object   Examples:  { \n     link :   { \n         rel :   alternate , \n         href :   http://www.example.org/customers?format=json \n     }  }   { \n     link :   { \n         alternate :   http://www.example.org/customers?format=json \n     }  }   { \n     links :   [{ \n         rel :   alternate , \n         href :   http://www.example.org/customers?format=json \n     }, \n     { \n         rel :   http://www.example.org/rels/owner , \n         href :   ... \n     }]  }   { \n     links :   { \n         alternate :   http://www.example.org/customers?format=json \n         http://www.example.org/rels/owner :   http://www.example.org/owner \n     }  }", 
            "title": "Links in JSON Representations"
        }, 
        {
            "location": "/hypermedia/#link-header", 
            "text": "The  Link  header provides a format-independent means to convey links, which is one of the key benefits, along with visibility at the protocol level. Also the need for documentation on how to discover links in XML or JSON representations is lowered.  # Link header format\nLink:  {URI} ;rel= {relation} ;type= {media type };title= {title} ...   DO  use link header when you want to convey links in a format-independent manner  DO  use link header when a representation format does not support links. E.g.:  Binary format  Formats that do not allow for easy discovery of links (e.g., plain-text documents)  When your client/server software needs to add links or read links without parsing the body of representations", 
            "title": "Link Header"
        }, 
        {
            "location": "/hypermedia/#link-relation-types", 
            "text": "ALWAYS  supply a link relation to act as an identifier for the semantics associated with the link  ALWAYS  use URIs (such as  http://www.example.org/rels/create-po ) to express extended link relation types  DO  choose unambiguous value of link relations  DO  use one of the  standard relation types , when appropriate  DO  use lowercase for all link relation types  DO  use multiple values in link relations, if applicable  CONSIDER  providing an informational resource as an HTML document at that URI, describing the semantics of the link relation type. Include details such as HTTP methods supported, formats supported, and business rules about using the link.    Link relation types meant for public use should register that link relation per the process outlined in section 6.2 of the Web Linking Internet-Draft.", 
            "title": "Link Relation Types"
        }, 
        {
            "location": "/hypermedia/#managing-application-flow-with-links", 
            "text": "One of the key applications of hypermedia and links is the ability to decouple the client from learning about the rules the server uses to manage its application flow. The server can provide links containing application state, thereby using Hypermedia As The Engine Of Application State.  This prevents clients from having to learn and hard-code application flow, however, the mere presence of a link will not decouple the client from having to know how to prepare the data and make a request for the transition.   DO  design representations such that it contain links that help clients transition to all the next possible steps  DO  encode the state that needs to be carried forward in the links  DO  document how to find links and the semantics of all extended link relation types.  DO , for clients, assume that absent links means the transition is not possible.", 
            "title": "Managing Application Flow with Links"
        }, 
        {
            "location": "/hypermedia/#ephemeral-uris", 
            "text": "Does this belong in Resource Identifiers?  A URI may be temporary and valid only for a single use or may expire after a fixed period of time.   DO  communicate ephemeral URIs via links.  DO  assign extended relation types for those links and document how long such URIs are valid and what the client should do after expiry.  DO  return appropriate  4xx  code when responding to expired URIs, with an instructions in the body of any actions the client can take.", 
            "title": "Ephemeral URIs"
        }, 
        {
            "location": "/hypermedia/#uri-template", 
            "text": "When the server does not have all the information necessary to generate a valid and complete URI for each link.  A URI template is a string consisting of token marked off between matching braces ( {  and  } ). Clients substitute these tokens (including matching braces) with URI-safe strings to convert the template into a valid URI.  For simplicity limit the tokens to the following parts of URIs:   Path segments  Values of query parameters  Values of matrix parameters   To include URI templates in a representation:   DO  use  link-template  or  link-templates  properties to convey URI templates, for JSON representations.  DO  document the tokens used in you URI template, since URI templates are semi-opaque and contain tokens that clients need to substitute, and you need a way to tell clients what values are valid for each token.  CONSIDER  using braces ( {  and  } ) to specify replacement tokens, as this a common standard in a lot of other templating system (e.g., WSDL 2.0 and WADL.   //   JSON   representation  { \n     link-templates :   [{ \n         rel :   http://www.example.org/rels/customer , \n         href :   http://www.example.org/customer/{customer-id} \n     }]  }", 
            "title": "URI Template"
        }, 
        {
            "location": "/methods/", 
            "text": "HTTP Methods\n\n\nBefore discussing the individual HTTP methods here is some general advise:\n\n\n\n\nDO\n use HTTP methods correctly.\n\n\nDO\n stay consistent with the HTTP verb definitions.\n\n\nDO\n use \nCRUD\n for basic operations, as most developers will be familiar with this way of working with an API.\n\n\n\n\n\n\nCRUD\n\n\n\n\nC\nreate using \nPOST\n\n\nR\nead using \nGET\n\n\nU\npdate using \nPUT\n \n\n\nD\nelete using\nDELETE\n\n\n\n\n\n\nHTTP supports the following methods:\n\n\n\n\n\n\n\n\nMethod\n\n\nSafe\n\n\nIdempotent\n\n\n\n\n\n\n\n\n\n\nGET\n\n\nYes\n\n\nYes\n\n\n\n\n\n\nHEAD\n\n\nYes\n\n\nYes\n\n\n\n\n\n\nOPTIONS\n\n\nYes\n\n\nYes\n\n\n\n\n\n\nPUT\n\n\nNo\n\n\nYes\n\n\n\n\n\n\nDELETE\n\n\nNo\n\n\nYes\n\n\n\n\n\n\nPATCH\n\n\nNo\n\n\nNo\n\n\n\n\n\n\nPOST\n\n\nNo\n\n\nNo\n\n\n\n\n\n\n\n\nSafety and idempotency are guarantees a server must provide to clients.\n\n\n\n\nSafe methods\n\n\nSafe methods (or read-only operations) are expected not to cause side-effects, however, it does not mean the server must return the same response every time.\n\n\n\n\n\n\nIdempotent methods\n\n\nIdempotent methods must guarantee that every request has the same effect, however, this does not necessarily mean returning the same status code. This is highly important in case of failures.\n\n\n\n\nGET\n\n\n\n\nDO\n use \nGET\n to get a \nsafe\n and \nidempotent\n representation of a resource.\n\n\nDO\n use \nGET\n as the preferred method of requesting resources using URL encoded query parameter. When these become too extensive use \nPOST\n instead.\n\n\nDO\n use \nGET\n to read an individual resource or query a collection of resources.\n\n\nDO\n return \n404 Not Found\n if an individual resource or resource collection does not exist.\n\n\nCONSIDER\n returning \n200 Ok\n if the resource collection is empty, along with a representation of an empty collection.\n\n\nDO NOT\n add request body payload as these will be ignored, use \nPOST\n instead.\n\n\nDO NOT\n use \nGET\n for unsafe and nonidempotent operations, use \nPOST\n instead.\n\n\n\n\nHEAD\n\n\nHEAD requests are used to retrieve header information of resources, and has the exact same semantics as \nGET\n, but only returns headers. \n\n\n\n\nCONSIDER\n using \nHEAD\n to check whether a resource exists or get its metadata.\n\n\n\n\nOPTIONS\n\n\nOPTIONS\n is rarely implemented. Although \nOPTIONS\n could be used at runtime to discover methods supported by the resource, doing so is expensive. The method is not cacheable.\n\n\n\n\nDO\n return a comma separated list of methods in the \nAllow\n header. When a resource supports \nPATCH\n add an \nAccept-Patch\n header with the supported media types.\n\n\nDO\n use \nOPTIONS\n to get a list of available HTTP methods supported by a given resource.\n\n\nDO\n use \nOPTIONS\n to ping the server or find the supported HTTP version \nOPTIONS * HTTP/1.1\n\n\nCONSIDER\n adding a \nLink\n header containing a link to a human-readble document that describes the resource. This can be used to develop a browser plug-in to automatically show the documentation when you type the resource URI in the browser.\n\n\nAVOID\n relying on \nOPTIONS\n at runtime for discovery, instead use documentation and links to discover URIs and make requests.\n\n\n\n\nPUT\n\n\n\n\nDO\n use \nPUT\n to update an entire single resource. The operation implies that the entire resource located at the URI will be replaced with the new representation in the request.\n\n\nDO\n return \n200 Ok\n or \n204 No Content\n if the resource was updated.\n\n\nDO\n use a comibation of \nETag\n and \nIf-Match\n header for concurrency.\n\n\nDO\n return \n404 Not Found\n is \nPUT\n does not support creation.\n\n\nCONSIDER\n using \nPATCH\n if making partial updates to entire resources become increasingly cumbersome.\n\n\nCONSIDER\n before using \nPUT\n on a collection resources as it implies replacing the entire collection.\n\n\nDO NOT\n use \nPUT\n to create new resources unless the clients can decide URIs of resources (e.g., WebDAV), instead use \nPOST\n.\n\n\n\n\nDELETE\n\n\n\n\nDO\n use \nDELETE\n to delete a resource. Always return \n200 OK\n, however, it is impractical to keep track of all deleted resource, so a \n404 Not Found\n may be a viable alternative. Security policies may also require the server to return \n404 Not Found\n for any resource that does not currently exist.\n\n\nCONSIDER\n before using \nDELETE\n on a collection resources as it implies deleting the entire collection.\n\n\n\n\nPATCH\n\n\nIt is important to understand the difference between \nPUT\n and \nPATCH\n.\n\n\n\n\nPUT\n is designed to update/replace the entire resource. This means that omitted fields will be removed, which is rarely the desired effect.\n\n\nPATCH\n is designed to support partial updates. This means the request should supply a \nset of changes\n (or instructions) for updating a resource and these should be applied atomically, leaving any fields not passed along intact.\n\n\n\n\n\n\nWarning\n\n\nBe aware, even though \nPATCH\n has gain a lot of use, \nPATCH\n is only a proposed standard, and details around the semantics are not widely understood. It's not an alternative to \nPOST\n or \nPUT\n where you supply a flat list of values to change. Please see \nRFC-5789\n for more information.\n\n\n\n\n\n\nDO\n use \nPATCH\n for partial updates of a single resources, i.e. where only a specific subset of fields should be replaced.\n\n\nDO\n document the semantic of the \nPATCH\n changeset, as it is not defined in the HTTP standard.\n\n\nDO\n return \n200 Ok\n or \n204 No Content\n for successful \nPATCH\n requests.\n\n\nDO\n use a comibation of \nETag\n and \nIf-Match\n (and/or \nIf-Unmodified-Since\n) header for concurrency. Return \n412 Precondition Failed\n if the supplied preconditions do not match.\n\n\nDO\n include the \nContent-Location\n header along with the entire representation of the resource. If not, the client must issue an unconditional \nGET\n request to fetch the updated representation of the resource, along with fresh \nETag\n and/or \nIf-Unmodified-Since\n if applicable.\n\n\nDO\n include the latest \nLast-Modified\n and/or \nETag\n headers to support conditional requests.\n\n\nDO\n return \n415 Unsupported Media Type\n when the client sends a patch document format that the server does not support. Include the \nAccept-Patch\n header with the supported media types.\n\n\nDO\n return \n422 Unprocessable Entity\n when the server cannot honor the request because it might result in a bad state for the resource.\n\n\nCONSIDER\n using suitable media types to describe the changeset.\n\n\nCONSIDER\n using the lightweight JSON merge patch (RFC 7386) to describe changesets in JSON format.\n\n\nCONSIDER\n using the JSON Patch (RFC 6902) to describe changesets in JSON format.\n\n\nCONSIDER\n before using \nPATCH\n on a collection resources as it implies patching the entire collection.\n\n\nCONSIDER\n overloading \nPOST\n, not \nPUT\n, when \nPATCH\n is not an option.\n\n\nCONSIDER\n using \nPUT\n instead of \nPATCH\n, if possible, either to update the entire resource, or by designing a new resource to encapsulate the parts of the original resource that can be updated. \nSuch resources may seem inconsistent (or even polluting), but anything that is appropriate for retrival and updates is a candidate as a resource\n.\n\n\nCONSIDER\n advertising the support for \nPATCH\n via the \nAllow\n header of the \nOPTIONS\nresponse, also including an \nAccept-Patch\n header with the supported media types for the \nPATCH\n method.\n\n\nCONSIDER\n designing a specific format for each resource, to ensure that \nPATCH\n request only include valid combinations of changes.\n\n\nDO NOT\n repeat \nPATCH\n requests unless explicitly stated in the documentation.\n\n\n\n\nPOST\n\n\nPOST\n requests are most often used to create resources, by using a collection resource as a factory. However, \nPOST\n may also be used for other operations that fall outside the scope of the other methods. \n\n\n\n\nDO\n use \nPOST\n to create resources.\n\n\nDO\n use \nPOST\n to modify one or more resources.\n\n\nDO\n use \nPOST\n to for queries with large inputs.\n\n\nDO\n use \nPOST\n to perform any unsafe and nonidempotent operation, when no other HTTP method seems appropriate, and only as a last resort.\n\n\nAVOID\n passing data in query string along \nPOST\n request, use the body instead.\n\n\nAVOID\n using \nPOST\nfor tunneling, like SOAP.\n\n\nDO NOT\n use nonstandard custom HTTP methods. Instead, design a controller resource that can abstract such operations, and \nPOST\n.\n\n\n\n\nCreating Resources\n\n\nWhile it is valid to use either \nPUT\n or \nPOST\n to create new resources, the general consensus is that creating a new resource without knowing the final URI is a \nPOST\n operation (each call will yield a new resource). If the URI (or part of it) is known, use \nPUT\n, because successive calls will not create a new resource, as \nPUT\n is idempotent.\n\n\n\n\nDO\n return \n201 Created\n and a \nLocation\n header containing the URI of the newly created resource.\n\n\nCONSIDER\n returning the newly created resource representation in the response.\n\n\nCONSIDER\n include a \nContent-Location\n header containing the URI of the newly created resource, if the response body includes a complete representation of the newly created resource.\n\n\nCONSIDER\n including the \nLast-Modified\n and \nETag\n headers of the newly created resource for optimistic concurrency.\n\n\n\n\nLarge and Stored Queries\n\n\nSometimes it may be necessary to support queries with large inputs, and the query string may no longer be an option. For those cases:\n\n\n\n\nDO\n use \nPOST\n to support large queries, as a necessary trade-off to address a practical limitation, even though this is a misuse of the uniform interface, and a consequence is a loss of cacheability\n\n\nCONSIDER\n the fact tha pagination may also cause extra latency, since \nPOST\ns are not cached.\n\n\nCONSIDER\n using stored queries to improve cacheability and reuse across clients:\n\n\nDO\n create a new resource whose state contains the query criteria. Return \n201 Created\n and a \nLocation\n header referring to a resource created.\n\n\nDO\n implement a \nGET\n request for the new resource such that it returns query results.\n\n\nDO\n find the resource that matches the request, and redirect the client to the URI of that resource, if the same or another client repeats the same query request using \nPOST\n.\n\n\nDO\n support pagination via \nGET\n instead of \nPOST\n.\n\n\nCONSIDER\n the number of different queries and evaluate cache hit ratio, and whether named queries are a better option.\n\n\n\n\nAsynchronous Tasks\n\n\nTo enable asynchronous processing of request, follow these guidelines (these step are also valid for \nDELETE\n):\n\n\n\n\nDO\n use \nPOST\n to create and return a representation of a new \ntask\n resource, and return status code \n202 Accepted\n. The purpose of this resource is to let a client track the status of the asynchronous task. Design this resource such that its representation includes the current status of the request and related information such as a time estimate.\n\n\nDO\n use \nGET\n to return a representation of the task resource, depending of the current status:\n\n\nDO\n return \n200 Ok\n and a representation of the task resource with the current status, when \nstill processing\n (pending).\n\n\nDO\n return \n303 See Other\n and a \nLocation\n header containing a URI of a resource that shows the outcome of the task, once the task has \nsuccessfully completed\n.\n\n\nDO\n return \n200 Ok\n with a representation of the task resource informing that the resource creation has \nfailed\n. Clients will need to read the body of the representation to find the reason for failure.\n\n\n\n\nExample of \npending\nHTTP\n/\n1.1\n \n202\n \nAccepted\n\n\nContent-Type\n:\n \napplication/json\n\n\nContent-Location\n:\n \nhttps://www.example.org/images/task/1\n\n\n\n{\n\n    \nstate\n:\n \npending\n,\n\n    \nmessage\n:\n \nYour request is being processed shortly.\n,\n\n    \npingAfter\n:\n \n2009-09-13T01:59:27Z\n,\n\n    \nlink\n:\n \n{\n\n        \nhref\n:\n \nhttps://www.example.org/images/task/1\n,\n\n        \nrel\n:\n \nself\n\n    \n}\n\n\n}\n\n\n\n\nExample of \ndone\nHTTP\n/\n1.1\n \n303\n \nSee Other\n\n\nContent-Type\n:\n \napplication/json\n\n\nLocation\n:\n \nhttps://www.example.org/images/1\n\n\nContent-Location\n:\n \nhttps://www.example.org/images/task/1\n\n\n\n{\n\n    \nstate\n:\n \ndone\n,\n\n    \nmessage\n:\n \nYour request has been processed.\n,\n\n    \nlink\n:\n \n{\n\n        \nhref\n:\n \nhttps://www.example.org/images/task/1\n,\n\n        \nrel\n:\n \nself\n\n    \n}\n\n\n}\n\n\n\n\n\n\nNote\n\n\nThe \n303 See Other\n does not mean that the resource at the request URI has moved to a new location. It merely states that the result exists at the URI indicated in the \nLocation\n header.\n\n\n\n\nBatch Operations\n\n\n\n\nTBD\n\n\nMUST: Use 207 for Batch or Bulk Requests\n\n\nSome APIs are required to provide either batch or bulk requests using POST for performance reasons, i.e. for communication and processing efficiency. In this case services may be in need to signal multiple response codes for each part of an batch or bulk request. As HTTP does not provide proper guidance for handling batch/bulk requests and responses, we herewith define the following approach:\n\n\nA batch or bulk request always has to respond with HTTP status code 207, unless it encounters a generic or unexpected failure before looking at individual parts.\nA batch or bulk response with status code 207 always returns a multi-status object containing sufficient status and/or monitoring information for each part of the batch or bulk request.\nA batch or bulk request may result in a status code 400/500, only if the service encounters a failure before looking at individual parts or, if an unanticipated failure occurs.\nThe before rules apply even in the case that processing of all individual part fail or each part is executed asynchronously! They are intended to allow clients to act on batch and bulk responses by inspecting the individual results in a consistent way.\n\n\n\n\nNote: while a batch defines a collection of requests triggering independent processes, a bulk defines a collection of independent resources created or updated together in one request. With respect to response processing this distinction normally does not matter.", 
            "title": "Methods"
        }, 
        {
            "location": "/methods/#http-methods", 
            "text": "Before discussing the individual HTTP methods here is some general advise:   DO  use HTTP methods correctly.  DO  stay consistent with the HTTP verb definitions.  DO  use  CRUD  for basic operations, as most developers will be familiar with this way of working with an API.    CRUD   C reate using  POST  R ead using  GET  U pdate using  PUT    D elete using DELETE    HTTP supports the following methods:     Method  Safe  Idempotent      GET  Yes  Yes    HEAD  Yes  Yes    OPTIONS  Yes  Yes    PUT  No  Yes    DELETE  No  Yes    PATCH  No  No    POST  No  No     Safety and idempotency are guarantees a server must provide to clients.   Safe methods  Safe methods (or read-only operations) are expected not to cause side-effects, however, it does not mean the server must return the same response every time.    Idempotent methods  Idempotent methods must guarantee that every request has the same effect, however, this does not necessarily mean returning the same status code. This is highly important in case of failures.", 
            "title": "HTTP Methods"
        }, 
        {
            "location": "/methods/#get", 
            "text": "DO  use  GET  to get a  safe  and  idempotent  representation of a resource.  DO  use  GET  as the preferred method of requesting resources using URL encoded query parameter. When these become too extensive use  POST  instead.  DO  use  GET  to read an individual resource or query a collection of resources.  DO  return  404 Not Found  if an individual resource or resource collection does not exist.  CONSIDER  returning  200 Ok  if the resource collection is empty, along with a representation of an empty collection.  DO NOT  add request body payload as these will be ignored, use  POST  instead.  DO NOT  use  GET  for unsafe and nonidempotent operations, use  POST  instead.", 
            "title": "GET"
        }, 
        {
            "location": "/methods/#head", 
            "text": "HEAD requests are used to retrieve header information of resources, and has the exact same semantics as  GET , but only returns headers.    CONSIDER  using  HEAD  to check whether a resource exists or get its metadata.", 
            "title": "HEAD"
        }, 
        {
            "location": "/methods/#options", 
            "text": "OPTIONS  is rarely implemented. Although  OPTIONS  could be used at runtime to discover methods supported by the resource, doing so is expensive. The method is not cacheable.   DO  return a comma separated list of methods in the  Allow  header. When a resource supports  PATCH  add an  Accept-Patch  header with the supported media types.  DO  use  OPTIONS  to get a list of available HTTP methods supported by a given resource.  DO  use  OPTIONS  to ping the server or find the supported HTTP version  OPTIONS * HTTP/1.1  CONSIDER  adding a  Link  header containing a link to a human-readble document that describes the resource. This can be used to develop a browser plug-in to automatically show the documentation when you type the resource URI in the browser.  AVOID  relying on  OPTIONS  at runtime for discovery, instead use documentation and links to discover URIs and make requests.", 
            "title": "OPTIONS"
        }, 
        {
            "location": "/methods/#put", 
            "text": "DO  use  PUT  to update an entire single resource. The operation implies that the entire resource located at the URI will be replaced with the new representation in the request.  DO  return  200 Ok  or  204 No Content  if the resource was updated.  DO  use a comibation of  ETag  and  If-Match  header for concurrency.  DO  return  404 Not Found  is  PUT  does not support creation.  CONSIDER  using  PATCH  if making partial updates to entire resources become increasingly cumbersome.  CONSIDER  before using  PUT  on a collection resources as it implies replacing the entire collection.  DO NOT  use  PUT  to create new resources unless the clients can decide URIs of resources (e.g., WebDAV), instead use  POST .", 
            "title": "PUT"
        }, 
        {
            "location": "/methods/#delete", 
            "text": "DO  use  DELETE  to delete a resource. Always return  200 OK , however, it is impractical to keep track of all deleted resource, so a  404 Not Found  may be a viable alternative. Security policies may also require the server to return  404 Not Found  for any resource that does not currently exist.  CONSIDER  before using  DELETE  on a collection resources as it implies deleting the entire collection.", 
            "title": "DELETE"
        }, 
        {
            "location": "/methods/#patch", 
            "text": "It is important to understand the difference between  PUT  and  PATCH .   PUT  is designed to update/replace the entire resource. This means that omitted fields will be removed, which is rarely the desired effect.  PATCH  is designed to support partial updates. This means the request should supply a  set of changes  (or instructions) for updating a resource and these should be applied atomically, leaving any fields not passed along intact.    Warning  Be aware, even though  PATCH  has gain a lot of use,  PATCH  is only a proposed standard, and details around the semantics are not widely understood. It's not an alternative to  POST  or  PUT  where you supply a flat list of values to change. Please see  RFC-5789  for more information.    DO  use  PATCH  for partial updates of a single resources, i.e. where only a specific subset of fields should be replaced.  DO  document the semantic of the  PATCH  changeset, as it is not defined in the HTTP standard.  DO  return  200 Ok  or  204 No Content  for successful  PATCH  requests.  DO  use a comibation of  ETag  and  If-Match  (and/or  If-Unmodified-Since ) header for concurrency. Return  412 Precondition Failed  if the supplied preconditions do not match.  DO  include the  Content-Location  header along with the entire representation of the resource. If not, the client must issue an unconditional  GET  request to fetch the updated representation of the resource, along with fresh  ETag  and/or  If-Unmodified-Since  if applicable.  DO  include the latest  Last-Modified  and/or  ETag  headers to support conditional requests.  DO  return  415 Unsupported Media Type  when the client sends a patch document format that the server does not support. Include the  Accept-Patch  header with the supported media types.  DO  return  422 Unprocessable Entity  when the server cannot honor the request because it might result in a bad state for the resource.  CONSIDER  using suitable media types to describe the changeset.  CONSIDER  using the lightweight JSON merge patch (RFC 7386) to describe changesets in JSON format.  CONSIDER  using the JSON Patch (RFC 6902) to describe changesets in JSON format.  CONSIDER  before using  PATCH  on a collection resources as it implies patching the entire collection.  CONSIDER  overloading  POST , not  PUT , when  PATCH  is not an option.  CONSIDER  using  PUT  instead of  PATCH , if possible, either to update the entire resource, or by designing a new resource to encapsulate the parts of the original resource that can be updated.  Such resources may seem inconsistent (or even polluting), but anything that is appropriate for retrival and updates is a candidate as a resource .  CONSIDER  advertising the support for  PATCH  via the  Allow  header of the  OPTIONS response, also including an  Accept-Patch  header with the supported media types for the  PATCH  method.  CONSIDER  designing a specific format for each resource, to ensure that  PATCH  request only include valid combinations of changes.  DO NOT  repeat  PATCH  requests unless explicitly stated in the documentation.", 
            "title": "PATCH"
        }, 
        {
            "location": "/methods/#post", 
            "text": "POST  requests are most often used to create resources, by using a collection resource as a factory. However,  POST  may also be used for other operations that fall outside the scope of the other methods.    DO  use  POST  to create resources.  DO  use  POST  to modify one or more resources.  DO  use  POST  to for queries with large inputs.  DO  use  POST  to perform any unsafe and nonidempotent operation, when no other HTTP method seems appropriate, and only as a last resort.  AVOID  passing data in query string along  POST  request, use the body instead.  AVOID  using  POST for tunneling, like SOAP.  DO NOT  use nonstandard custom HTTP methods. Instead, design a controller resource that can abstract such operations, and  POST .", 
            "title": "POST"
        }, 
        {
            "location": "/methods/#creating-resources", 
            "text": "While it is valid to use either  PUT  or  POST  to create new resources, the general consensus is that creating a new resource without knowing the final URI is a  POST  operation (each call will yield a new resource). If the URI (or part of it) is known, use  PUT , because successive calls will not create a new resource, as  PUT  is idempotent.   DO  return  201 Created  and a  Location  header containing the URI of the newly created resource.  CONSIDER  returning the newly created resource representation in the response.  CONSIDER  include a  Content-Location  header containing the URI of the newly created resource, if the response body includes a complete representation of the newly created resource.  CONSIDER  including the  Last-Modified  and  ETag  headers of the newly created resource for optimistic concurrency.", 
            "title": "Creating Resources"
        }, 
        {
            "location": "/methods/#large-and-stored-queries", 
            "text": "Sometimes it may be necessary to support queries with large inputs, and the query string may no longer be an option. For those cases:   DO  use  POST  to support large queries, as a necessary trade-off to address a practical limitation, even though this is a misuse of the uniform interface, and a consequence is a loss of cacheability  CONSIDER  the fact tha pagination may also cause extra latency, since  POST s are not cached.  CONSIDER  using stored queries to improve cacheability and reuse across clients:  DO  create a new resource whose state contains the query criteria. Return  201 Created  and a  Location  header referring to a resource created.  DO  implement a  GET  request for the new resource such that it returns query results.  DO  find the resource that matches the request, and redirect the client to the URI of that resource, if the same or another client repeats the same query request using  POST .  DO  support pagination via  GET  instead of  POST .  CONSIDER  the number of different queries and evaluate cache hit ratio, and whether named queries are a better option.", 
            "title": "Large and Stored Queries"
        }, 
        {
            "location": "/methods/#asynchronous-tasks", 
            "text": "To enable asynchronous processing of request, follow these guidelines (these step are also valid for  DELETE ):   DO  use  POST  to create and return a representation of a new  task  resource, and return status code  202 Accepted . The purpose of this resource is to let a client track the status of the asynchronous task. Design this resource such that its representation includes the current status of the request and related information such as a time estimate.  DO  use  GET  to return a representation of the task resource, depending of the current status:  DO  return  200 Ok  and a representation of the task resource with the current status, when  still processing  (pending).  DO  return  303 See Other  and a  Location  header containing a URI of a resource that shows the outcome of the task, once the task has  successfully completed .  DO  return  200 Ok  with a representation of the task resource informing that the resource creation has  failed . Clients will need to read the body of the representation to find the reason for failure.   Example of  pending HTTP / 1.1   202   Accepted  Content-Type :   application/json  Content-Location :   https://www.example.org/images/task/1  { \n     state :   pending , \n     message :   Your request is being processed shortly. , \n     pingAfter :   2009-09-13T01:59:27Z , \n     link :   { \n         href :   https://www.example.org/images/task/1 , \n         rel :   self \n     }  }   Example of  done HTTP / 1.1   303   See Other  Content-Type :   application/json  Location :   https://www.example.org/images/1  Content-Location :   https://www.example.org/images/task/1  { \n     state :   done , \n     message :   Your request has been processed. , \n     link :   { \n         href :   https://www.example.org/images/task/1 , \n         rel :   self \n     }  }    Note  The  303 See Other  does not mean that the resource at the request URI has moved to a new location. It merely states that the result exists at the URI indicated in the  Location  header.", 
            "title": "Asynchronous Tasks"
        }, 
        {
            "location": "/methods/#batch-operations", 
            "text": "TBD", 
            "title": "Batch Operations"
        }, 
        {
            "location": "/methods/#must-use-207-for-batch-or-bulk-requests", 
            "text": "Some APIs are required to provide either batch or bulk requests using POST for performance reasons, i.e. for communication and processing efficiency. In this case services may be in need to signal multiple response codes for each part of an batch or bulk request. As HTTP does not provide proper guidance for handling batch/bulk requests and responses, we herewith define the following approach:  A batch or bulk request always has to respond with HTTP status code 207, unless it encounters a generic or unexpected failure before looking at individual parts.\nA batch or bulk response with status code 207 always returns a multi-status object containing sufficient status and/or monitoring information for each part of the batch or bulk request.\nA batch or bulk request may result in a status code 400/500, only if the service encounters a failure before looking at individual parts or, if an unanticipated failure occurs.\nThe before rules apply even in the case that processing of all individual part fail or each part is executed asynchronously! They are intended to allow clients to act on batch and bulk responses by inspecting the individual results in a consistent way.   Note: while a batch defines a collection of requests triggering independent processes, a bulk defines a collection of independent resources created or updated together in one request. With respect to response processing this distinction normally does not matter.", 
            "title": "MUST: Use 207 for Batch or Bulk Requests"
        }, 
        {
            "location": "/mocking/", 
            "text": "Mocking\n\n\nMock Your API and get User Feedback\n\n\nAnother huge advantage of tools like RAML or Swagger is that they allow you to mock your API.\n\n\nThis means that you can not only build your API in a visual interface and take advantage of the very same best practices we utilize in development, but you can also share a mock version of your API with potential clients.\nUsing MuleSoft's API Designer you can easily turn on a mocking service that gives you a URL that can be shared with other developers.\n\n\nThis allows your clients to \"test out\" your API by making real calls as if they would from their application.\n\n\nBy utilizing the example responses defined in the RAML file developers can quickly identify issues and inconsistencies, helping you eliminate the majority of design related issues before development even starts.\n\n\nAnd by passing along tools like the API Notebook, developers can interact with your Mock API through JavaScript without having to code any calls themselves, and also having the ability to send you the specific use case back giving you true examples of what your developers are trying to accomplish.\n\n\nThis process can be repeated as necessary, as modifying the spec and creating a new mock only takes minutes, empowering you to perfect the design of your API and ensure that it not only meets your developers' needs, but also provides a solid, strong foundation for the future of your API.\nAfter all, the nemesis of a long-lived API is not the code, nor the system architecture, but the API design itself.\n\n\nNo matter how careful you are with your API, without a solid foundation it will crumble quickly, costing you thousands to hundreds of thousands of dollars down the road.\n\n\nIt's better to take the time now, up front and ensure that your API is well designed.\n\n\n\n\n\n\ntesting api\u2019s\n\n\nautomated in-memory integration tests (with live dependencies stubed out)\n\n\nImplement a \u201cHealth-Check\u201d Endpoint", 
            "title": "Mocking"
        }, 
        {
            "location": "/mocking/#mocking", 
            "text": "Mock Your API and get User Feedback  Another huge advantage of tools like RAML or Swagger is that they allow you to mock your API.  This means that you can not only build your API in a visual interface and take advantage of the very same best practices we utilize in development, but you can also share a mock version of your API with potential clients.\nUsing MuleSoft's API Designer you can easily turn on a mocking service that gives you a URL that can be shared with other developers.  This allows your clients to \"test out\" your API by making real calls as if they would from their application.  By utilizing the example responses defined in the RAML file developers can quickly identify issues and inconsistencies, helping you eliminate the majority of design related issues before development even starts.  And by passing along tools like the API Notebook, developers can interact with your Mock API through JavaScript without having to code any calls themselves, and also having the ability to send you the specific use case back giving you true examples of what your developers are trying to accomplish.  This process can be repeated as necessary, as modifying the spec and creating a new mock only takes minutes, empowering you to perfect the design of your API and ensure that it not only meets your developers' needs, but also provides a solid, strong foundation for the future of your API.\nAfter all, the nemesis of a long-lived API is not the code, nor the system architecture, but the API design itself.  No matter how careful you are with your API, without a solid foundation it will crumble quickly, costing you thousands to hundreds of thousands of dollars down the road.  It's better to take the time now, up front and ensure that your API is well designed.    testing api\u2019s  automated in-memory integration tests (with live dependencies stubed out)  Implement a \u201cHealth-Check\u201d Endpoint", 
            "title": "Mocking"
        }, 
        {
            "location": "/references/", 
            "text": "References\n\n\nBibliography\n\n\n\n\nAllamaraju, S. (2010). RESTful web services cookbook: Solutions for improving scalability and simplicity. Yahoo Press.\n\n\nBiehl, M. (2016). RESTful API Design: APIs your customers will love. API-University Press.\n\n\nSturgeon, P. (2016). Build APIs You Wont Hate. Leanpub\n\n\nWebber J., Parastatidis S., Robinson I. (2010). REST in Practice: Hypermedia and Systems Architecture. O'Reilly Media\n\n\n\n\nAPI Design\n\n\n\n\nAPI Design Guide\n\n\nAPI Strategy 301: API-as-a-Product\n\n\nAPIs as a product\n\n\nCharacteristics of Good APIs\n\n\nDogfooding: how to build a great API\n\n\nDriving Architectural Simplicity - The Value, Challenge, and Practice of Simple Solutions\n\n\nNew Series: API Design Best Practices\n\n\nSigns you're veering from good API design\n\n\nThe 5 laws of API dates and times\n\n\nWeb API Design - Crafting Interfaces that Developers Love\n\n\nWhat Is an API?\n\n\n\n\nAPI First\n\n\n\n\nConsumer-Driven Contracts: A Service Evolution Pattern\n\n\nHow to Scale Your API Design Process with OpenAPI\n\n\nIntro to RAML - The RESTful API Modeling Language\n\n\nOpen API and RAML: Better Together\n\n\nOpenAPI code generators for Visual Studio\n\n\nPlanning Your API Strategy for 2018: Tools and Resources to Set Your Team Up for Success\n\n\nSimplify RAML with Resource Types and Traits\n\n\nSwagger is now the OpenAPI Specification\n\n\nWhat Is the Difference Between Swagger and OpenAPI?\n\n\nWriting OpenAPI (Swagger) Specification Tutorial - Part 8 - Splitting specification file\u00df\n\n\n\n\nDocumentation\n\n\n\n\nGenerate beautiful Swagger API documentation from Insomnia\n\n\nGenerate C# API Documentation with Wyam\n\n\nGitHub - lord/slate: Beautiful static documentation for your API\n\n\nTen Extras for Great API Documentation\n\n\nThe data, the hypermedia and the documentation\n\n\nThe Easiest Ways to Generate API Documentation\n\n\nThe Ten Essentials for Good API Documentation\n\n\nThe Utopia of API Documentation\n\n\nUltimate Guide to 30+ API Documentation Solutions\n\n\nWhat nobody tells you about documentation\n\n\nWhich tool to choose for API docs\n\n\n\n\nError\n\n\n\n\nApigility\n\n\nproblem/problem/src/main/java/org/zalando/problem at master \u00b7 zalando/problem\n\n\n\n\nGraphQL and Queries\n\n\n\n\n...And GraphQL for all? A few things to think about before blindly dumping REST for GraphQL\n\n\nClient-directed query\n\n\nIs using OData\\IQueryable in your Web API an inherently bad thing?\n\n\nSo what\u2019s this GraphQL thing I keep hearing about?\n\n\nYou Might Not Need GraphQL\n\n\n\n\nHTTP\n\n\n\n\nHTTP headers\n\n\n\n\nHypermedia\n\n\n\n\nHackable URIs may look nice, but they don\u2019t have much to do with REST and HATEOAS\n\n\nHypermedia\n\n\nkevinswiber/siren: Structured Interface for Representing Entities, super-rad hypermedia\n\n\nREST: From GET to HATEOAS\n\n\nSelf Descriptive HTTP API in ASP.NET Core: HATEOAS\n\n\nSelf Descriptive HTTP API in ASP.NET Core: Hypermedia\n\n\nSelf Descriptive HTTP API in ASP.NET Core: Siren\n\n\nWhat is the RESTed NARWHL?\n\n\n\n\nREST\n\n\n\n\nAnemic REST\n\n\nAPI Design Tips And Tricks - Getting, creating, updating or deleting multiple resources in one API call\n\n\nBest Practices for Designing a Pragmatic RESTful API\n\n\nChoosing an HTTP Status Code \u2014 Stop Making It Hard\n\n\nDDD \n REST - Domain Driven APIs for the web\n\n\nEvolving API Pagination at Slack\n\n\nFielding Dissertation: CHAPTER 5: Representational State Transfer (REST)\n\n\nFive RESTFul Web Design Patterns Implemented in ASP.NET Core 2.0 Part 1: Content Negotiation\n\n\nIs Proliferation Of Custom Media Types RESTFul?\n\n\nNobody Understands REST or HTTP\n\n\nPUT or POST: The REST of the Story\n\n\nREST API Design - Resource Modeling\n\n\nREST API Tutorial\n\n\nREST Architectural constraints\n\n\nREST Beyond the Obvious \u2013 API design for ever evolving systems\n\n\nREST efficiency\n\n\nRESTful API Design Tips from Experience\n\n\nRESTful APIs - An accurate description\n\n\nRESTful Resource Naming\n\n\nThe RESTafarian flame wars \u2013 common disagreements over REST API design\n\n\nThoughts on RESTful API Design\n\n\nTop REST API best practices\n\n\nTurning Up The Good On REST APIs\n\n\nWhy REST is not a silver bullet for service integration\n\n\nZalando RESTful API and Event Scheme Guidelines\n\n\n\n\nSecurity\n\n\n\n\nAPI Keys \u2260 Security: Why API Keys Are Not Enough\n\n\nAPI Keys vs OAuth Tokens vs JSON Web Tokens\n\n\nStrict-Transport-Security\n\n\nThe Basics of Web Application Security\n\n\nUsing JSON Web Tokens as API Keys\n\n\n\n\nTracing\n\n\n\n\nA consistent approach to track correlation IDs through microservices\n\n\n\n\nURI\n\n\n\n\nOpaque URIs != Unreadable URIs\n\n\nThe Opacity Axiom\n\n\n\n\nVersioning\n\n\n\n\nRESTFul API Versioning Insights\n\n\nTroy Hunt: Your API versioning is wrong, which is why I decided to do it 3 different wrong ways\n\n\nVersioning RESTful Services\n\n\nVersioning URIs", 
            "title": "References"
        }, 
        {
            "location": "/references/#references", 
            "text": "", 
            "title": "References"
        }, 
        {
            "location": "/references/#bibliography", 
            "text": "Allamaraju, S. (2010). RESTful web services cookbook: Solutions for improving scalability and simplicity. Yahoo Press.  Biehl, M. (2016). RESTful API Design: APIs your customers will love. API-University Press.  Sturgeon, P. (2016). Build APIs You Wont Hate. Leanpub  Webber J., Parastatidis S., Robinson I. (2010). REST in Practice: Hypermedia and Systems Architecture. O'Reilly Media", 
            "title": "Bibliography"
        }, 
        {
            "location": "/references/#api-design", 
            "text": "API Design Guide  API Strategy 301: API-as-a-Product  APIs as a product  Characteristics of Good APIs  Dogfooding: how to build a great API  Driving Architectural Simplicity - The Value, Challenge, and Practice of Simple Solutions  New Series: API Design Best Practices  Signs you're veering from good API design  The 5 laws of API dates and times  Web API Design - Crafting Interfaces that Developers Love  What Is an API?", 
            "title": "API Design"
        }, 
        {
            "location": "/references/#api-first", 
            "text": "Consumer-Driven Contracts: A Service Evolution Pattern  How to Scale Your API Design Process with OpenAPI  Intro to RAML - The RESTful API Modeling Language  Open API and RAML: Better Together  OpenAPI code generators for Visual Studio  Planning Your API Strategy for 2018: Tools and Resources to Set Your Team Up for Success  Simplify RAML with Resource Types and Traits  Swagger is now the OpenAPI Specification  What Is the Difference Between Swagger and OpenAPI?  Writing OpenAPI (Swagger) Specification Tutorial - Part 8 - Splitting specification file\u00df", 
            "title": "API First"
        }, 
        {
            "location": "/references/#documentation", 
            "text": "Generate beautiful Swagger API documentation from Insomnia  Generate C# API Documentation with Wyam  GitHub - lord/slate: Beautiful static documentation for your API  Ten Extras for Great API Documentation  The data, the hypermedia and the documentation  The Easiest Ways to Generate API Documentation  The Ten Essentials for Good API Documentation  The Utopia of API Documentation  Ultimate Guide to 30+ API Documentation Solutions  What nobody tells you about documentation  Which tool to choose for API docs", 
            "title": "Documentation"
        }, 
        {
            "location": "/references/#error", 
            "text": "Apigility  problem/problem/src/main/java/org/zalando/problem at master \u00b7 zalando/problem", 
            "title": "Error"
        }, 
        {
            "location": "/references/#graphql-and-queries", 
            "text": "...And GraphQL for all? A few things to think about before blindly dumping REST for GraphQL  Client-directed query  Is using OData\\IQueryable in your Web API an inherently bad thing?  So what\u2019s this GraphQL thing I keep hearing about?  You Might Not Need GraphQL", 
            "title": "GraphQL and Queries"
        }, 
        {
            "location": "/references/#http", 
            "text": "HTTP headers", 
            "title": "HTTP"
        }, 
        {
            "location": "/references/#hypermedia", 
            "text": "Hackable URIs may look nice, but they don\u2019t have much to do with REST and HATEOAS  Hypermedia  kevinswiber/siren: Structured Interface for Representing Entities, super-rad hypermedia  REST: From GET to HATEOAS  Self Descriptive HTTP API in ASP.NET Core: HATEOAS  Self Descriptive HTTP API in ASP.NET Core: Hypermedia  Self Descriptive HTTP API in ASP.NET Core: Siren  What is the RESTed NARWHL?", 
            "title": "Hypermedia"
        }, 
        {
            "location": "/references/#rest", 
            "text": "Anemic REST  API Design Tips And Tricks - Getting, creating, updating or deleting multiple resources in one API call  Best Practices for Designing a Pragmatic RESTful API  Choosing an HTTP Status Code \u2014 Stop Making It Hard  DDD   REST - Domain Driven APIs for the web  Evolving API Pagination at Slack  Fielding Dissertation: CHAPTER 5: Representational State Transfer (REST)  Five RESTFul Web Design Patterns Implemented in ASP.NET Core 2.0 Part 1: Content Negotiation  Is Proliferation Of Custom Media Types RESTFul?  Nobody Understands REST or HTTP  PUT or POST: The REST of the Story  REST API Design - Resource Modeling  REST API Tutorial  REST Architectural constraints  REST Beyond the Obvious \u2013 API design for ever evolving systems  REST efficiency  RESTful API Design Tips from Experience  RESTful APIs - An accurate description  RESTful Resource Naming  The RESTafarian flame wars \u2013 common disagreements over REST API design  Thoughts on RESTful API Design  Top REST API best practices  Turning Up The Good On REST APIs  Why REST is not a silver bullet for service integration  Zalando RESTful API and Event Scheme Guidelines", 
            "title": "REST"
        }, 
        {
            "location": "/references/#security", 
            "text": "API Keys \u2260 Security: Why API Keys Are Not Enough  API Keys vs OAuth Tokens vs JSON Web Tokens  Strict-Transport-Security  The Basics of Web Application Security  Using JSON Web Tokens as API Keys", 
            "title": "Security"
        }, 
        {
            "location": "/references/#tracing", 
            "text": "A consistent approach to track correlation IDs through microservices", 
            "title": "Tracing"
        }, 
        {
            "location": "/references/#uri", 
            "text": "Opaque URIs != Unreadable URIs  The Opacity Axiom", 
            "title": "URI"
        }, 
        {
            "location": "/references/#versioning", 
            "text": "RESTFul API Versioning Insights  Troy Hunt: Your API versioning is wrong, which is why I decided to do it 3 different wrong ways  Versioning RESTful Services  Versioning URIs", 
            "title": "Versioning"
        }, 
        {
            "location": "/representations/", 
            "text": "Representations\n\n\nA \nrepresentation\n (request/response) is concrete and real. Here we will offer guidelines as to what makes a good response design. To ensure scalability and longevity of the API, along with providing helpful responses that developers can understand and trust, we will cover what HTTP headers are appropriate in a response, which HTTP status codes to return, as well as how to include descriptive error representations on failures.\n\n\n\n\nBandwidth\n\n\nIt might be pertinent to support techniques for reducing bandwidth based on client needs. This is especially true for APIs that have large payloads and/or are used in high-traffic scenarios. Supporting mobile clients with less bandwidth connectivity, would be one such case.\n\n\nTo reduce bandwidth and improve responsiveness consider:\n\n\n\n\nCompression using \nContent-Encoding\n.\n\n\nPartial responses\n using query parameters.\n\n\nDividing the size of the payload using \nPagination\n.\n\n\nETag\n and \nIf-Modified-Since\n/\nIf-None-Match\n for \nCaching\n.\n\n\nUsing \nBatch Operations\n.\n\n\n\n\nAll these common techniques are discussed in details elsewhere in these guidelines.\n\n\n\n\nHTTP Headers\n\n\nHeaders ensure visibility, discoverability, routing by proxies, caching, optimistic concurrency, and correct operation of HTTP as an application protocol.\n\n\nUse the following headers to annotate representations that contains a message body.\n\n\nContent-Type\n\n\nEven though it is perfectly acceptable to use only a single format, in order to keep the API flexible and extendable, it is also important to build for the future. Until recently XML was the format of choice, but then along came JSON.\n\n\n\n\nDO\n use \nContent-Type\n, to describe the type of representation, including a \ncharset\n parameter or other parameters defined for that media type.\n\n\nDO\n include the \ncharset\n parameter, if the media type supports it, with a value of the character encoding used to convert characters into bytes.\n\n\nDO\n use the specified encoding, when you receive a representation with a media type that supports the \ncharset\nparameter.\n\n\nDO\n let your parser interpret the character set, if you receive an XML representation with a missing \ncharset\n parameter.\n\n\nAVOID\n using the \ntext/xml\n media type for XML-formatted representations. The default charset for \ntext/xml\n is \nus-ascii\n, whereas \napplication/xml\n uses \nUTF-8\n.\n\n\n\n\n\n\nTip\n\n\nNote that Text and XML media types let you specify the character encoding. The JSON media type \napplication/json\n does not specify a \ncharset\n parameter, but uses \nUTF-8\n as the default encoding.\n\n\n\n\nContent-Length\n\n\n\n\nDO\n use \nContent-Length\n, to specify the size in bytes of the body. Or specify \nTransfer-Encoding: chunked\n. Some proxies reject \nPOST\n and \nPUT\n requests that contain neither of these headers.\n\n\n\n\nContent-Language\n\n\n\n\nDO\n use \nContent-Language\n, two-letter RFC 5646 language tag, optionally followed by a hyphen (-) and any two-letter country code.\n\n\n\n\nContent-Encoding\n\n\n\n\nDO\n use \nContent-Encoding\n. Clients can indicate their preference for \nContent-Encoding\n using the \nAccept-Encoding\n header, however, there is no standard way for the client to learn whether a server can process representations compressed in a given encoding.\n\n\n\n\nOther Common Headers\n\n\n\n\nCONSIDER\n using \nETag\n and/or \nLast-Modified\n for caching and/or concurrency, the latter applies for responses only.\n\n\nCONSIDER\n using \nContent-MD5\n, when sending or receiving large representations over potentially unreliable networks to verify the integrity of the message.\n\n\nDO NOT\n use \nContent-MD5\n as any measure of security.\n\n\n\n\nCustom HTTP Headers\n\n\n\n\nWarning\n\n\nGenerally custom HTTP headers should be avoided, as they may impede interoperability. We discourage the use of hop-by-hop custom HTTP headers.\n\n\n\n\nHowever, depending on what clients and servers use custom headers for, they can be useful in cases where context information needs to be passed through multiple services in an end-to-end fashion. \n\n\n\n\nDO\n use custom headers for informational purposes.\n\n\nCONSIDER\n using the convention \nX-{company-name}-{header-name}\n, when introducing custom headers, as there is no established convention for naming custom headers. Avoid camelCase (without hyphens). Exceptions are common abbreviations like \nID\n. \nthe usage of X- headers is deprecated (RFC-6648)\n\n\nCONSIDER\n including the information in a custom HTTP header in the body or the URI, if the information is important for the correct interpretation of the request\n\n\nDO NOT\n implement clients and servers such that they fail when they do not find expected custom headers.\n\n\nDO NOT\n use custom HTTP headers to change behavior of HTTP methods, and limit any behavior-changing headers to \nPOST\n.\n\n\nDO NOT\n use \nX-HTTP-Method-Override\n to override \nPOST\n, use a distinct resource to process the same request using \nPOST\n without the header. Any HTTP intermediary between the client and the server may omit custom headers.\n\n\n\n\nEnd-To-End HTTP Headers\n\n\n\n\nDO\n use the specified end-to-end HTTP headers.\n\n\nDO\n propagate the end-to-end HTTP headers to upstream servers. Header names and values must remain intact.\n\n\n\n\n\n\nThe following may be candidates for end-to-end HTTP headers\n\n\n\n\nCorrelation ID of the request, which is written into the logs and passed to upstream services. \n\n\nGeneric user id that owns the passed (OAuth2) access token. May save additional token validation round trips\n\n\nSales channel\n\n\nDevice type, OS, and version\n\n\nApp version, etc.\n\n\n\n\n\n\nFormat and a Media Type\n\n\nHTTP's message format is designed to allow different media types and formats for requests and responses.\n\n\nWhen it comes to format and media type selection, the rule of thumb is to let the use cases and the types of clients dictate the choice. For this reason, it is important not to pick up a development framework that rigidly enforces one or two formats for all resource with no flexibility to use other formats.\n\n\n\n\nDO\n determine whether there is a standard format and media type that matches your use cases. Check IANA \n1\n.\n\n\nDO\n use extensible formats such as XML, Atom Syndication Format, or JSON, if there is no standard media type and format.\n\n\nCONSIDER\n adding a \nContent-Disposition: attachment; filename=\nstatus.xls\n to give a hint of the filename, when using image formats like \nimage/png\n or rich document formats like \napplication/vnd.ms-excel\n or \napplication/pdf\n to provide alternative representations of data.\n\n\n\n\nIf you choose to create new media types of your own, consider:\n\n\n\n\nDO\n use a sub-type that ends with \n+xml\n in the \nContent-Type\n header, when using XML\n\n\nDO\n use a sub-type starting with \nvnd\n (\napplication/vnd.example.org.user+xml\n), when the media type is for private use,\n\n\nDO\n register your media type with IANA as per RFC 4288, if the media type is for public use,\n\n\nAVOID\n introducing new application-specific media types unless they are expected to be broadly used, as this may impede interoperability.\n\n\n\n\n\n\nWarning\n\n\nAlthough custom media types improve protocol-level visibility, existing protocol-level tools for monitoring, filtering, or routing HTTP traffic pay little or no attention to media types. Hence, using custom media types only for the sake of protocol-level visibility is not necessary.\n\n\n\n\nPortable Data Formats\n\n\n\n\nDO\n use decimal, float and double data types defined in the W3C XML Schema for formatting numbers including currency.\n\n\nDO\n use ISO 3166 (ISO 3166-1-alpha2) codes for countries and dependent territories.\n\n\nDO\n use ISO 4217 alphabetic or numeric codes for denoting currency.\n\n\nDO\n use RFC 3339 for dates, times, and date-time values used in representations. Time durations and intervals could conform to ISO 8601\n\n\nDO\n use ISO 639-1 language tags for representing the language of text. BCP-47 (based on ISO 639-1) for language variants.\n\n\nDO\n use time zone identifiers from the Olson Time Zone Database to convey time zones.\n\n\nDO\n use the HTTP-date format defined in RFC 7231 Section 7.1.1.1. (Date/Time Formats) for \nLast-Modified\n, \nDate\n, and \nExpires\n HTTP headers.\n\n\nAVOID\n using language-, region-, or country-specific formats or format identifiers, except when the text is meant for presentation to end users.\n\n\n\n\nAlso, consider defining the format for numbers and integers. The precision could be described as follows, to prevent clients from guessing the precision:\n\n\n\n\n\n\n\n\nType\n\n\nFormat\n\n\nSpecified value range\n\n\n\n\n\n\n\n\n\n\ninteger\n\n\nint32\n\n\ninteger between -2^31 and 2^31-1\n\n\n\n\n\n\ninteger\n\n\nint64\n\n\ninteger between -2^63 and 2^63-1\n\n\n\n\n\n\ninteger\n\n\nbigint\n\n\narbitrarily large signed integer number\n\n\n\n\n\n\nnumber\n\n\nfloat\n\n\nIEEE 754-2008/ISO 60559:2011 binary64 decimal number\n\n\n\n\n\n\nnumber\n\n\ndouble\n\n\nIEEE 754-2008/ISO 60559:2011 binary128 decimal number\n\n\n\n\n\n\nnumber\n\n\ndecimal\n\n\narbitrarily precise signed decimal number\n\n\n\n\n\n\n\n\nJSON\n\n\nJSON has become the de facto format within RESTful APIs, by providing a compact, human-readable format for accessing data, which can help minimalize the bandwidth required.\n\n\nOne of the advantages to REST is that it is not limited to a single format, and the choice of format should be based on what is most suitable for the clients.\n\n\n\n\nDO\n prefer JSON over XML to encode structured representations, whenever possible.\n\n\nDO\n include a \nself\n link to the resource in each representation.\n\n\nDO\n add a property to indicate the language, if an object in the representation is localized.\n\n\nDO\n pretty print the representation by default, as this will help when using a browser to access the public API. Together with compression the additional white-space characters are negligible.\n\n\nDO\n use gzip compression, if applicable.\n\n\nDO\n prefer \napplication/json\n over more specialized and custom media type like \napplication/example.booking+json\n.\n\n\nDO\n use consistent property names.\n\n\nDO\n use camelCase for property names.\n\n\nDO\n use a subset of \nus-ascii\nfor property names. The first character must be a letter, an underscore or a dollar sign, and subsequent characters can be a letter, an underscore, a dollar sign, or a number.\n\n\nDO\n pluralize arrays to indicate they contain multiple values prefer to pluralize array names. This implies that object names should in turn be singular.\n\n\nDO\n use consistent property values\n\n\nDO\n use string to represent enumerations.\n\n\nCONSIDER\n using common field names and semantics to achieve consistency across the API portfolio, as there is very little utility for clients in having different names or value types for these fields across APIs. Candidates are, but not limited to: \nid\n, \nrelation_id\n, \ntype\n, \ncreated\n, \nmodified/updated\n.\n\n\nCONSIDER\n including entity identifiers for each of the application domain entities that make up the resource.\n\n\nCONSIDER\n the use of an envelope by default. Only use envelopes in exceptional cases.\n\n\nCONSIDER\n follow RFC-7159 by having (if possible) a serialized object as the top-level structure, since it would allow for future extension. \n\n\nDO NOT\n return an array as the top-level structure, as this may expose security vunerabilities. Instead use an envelope, like: \n{ list: [...]}\n.\n\n\nDO NOT\n use \nnull\n for boolean property values must not be null. A boolean is essentially a closed enumeration of two values, true and false. If the content has a meaningful null value, strongly prefer to replace the boolean with enumeration of named values or statuses.\n\n\nDO NOT\n return \nnull\n for empty array values should not be null. Empty array values can unambiguously be represented as the the empty list, [].\n\n\n\n\nExample\n{\n\n    \nname\n:\n \nJohn\n,\n\n    \nid\n:\n \nurn:example:user:1234\n,\n\n    \nlink\n:\n \n{\n\n        \nrel\n:\n \nself\n,\n\n        \nhref\n:\n \nhttps://www.example.org/person/john\n\n    \n},\n\n    \naddress\n:\n \n{\n\n        \nid\n:\n \nurn:example:address:4567\n,\n\n        \nlink\n:\n \n{\n\n            \nrel\n:\n \nself\n,\n\n            \nhref\n:\n \nhttps://www.example.org/person/john/address\n\n        \n}\n\n    \n},\n\n    \ncontent\n:\n \n{\n\n        \ntext\n:\n \n[{\n\n        \nvalue\n:\n \n...\n\n        \n},\n \n{\n\n            \nlang\n:\n \nen-GB\n,\n\n            \nvalue\n:\n \n...\n\n        \n},\n \n{\n\n            \nlang\n:\n \nen-US\n,\n\n            \nvalue\n:\n \n...\n\n        \n}]\n\n    \n}\n\n\n}\n\n\n\n\nJSON Collections\n\n\n\n\nDO\n return an empty collection, if the query does not match any resources.\n\n\nDO\n include \nPagination Links\n.\n\n\n\n\nXML\n\n\n Suggested topics: Atom resources, AtomPub Service, category documents, AtomPub for feed and entry resources, media resources \n\n\nHTML\n\n\n\n\nDO\n provide HTML representations, for resources that are expected to be consumed by end users.\n\n\nCONSIDER\n  using microformats or RDFx to annotate data within the markup.\n\n\nAVOID\n avoid designing HTML representations for machine clients.\n\n\n\n\nBinary Data\n\n\n\n\nDO\n use multipart media types such as \nmultipart/mixed\n, \nmultipart/related\n, or \nmultipart/alternative\n.\n\n\nCONSIDER\n providing a link to fetch the binary data as a separate resource as an alternative. Creating and parsing multipart messages in some programming languages may be cumbersome and complex.\n\n\nAVOID\n encoding binary data within textual formats using Base64 encoding.\n\n\n\n\nPagination\n\n\nAccess to lists of data items must support pagination for best client side batch processing and iteration experience. This holds true for all lists that are (potentially) larger than just a few hundred entries. It's almost always a bad idea to return every resource in a database.\n\n\nThere are two overall pagination techniques:\n\n\n\n\nOffset/limit\n based pagination, where a numeric \noffset\n identifies the first page entry and a \nlimit\n signifies how many entries are returned.\n\n\nCursor\n based (or key based) pagination, where a unique key element identifies the first page entry.\n\n\n\n\nOffset/limit-based vs. cursor-based pagination\nCursor-based pagination is usually better and more efficient when compared to offset/limit-based pagination. Especially when it comes to high-data volumes and/or storage in NoSQL databases, so there may be a tendency to prefer cursor-based pagination, however, before choosing cursor-based pagination, consider the following:\nFeature\nOffset/limit\nCursor\nComments\nUsability\n+\n-\nOffset/limit-based pagination is more wellknown, so it may be easier to use for most API clients.\nFramework support\n+\n-\nOffset/limit-based pagination is more wellknown, so it may have better framework support.\nTotal count\n+\n-\nCursor-based pagination may not work if you need the total count of results and/or backward iteration support.\nUse case: Jump to a certain page\n+\n-\nIf jumping to a particular page in a range (e.g., 51 of 100) is really a required use case, cursor-based navigation is not feasible.\nPerformance\n-\n+\nEfficient server-side processing using offset/limit-based pagination is hardly feasible for higher data list volumes, especially if they do not reside in the database's main memory.\nSharded or NoSQL databases\n-\n+\nNot feasable for offset/limit-based pagination for most database implementations.\n\n\nTip\n\n\nThe technical conception of pagination should also consider user experience related issues. Jumping to a specific page is far less used than navigation via next/previous page links. This favours \ncursor\n-based over \noffset/limit\n-based pagination.\n\n\n\n\nWhen providing paginated collections:\n\n\n\n\nDO\n use offset/limit-based pagination when resource collections are backed by traditional relation databases. It is more common, well understood in leading databases, and easy for developers.\n\n\nDO\n use a cursor-based pagination strategy, when the dataset is very large and/or backed by a non-traditional relational data store, like a document database.\n\n\n\n\n\n\nSHOULD:: Use Simple Hypertext Controls for Pagination and Self-References\n\n\nHypertext controls for pagination inside collections and self-references should use a simple URI value in combination with their corresponding link relations (next, prev, first, last, self) instead of the extensible common hypertext control\n\n\nSee Pagination for information how to best represent paginateable collections.\n\n\n\n\n\n\nVariability\n\n\nBoth pagination strategies suffer when data changes, which may lead to anomalies in result pages.\n\n\nOffset/limit-based pagination may create duplicates or lead to missing entries if rows are inserted or deleted between two subsequent paging requests.\n\n\nWhen using cursor-based pagination, paging cannot continue when the cursor entry has been deleted while fetching two page\n\n\n\n\nLinks\n\n\nUse pagination links where applicable.\n\n\n\n\nDO\n add a self link to the collection resource.\n\n\nDO\n add link to the next page, if the collection is paginated and has a next page.\n\n\nDO\n a link to the previous page, if the collection is paginated and has a previous page.\n\n\nDO\n keep collections homogeneous by include only the homogeneous aspects of its member resources.\n\n\nCONSIDER\n adding an indicator of the size of the collection, either embedded in the collection representation or using a custom HTTP header, like \nX-Total-Count\n.\n\n\nCONSIDER\n using the HTTP \nLink\n header to supply pagination links.\n\n\n\n\n\n\nMUST: Not Use Link Headers with JSON entities\n\n\nWe don't allow the use of the Link Header defined by RFC 5988 in conjunction with JSON media types. We prefer links directly embedded in JSON payloads to the uncommon link header syntax.\n\n\n\n\n\n\nWarning\n\n\nAlthough the size of the collection is useful for building user interfaces, avoid computing the exact size of the collection. It may be expensive to compute, volatile, or even confidential. Providing a hint is usually good enough.\n\n\nYou should avoid providing a total count in your API unless there's a clear need to do so. Very often, there are systems and performance implications to supporting full counts, especially as datasets grow and requests become complex queries or filters that drive full scans (e.g., your database might need to look at all candidate items to count them). While this is an implementation detail relative to the API, it's important to consider your ability to support serving counts over the life of a service.\n\n\n\n\nRepresentations\n\n\nPagination links can be represented as simplified hypertext controls for pagination within the collection representation.\n\n\nIn the following example the collections has an \nitems:\n \n[\n...\n]\n attribute holding the items of the current page, as well as pagination links (highlighted below). The collection may also contain additional metadata about the collection (e.g. offset, limit) when necessary.\n\n\n\n\nJSON representation containing pagination links\n\n\n{\n\n\n    \nself\n:\n \nhttps://example.org/articles/authors?offset=4\nlimit=5\n,\n\n\n    \nfirst\n:\n \nhttps://example.org/articles/authors?offset=0\nlimit=5\n,\n\n\n    \nnext\n:\n \nhttps://example.org/articles/authors?offset=9\nlimit=5\n,\n\n\n    \nprev\n:\n \nhttps://example.org/articles/authors?offset=0\nlimit=5\n,\n\n\n    \nlast\n:\n \nhttps://example.org/articles/authors?offset=100\nlimit=5\n,\n\n\n    \noffset\n:\n \n10\n,\n\n    \nlimit\n:\n \n5\n,\n\n    \nitems\n:\n \n[\n\n        \n{\n  \n        \nhref\n:\n \nhttps://example.org/authors/123e4567-e89b-12d3-a456-426655440000\n,\n\n        \nid\n:\n \n123e4567-e89b-12d3-a456-426655440000\n,\n\n        \nname\n:\n \nKent Beck\n\n        \n},\n\n        \n{\n  \n        \nhref\n:\n \nhttps://example.org/authors/987e2343-e89b-12d3-a456-426655440000\n,\n\n        \nid\n:\n \n987e2343-e89b-12d3-a456-426655440000\n,\n\n        \nname\n:\n \nMartin Fowler\n\n        \n},\n\n        \n...\n\n    \n]\n\n\n}\n\n\n\n\n\n\n\nAn alternative approach may be to using HTTP \nLink\n header introduced by RFC 5988\n2\n:\n\n\n\n\nHTTP header\n\n\nUsing the HTTP \nLink\n header for pagination links:\n\n# Request\nGET /articles/authors?offset=4\nlimit=5\n\n# Response\nLink: \nhttps://example.org/articles/authors?offset=9\nlimit=5\n; rel=\nnext\n,\n      \nhttps://example.org/articles/authors?offset=100\nlimit=5\n; rel=\nlast\n,\n      \nhttps://example.org/articles/authors?offset=0\nlimit=5\n; rel=\nfirst\n,\n      \nhttps://example.org/articles/authors?offset=0\nlimit=5\n; rel=\nprev\n\n\n\nOr using custom HTTP headers:\n\n# Request\nGET projects/1/stories?offset=1300\nlimit=300\n\n# Response\nX-Tracker-Pagination-Total: 1543\nX-Tracker-Pagination-Limit: 300\nX-Tracker-Pagination-Offset: 1300\nX-Tracker-Pagination-Returned: 243\n\n\n\n\n\nError Representations\n\n\nCommunicate errors through standard HTTP status codes along with details supplied in the response body. \n\n\nErrors are a key element for providing context and visibility, and status codes enable clients to quickly ascertain the status of their request. While well-formed and descriptive error details will tell the client what happened, why it happened, and how to fix it.\n\n\n\n\nDO\n provide error documentation.\n\n\nDO\n include a \nDate\n header with a value indicating the date-time at which the error occurred.\n\n\nDO\n include a body in the representation formatted and localized using content negotiation or in human-readable HTML or plain text, unless the request method is \nHEAD\n.\n\n\nDO\n provide an identifier or a link that can be used to refer to that error, if you are logging errors on the server side for later tracking or analysis.\n\n\nDO\n include a brief message describing the error condition\n\n\nDO\n include a longer description with information on how to fix the error condition, if applicable\n\n\nDO\n describe any action that the client can take to correct the error or to help the server debug and fix the error, if appropriate.\n\n\nCONSIDER\n using Problem Detail. The RFC 7807 \n3\n defines the media type application/problem+json. Operations should return that (together with a suitable status code) when any problem occurred during processing and you can give more details than the status code itself can supply, whether it be caused by the client or the server (i.e. both for 4xx or 5xx errors).\n\n\nCONSIDER\n adding a field breakdown, providing detailed errors, along with a fixed top-level error description, for \nPUT\n, \nPATCH\n and \nPOST\n requests.\n\n\nCONSIDER\n including a link to that document via a \nLink\n header or a link in the body, if information to correct or debug the error is available as a separate human-readable document. Also consider tracking the hits to these pages to see what areas tend to be more troublesome for your users \u2013 allowing you to provide even better documentation and/or build a better API.\n\n\nAVOID\n including details such as stack traces, errors from database connections failures, etc.\n\n\nAVOID\n using generic or non-descriptive error messages as they are often one of the biggest hinderances to API integration, as developers may struggle for hours trying to figure out why the call is failing, even misinterpreting the intent of the error message altogether.\n\n\nDO NOT\n return \n2xx\n and include a message body that describes an error condition. Doing so prevents HTTP-aware software from detecting errors.\n\n\n\n\nError example\n{\n\n    \nerror\n \n:\n \n{\n\n    \ncode\n \n:\n \ne3526\n,\n\n    \nmessage\n \n:\n \nMissing UserID\n,\n\n    \ndescription\n \n:\n \nA UserID is required to edit a user.\n,\n\n    \nlink\n \n:\n \nhttps://docs.mysite.com/errors/e3526/\n\n    \n}\n\n\n}\n\n\n\n\nValidation error example\n{\n\n    \ncode\n \n:\n \n1024\n,\n\n    \nmessage\n \n:\n \nValidation Failed\n,\n\n    \nerrors\n \n:\n \n[\n\n    \n{\n\n        \ncode\n \n:\n \n5432\n,\n\n        \nfield\n \n:\n \nfirst_name\n,\n\n        \nmessage\n \n:\n \nFirst name cannot have fancy characters\n\n    \n},\n\n    \n{\n\n        \ncode\n \n:\n \n5622\n,\n\n        \nfield\n \n:\n \npassword\n,\n\n        \nmessage\n \n:\n \nPassword cannot be blank\n\n    \n}\n\n    \n]\n\n\n}\n\n\n\n\nHTTP Status Codes\n\n\n\n\nAlways return meaningful HTTP Status Codes!\n\n\n\n\nBy using meaningful status codes, developers can quickly see what is happening with the application and do a \"quick check\" for errors without having to rely on the body's response.\n\n\n\n\nDO\n return \n2xx\n when the request was received, understood, and accepted.\n\n\nDO\n return \n3xx\n when the client needs to take further action. Include the necessary information in order for the client to complete the request.\n\n\nDO\n return a representation with a \n4xx\n status code, for errors due to client inputs.\n\n\nDO\n return a representation with a \n5xx\n status code, for errors due to server implementation or its current state.\n\n\nDO\n use the most specific HTTP status code for your concrete resource request processing status or error situation.\n\n\nDO\n provide good documentation in the API definition when using HTTP status codes that are less commonly used and not listed below.\n\n\nDO NOT\n invent new HTTP status codes; only use standardized HTTP status codes and consistent with its intended semantics.\n\n\n\n\n2xx\n\n\nFor successful responses:\n\n\n\n\nDO\n return \n200 OK\n when the request completed without issues.\n\n\nDO\n return \n201 Created\n when a resource was successfully created. Always set the \nLocation\n header with the URI of the newly created resource. Return either an empty response or the created resource.\n\n\nDO\n return \n202 Accepted\n when a request was successful and will be processed asynchronously.\n\n\nDO\n return \n204 No content\n when there is no response body.\n\n\nDO\n return \n207 Multi-Status\n when the response body contains multiple status informations for different parts of a batch/bulk request.\n\n\n\n\n3xx\n\n\nFor any action required by the client:\n\n\n\n\nDO\n return \n301 Moved Permanently\n when this and all future requests should be directed to the URI specified in the \nLocation\n header.\n\n\nDO\n return \n303 See Other\n when the response to the request can be found under the URI specified in the \nLocation\n header using a GET method.\n\n\nDO\n return \n304 Not Modified\n when the resource has not been modified since the date or version passed via request headers \nIf-Modified-Since\n or \nIf-None-Match\n.\n\n\n\n\n4xx\n\n\nFor client errors:\n\n\n\n\nDO\n return \n400 Bad Request\n when your server cannot decipher client requests because of syntactical errors.\n\n\nDO\n return \n401 Unauthorized\n when the client is not authorized to access the resource, but may be able to gain access after authentication. If your server will not let the client access the resource even after authentication return \n403 Forbidden\n instead. When returning this error code, include a WWW-Authenticate header field with the authentication method to use.\n\n\nDO\n return \n403 Forbidden\n when your serer will not let the client gain access (authenticated or not).\n\n\nDO\n return \n404 Not Found\n when the resource is not found. If possible, return a reason in the message body.\n\n\nDO\n return \n405 Not Allowed\n when an HTTP method is not allowed. Return an \nAllow\n header with methods that are valid for the resource.\n\n\nDO\n return \n406 Not Acceptable\n when the resource can only generate content not acceptable according to the \nAccept\n headers sent in the request.\n\n\nDO\n return \n408 Request Timeout\n when the server times out waiting for the resource.\n\n\nDO\n return \n409 Conflict\n when the request conflicts with the current state of the resource. Include a body explaining the reason.\n\n\nDO\n return \n410 Gone\n when the resource used to exist, but it does not anymore. You may not be able to return this unless you tracked deleted resources, then return \n404 Not Found\n.\n\n\nDO\n return \n412 Precondition Failed\n for conditional requests, when \nIf-Match\n and/or \nETag\n preconditions fail.\n\n\nDO\n return \n413 Request Entity Too Large\n when the body of a \nPOST\n or \nPUT\n is too large. If possible, specify what is allowed in the body and provide alternatives.\n\n\nDO\n return \n415 Unsupported Media Type\n when a client sends the message body in a form that the server does not understand.\n\n\nDO\n return \n423 Locked\n when using pessimistic locking.\n\n\nDO\n return \n428 Precondition Required\n when the server requires the request to be conditional (e.g. to make sure that the \"lost update problem\" is avoided).\n\n\nDO\n return \n429 Too Many Requests\n when the client does not consider rate limiting and sent too many requests. Include headers to indicate rate limits.\n\n\n\n\n5xx\n\n\nFor server errors:\n\n\n\n\nDO\n return \n500 Internal Server Error\n when your code on the server side failed due to come implementation bug.\n\n\nDO\n return \n501 Not Implemented\n to indicate that a future feature may become available.\n\n\nDO\n return \n503 Service Unavailable\n when the server cannot fulfill the request either for some specific interval or undetermined amount of time. If possible, include a \nRetry-After\n response header with either a date or a number of seconds as a hint.\n\n\n\n\nEntity Identifiers in Representations\n\n\nWhen an API is part of a larger API portfolio or system, information may cross several system boundaries, and entity identifiers can be used to uniformly identify, cross-reference or transform data. Especially when a lot of different technologies are envolved (RPC, SOAP, asynchronous messaging, stored procedures, etc.) and/or third-party applications, the only common denominator may very well be entity identifiers.\n\n\n\n\nCONSIDER\n consider formatting identifiers as URNs, for each of the application domain entities included in the representation of a resource, to maintain uniqueness of identifiers.\n\n\nCONSIDER\n using strings rather than number types for identifiers, as this gives more flexibility to evolve the identifier naming scheme. Accordingly, if used as identifiers, UUIDs should not be qualified using a format property.\n\n\nCONSIDER\n using UUIDs as entity identifiers for scaling in high frequency and near real time use cases, as they can be generated without collisions in a distributed, non-coordinated way and without additional server roundtrips.\n\n\nCONSIDER\n limiting the use of UUIDs as entity identifiers when it is not strictly necessary, if it possible to come up with a better naming scheme, if the id volume is low, or if the ids have widespread steering functionality.\n\n\n\n\n\n\n\n\n\n\n\n\nThe Internet Assigned Number Authority (\nIANA\n) media type registry.\n\n\n\n\n\n\nWeb Linking\n.\n\n\n\n\n\n\nProblem Details for HTTP APIs\n.", 
            "title": "Representations"
        }, 
        {
            "location": "/representations/#representations", 
            "text": "A  representation  (request/response) is concrete and real. Here we will offer guidelines as to what makes a good response design. To ensure scalability and longevity of the API, along with providing helpful responses that developers can understand and trust, we will cover what HTTP headers are appropriate in a response, which HTTP status codes to return, as well as how to include descriptive error representations on failures.   Bandwidth  It might be pertinent to support techniques for reducing bandwidth based on client needs. This is especially true for APIs that have large payloads and/or are used in high-traffic scenarios. Supporting mobile clients with less bandwidth connectivity, would be one such case.  To reduce bandwidth and improve responsiveness consider:   Compression using  Content-Encoding .  Partial responses  using query parameters.  Dividing the size of the payload using  Pagination .  ETag  and  If-Modified-Since / If-None-Match  for  Caching .  Using  Batch Operations .   All these common techniques are discussed in details elsewhere in these guidelines.", 
            "title": "Representations"
        }, 
        {
            "location": "/representations/#http-headers", 
            "text": "Headers ensure visibility, discoverability, routing by proxies, caching, optimistic concurrency, and correct operation of HTTP as an application protocol.  Use the following headers to annotate representations that contains a message body.", 
            "title": "HTTP Headers"
        }, 
        {
            "location": "/representations/#content-type", 
            "text": "Even though it is perfectly acceptable to use only a single format, in order to keep the API flexible and extendable, it is also important to build for the future. Until recently XML was the format of choice, but then along came JSON.   DO  use  Content-Type , to describe the type of representation, including a  charset  parameter or other parameters defined for that media type.  DO  include the  charset  parameter, if the media type supports it, with a value of the character encoding used to convert characters into bytes.  DO  use the specified encoding, when you receive a representation with a media type that supports the  charset parameter.  DO  let your parser interpret the character set, if you receive an XML representation with a missing  charset  parameter.  AVOID  using the  text/xml  media type for XML-formatted representations. The default charset for  text/xml  is  us-ascii , whereas  application/xml  uses  UTF-8 .    Tip  Note that Text and XML media types let you specify the character encoding. The JSON media type  application/json  does not specify a  charset  parameter, but uses  UTF-8  as the default encoding.", 
            "title": "Content-Type"
        }, 
        {
            "location": "/representations/#content-length", 
            "text": "DO  use  Content-Length , to specify the size in bytes of the body. Or specify  Transfer-Encoding: chunked . Some proxies reject  POST  and  PUT  requests that contain neither of these headers.", 
            "title": "Content-Length"
        }, 
        {
            "location": "/representations/#content-language", 
            "text": "DO  use  Content-Language , two-letter RFC 5646 language tag, optionally followed by a hyphen (-) and any two-letter country code.", 
            "title": "Content-Language"
        }, 
        {
            "location": "/representations/#content-encoding", 
            "text": "DO  use  Content-Encoding . Clients can indicate their preference for  Content-Encoding  using the  Accept-Encoding  header, however, there is no standard way for the client to learn whether a server can process representations compressed in a given encoding.", 
            "title": "Content-Encoding"
        }, 
        {
            "location": "/representations/#other-common-headers", 
            "text": "CONSIDER  using  ETag  and/or  Last-Modified  for caching and/or concurrency, the latter applies for responses only.  CONSIDER  using  Content-MD5 , when sending or receiving large representations over potentially unreliable networks to verify the integrity of the message.  DO NOT  use  Content-MD5  as any measure of security.", 
            "title": "Other Common Headers"
        }, 
        {
            "location": "/representations/#custom-http-headers", 
            "text": "Warning  Generally custom HTTP headers should be avoided, as they may impede interoperability. We discourage the use of hop-by-hop custom HTTP headers.   However, depending on what clients and servers use custom headers for, they can be useful in cases where context information needs to be passed through multiple services in an end-to-end fashion.    DO  use custom headers for informational purposes.  CONSIDER  using the convention  X-{company-name}-{header-name} , when introducing custom headers, as there is no established convention for naming custom headers. Avoid camelCase (without hyphens). Exceptions are common abbreviations like  ID .  the usage of X- headers is deprecated (RFC-6648)  CONSIDER  including the information in a custom HTTP header in the body or the URI, if the information is important for the correct interpretation of the request  DO NOT  implement clients and servers such that they fail when they do not find expected custom headers.  DO NOT  use custom HTTP headers to change behavior of HTTP methods, and limit any behavior-changing headers to  POST .  DO NOT  use  X-HTTP-Method-Override  to override  POST , use a distinct resource to process the same request using  POST  without the header. Any HTTP intermediary between the client and the server may omit custom headers.", 
            "title": "Custom HTTP Headers"
        }, 
        {
            "location": "/representations/#end-to-end-http-headers", 
            "text": "DO  use the specified end-to-end HTTP headers.  DO  propagate the end-to-end HTTP headers to upstream servers. Header names and values must remain intact.    The following may be candidates for end-to-end HTTP headers   Correlation ID of the request, which is written into the logs and passed to upstream services.   Generic user id that owns the passed (OAuth2) access token. May save additional token validation round trips  Sales channel  Device type, OS, and version  App version, etc.", 
            "title": "End-To-End HTTP Headers"
        }, 
        {
            "location": "/representations/#format-and-a-media-type", 
            "text": "HTTP's message format is designed to allow different media types and formats for requests and responses.  When it comes to format and media type selection, the rule of thumb is to let the use cases and the types of clients dictate the choice. For this reason, it is important not to pick up a development framework that rigidly enforces one or two formats for all resource with no flexibility to use other formats.   DO  determine whether there is a standard format and media type that matches your use cases. Check IANA  1 .  DO  use extensible formats such as XML, Atom Syndication Format, or JSON, if there is no standard media type and format.  CONSIDER  adding a  Content-Disposition: attachment; filename= status.xls  to give a hint of the filename, when using image formats like  image/png  or rich document formats like  application/vnd.ms-excel  or  application/pdf  to provide alternative representations of data.   If you choose to create new media types of your own, consider:   DO  use a sub-type that ends with  +xml  in the  Content-Type  header, when using XML  DO  use a sub-type starting with  vnd  ( application/vnd.example.org.user+xml ), when the media type is for private use,  DO  register your media type with IANA as per RFC 4288, if the media type is for public use,  AVOID  introducing new application-specific media types unless they are expected to be broadly used, as this may impede interoperability.    Warning  Although custom media types improve protocol-level visibility, existing protocol-level tools for monitoring, filtering, or routing HTTP traffic pay little or no attention to media types. Hence, using custom media types only for the sake of protocol-level visibility is not necessary.", 
            "title": "Format and a Media Type"
        }, 
        {
            "location": "/representations/#portable-data-formats", 
            "text": "DO  use decimal, float and double data types defined in the W3C XML Schema for formatting numbers including currency.  DO  use ISO 3166 (ISO 3166-1-alpha2) codes for countries and dependent territories.  DO  use ISO 4217 alphabetic or numeric codes for denoting currency.  DO  use RFC 3339 for dates, times, and date-time values used in representations. Time durations and intervals could conform to ISO 8601  DO  use ISO 639-1 language tags for representing the language of text. BCP-47 (based on ISO 639-1) for language variants.  DO  use time zone identifiers from the Olson Time Zone Database to convey time zones.  DO  use the HTTP-date format defined in RFC 7231 Section 7.1.1.1. (Date/Time Formats) for  Last-Modified ,  Date , and  Expires  HTTP headers.  AVOID  using language-, region-, or country-specific formats or format identifiers, except when the text is meant for presentation to end users.   Also, consider defining the format for numbers and integers. The precision could be described as follows, to prevent clients from guessing the precision:     Type  Format  Specified value range      integer  int32  integer between -2^31 and 2^31-1    integer  int64  integer between -2^63 and 2^63-1    integer  bigint  arbitrarily large signed integer number    number  float  IEEE 754-2008/ISO 60559:2011 binary64 decimal number    number  double  IEEE 754-2008/ISO 60559:2011 binary128 decimal number    number  decimal  arbitrarily precise signed decimal number", 
            "title": "Portable Data Formats"
        }, 
        {
            "location": "/representations/#json", 
            "text": "JSON has become the de facto format within RESTful APIs, by providing a compact, human-readable format for accessing data, which can help minimalize the bandwidth required.  One of the advantages to REST is that it is not limited to a single format, and the choice of format should be based on what is most suitable for the clients.   DO  prefer JSON over XML to encode structured representations, whenever possible.  DO  include a  self  link to the resource in each representation.  DO  add a property to indicate the language, if an object in the representation is localized.  DO  pretty print the representation by default, as this will help when using a browser to access the public API. Together with compression the additional white-space characters are negligible.  DO  use gzip compression, if applicable.  DO  prefer  application/json  over more specialized and custom media type like  application/example.booking+json .  DO  use consistent property names.  DO  use camelCase for property names.  DO  use a subset of  us-ascii for property names. The first character must be a letter, an underscore or a dollar sign, and subsequent characters can be a letter, an underscore, a dollar sign, or a number.  DO  pluralize arrays to indicate they contain multiple values prefer to pluralize array names. This implies that object names should in turn be singular.  DO  use consistent property values  DO  use string to represent enumerations.  CONSIDER  using common field names and semantics to achieve consistency across the API portfolio, as there is very little utility for clients in having different names or value types for these fields across APIs. Candidates are, but not limited to:  id ,  relation_id ,  type ,  created ,  modified/updated .  CONSIDER  including entity identifiers for each of the application domain entities that make up the resource.  CONSIDER  the use of an envelope by default. Only use envelopes in exceptional cases.  CONSIDER  follow RFC-7159 by having (if possible) a serialized object as the top-level structure, since it would allow for future extension.   DO NOT  return an array as the top-level structure, as this may expose security vunerabilities. Instead use an envelope, like:  { list: [...]} .  DO NOT  use  null  for boolean property values must not be null. A boolean is essentially a closed enumeration of two values, true and false. If the content has a meaningful null value, strongly prefer to replace the boolean with enumeration of named values or statuses.  DO NOT  return  null  for empty array values should not be null. Empty array values can unambiguously be represented as the the empty list, [].   Example { \n     name :   John , \n     id :   urn:example:user:1234 , \n     link :   { \n         rel :   self , \n         href :   https://www.example.org/person/john \n     }, \n     address :   { \n         id :   urn:example:address:4567 , \n         link :   { \n             rel :   self , \n             href :   https://www.example.org/person/john/address \n         } \n     }, \n     content :   { \n         text :   [{ \n         value :   ... \n         },   { \n             lang :   en-GB , \n             value :   ... \n         },   { \n             lang :   en-US , \n             value :   ... \n         }] \n     }  }", 
            "title": "JSON"
        }, 
        {
            "location": "/representations/#json-collections", 
            "text": "DO  return an empty collection, if the query does not match any resources.  DO  include  Pagination Links .", 
            "title": "JSON Collections"
        }, 
        {
            "location": "/representations/#xml", 
            "text": "Suggested topics: Atom resources, AtomPub Service, category documents, AtomPub for feed and entry resources, media resources", 
            "title": "XML"
        }, 
        {
            "location": "/representations/#html", 
            "text": "DO  provide HTML representations, for resources that are expected to be consumed by end users.  CONSIDER   using microformats or RDFx to annotate data within the markup.  AVOID  avoid designing HTML representations for machine clients.", 
            "title": "HTML"
        }, 
        {
            "location": "/representations/#binary-data", 
            "text": "DO  use multipart media types such as  multipart/mixed ,  multipart/related , or  multipart/alternative .  CONSIDER  providing a link to fetch the binary data as a separate resource as an alternative. Creating and parsing multipart messages in some programming languages may be cumbersome and complex.  AVOID  encoding binary data within textual formats using Base64 encoding.", 
            "title": "Binary Data"
        }, 
        {
            "location": "/representations/#pagination", 
            "text": "Access to lists of data items must support pagination for best client side batch processing and iteration experience. This holds true for all lists that are (potentially) larger than just a few hundred entries. It's almost always a bad idea to return every resource in a database.  There are two overall pagination techniques:   Offset/limit  based pagination, where a numeric  offset  identifies the first page entry and a  limit  signifies how many entries are returned.  Cursor  based (or key based) pagination, where a unique key element identifies the first page entry.   Offset/limit-based vs. cursor-based pagination Cursor-based pagination is usually better and more efficient when compared to offset/limit-based pagination. Especially when it comes to high-data volumes and/or storage in NoSQL databases, so there may be a tendency to prefer cursor-based pagination, however, before choosing cursor-based pagination, consider the following: Feature Offset/limit Cursor Comments Usability + - Offset/limit-based pagination is more wellknown, so it may be easier to use for most API clients. Framework support + - Offset/limit-based pagination is more wellknown, so it may have better framework support. Total count + - Cursor-based pagination may not work if you need the total count of results and/or backward iteration support. Use case: Jump to a certain page + - If jumping to a particular page in a range (e.g., 51 of 100) is really a required use case, cursor-based navigation is not feasible. Performance - + Efficient server-side processing using offset/limit-based pagination is hardly feasible for higher data list volumes, especially if they do not reside in the database's main memory. Sharded or NoSQL databases - + Not feasable for offset/limit-based pagination for most database implementations.  Tip  The technical conception of pagination should also consider user experience related issues. Jumping to a specific page is far less used than navigation via next/previous page links. This favours  cursor -based over  offset/limit -based pagination.   When providing paginated collections:   DO  use offset/limit-based pagination when resource collections are backed by traditional relation databases. It is more common, well understood in leading databases, and easy for developers.  DO  use a cursor-based pagination strategy, when the dataset is very large and/or backed by a non-traditional relational data store, like a document database.", 
            "title": "Pagination"
        }, 
        {
            "location": "/representations/#should-use-simple-hypertext-controls-for-pagination-and-self-references", 
            "text": "Hypertext controls for pagination inside collections and self-references should use a simple URI value in combination with their corresponding link relations (next, prev, first, last, self) instead of the extensible common hypertext control  See Pagination for information how to best represent paginateable collections.    Variability  Both pagination strategies suffer when data changes, which may lead to anomalies in result pages.  Offset/limit-based pagination may create duplicates or lead to missing entries if rows are inserted or deleted between two subsequent paging requests.  When using cursor-based pagination, paging cannot continue when the cursor entry has been deleted while fetching two page", 
            "title": "SHOULD:: Use Simple Hypertext Controls for Pagination and Self-References"
        }, 
        {
            "location": "/representations/#links", 
            "text": "Use pagination links where applicable.   DO  add a self link to the collection resource.  DO  add link to the next page, if the collection is paginated and has a next page.  DO  a link to the previous page, if the collection is paginated and has a previous page.  DO  keep collections homogeneous by include only the homogeneous aspects of its member resources.  CONSIDER  adding an indicator of the size of the collection, either embedded in the collection representation or using a custom HTTP header, like  X-Total-Count .  CONSIDER  using the HTTP  Link  header to supply pagination links.", 
            "title": "Links"
        }, 
        {
            "location": "/representations/#must-not-use-link-headers-with-json-entities", 
            "text": "We don't allow the use of the Link Header defined by RFC 5988 in conjunction with JSON media types. We prefer links directly embedded in JSON payloads to the uncommon link header syntax.    Warning  Although the size of the collection is useful for building user interfaces, avoid computing the exact size of the collection. It may be expensive to compute, volatile, or even confidential. Providing a hint is usually good enough.  You should avoid providing a total count in your API unless there's a clear need to do so. Very often, there are systems and performance implications to supporting full counts, especially as datasets grow and requests become complex queries or filters that drive full scans (e.g., your database might need to look at all candidate items to count them). While this is an implementation detail relative to the API, it's important to consider your ability to support serving counts over the life of a service.", 
            "title": "MUST: Not Use Link Headers with JSON entities"
        }, 
        {
            "location": "/representations/#representations_1", 
            "text": "Pagination links can be represented as simplified hypertext controls for pagination within the collection representation.  In the following example the collections has an  items:   [ ... ]  attribute holding the items of the current page, as well as pagination links (highlighted below). The collection may also contain additional metadata about the collection (e.g. offset, limit) when necessary.   JSON representation containing pagination links  {       self :   https://example.org/articles/authors?offset=4 limit=5 ,       first :   https://example.org/articles/authors?offset=0 limit=5 ,       next :   https://example.org/articles/authors?offset=9 limit=5 ,       prev :   https://example.org/articles/authors?offset=0 limit=5 ,       last :   https://example.org/articles/authors?offset=100 limit=5 ,       offset :   10 , \n     limit :   5 , \n     items :   [ \n         {   \n         href :   https://example.org/authors/123e4567-e89b-12d3-a456-426655440000 , \n         id :   123e4567-e89b-12d3-a456-426655440000 , \n         name :   Kent Beck \n         }, \n         {   \n         href :   https://example.org/authors/987e2343-e89b-12d3-a456-426655440000 , \n         id :   987e2343-e89b-12d3-a456-426655440000 , \n         name :   Martin Fowler \n         }, \n         ... \n     ]  }    An alternative approach may be to using HTTP  Link  header introduced by RFC 5988 2 :   HTTP header  Using the HTTP  Link  header for pagination links: # Request\nGET /articles/authors?offset=4 limit=5\n\n# Response\nLink:  https://example.org/articles/authors?offset=9 limit=5 ; rel= next ,\n       https://example.org/articles/authors?offset=100 limit=5 ; rel= last ,\n       https://example.org/articles/authors?offset=0 limit=5 ; rel= first ,\n       https://example.org/articles/authors?offset=0 limit=5 ; rel= prev  \nOr using custom HTTP headers: # Request\nGET projects/1/stories?offset=1300 limit=300\n\n# Response\nX-Tracker-Pagination-Total: 1543\nX-Tracker-Pagination-Limit: 300\nX-Tracker-Pagination-Offset: 1300\nX-Tracker-Pagination-Returned: 243", 
            "title": "Representations"
        }, 
        {
            "location": "/representations/#error-representations", 
            "text": "Communicate errors through standard HTTP status codes along with details supplied in the response body.   Errors are a key element for providing context and visibility, and status codes enable clients to quickly ascertain the status of their request. While well-formed and descriptive error details will tell the client what happened, why it happened, and how to fix it.   DO  provide error documentation.  DO  include a  Date  header with a value indicating the date-time at which the error occurred.  DO  include a body in the representation formatted and localized using content negotiation or in human-readable HTML or plain text, unless the request method is  HEAD .  DO  provide an identifier or a link that can be used to refer to that error, if you are logging errors on the server side for later tracking or analysis.  DO  include a brief message describing the error condition  DO  include a longer description with information on how to fix the error condition, if applicable  DO  describe any action that the client can take to correct the error or to help the server debug and fix the error, if appropriate.  CONSIDER  using Problem Detail. The RFC 7807  3  defines the media type application/problem+json. Operations should return that (together with a suitable status code) when any problem occurred during processing and you can give more details than the status code itself can supply, whether it be caused by the client or the server (i.e. both for 4xx or 5xx errors).  CONSIDER  adding a field breakdown, providing detailed errors, along with a fixed top-level error description, for  PUT ,  PATCH  and  POST  requests.  CONSIDER  including a link to that document via a  Link  header or a link in the body, if information to correct or debug the error is available as a separate human-readable document. Also consider tracking the hits to these pages to see what areas tend to be more troublesome for your users \u2013 allowing you to provide even better documentation and/or build a better API.  AVOID  including details such as stack traces, errors from database connections failures, etc.  AVOID  using generic or non-descriptive error messages as they are often one of the biggest hinderances to API integration, as developers may struggle for hours trying to figure out why the call is failing, even misinterpreting the intent of the error message altogether.  DO NOT  return  2xx  and include a message body that describes an error condition. Doing so prevents HTTP-aware software from detecting errors.   Error example { \n     error   :   { \n     code   :   e3526 , \n     message   :   Missing UserID , \n     description   :   A UserID is required to edit a user. , \n     link   :   https://docs.mysite.com/errors/e3526/ \n     }  }   Validation error example { \n     code   :   1024 , \n     message   :   Validation Failed , \n     errors   :   [ \n     { \n         code   :   5432 , \n         field   :   first_name , \n         message   :   First name cannot have fancy characters \n     }, \n     { \n         code   :   5622 , \n         field   :   password , \n         message   :   Password cannot be blank \n     } \n     ]  }", 
            "title": "Error Representations"
        }, 
        {
            "location": "/representations/#http-status-codes", 
            "text": "Always return meaningful HTTP Status Codes!   By using meaningful status codes, developers can quickly see what is happening with the application and do a \"quick check\" for errors without having to rely on the body's response.   DO  return  2xx  when the request was received, understood, and accepted.  DO  return  3xx  when the client needs to take further action. Include the necessary information in order for the client to complete the request.  DO  return a representation with a  4xx  status code, for errors due to client inputs.  DO  return a representation with a  5xx  status code, for errors due to server implementation or its current state.  DO  use the most specific HTTP status code for your concrete resource request processing status or error situation.  DO  provide good documentation in the API definition when using HTTP status codes that are less commonly used and not listed below.  DO NOT  invent new HTTP status codes; only use standardized HTTP status codes and consistent with its intended semantics.", 
            "title": "HTTP Status Codes"
        }, 
        {
            "location": "/representations/#2xx", 
            "text": "For successful responses:   DO  return  200 OK  when the request completed without issues.  DO  return  201 Created  when a resource was successfully created. Always set the  Location  header with the URI of the newly created resource. Return either an empty response or the created resource.  DO  return  202 Accepted  when a request was successful and will be processed asynchronously.  DO  return  204 No content  when there is no response body.  DO  return  207 Multi-Status  when the response body contains multiple status informations for different parts of a batch/bulk request.", 
            "title": "2xx"
        }, 
        {
            "location": "/representations/#3xx", 
            "text": "For any action required by the client:   DO  return  301 Moved Permanently  when this and all future requests should be directed to the URI specified in the  Location  header.  DO  return  303 See Other  when the response to the request can be found under the URI specified in the  Location  header using a GET method.  DO  return  304 Not Modified  when the resource has not been modified since the date or version passed via request headers  If-Modified-Since  or  If-None-Match .", 
            "title": "3xx"
        }, 
        {
            "location": "/representations/#4xx", 
            "text": "For client errors:   DO  return  400 Bad Request  when your server cannot decipher client requests because of syntactical errors.  DO  return  401 Unauthorized  when the client is not authorized to access the resource, but may be able to gain access after authentication. If your server will not let the client access the resource even after authentication return  403 Forbidden  instead. When returning this error code, include a WWW-Authenticate header field with the authentication method to use.  DO  return  403 Forbidden  when your serer will not let the client gain access (authenticated or not).  DO  return  404 Not Found  when the resource is not found. If possible, return a reason in the message body.  DO  return  405 Not Allowed  when an HTTP method is not allowed. Return an  Allow  header with methods that are valid for the resource.  DO  return  406 Not Acceptable  when the resource can only generate content not acceptable according to the  Accept  headers sent in the request.  DO  return  408 Request Timeout  when the server times out waiting for the resource.  DO  return  409 Conflict  when the request conflicts with the current state of the resource. Include a body explaining the reason.  DO  return  410 Gone  when the resource used to exist, but it does not anymore. You may not be able to return this unless you tracked deleted resources, then return  404 Not Found .  DO  return  412 Precondition Failed  for conditional requests, when  If-Match  and/or  ETag  preconditions fail.  DO  return  413 Request Entity Too Large  when the body of a  POST  or  PUT  is too large. If possible, specify what is allowed in the body and provide alternatives.  DO  return  415 Unsupported Media Type  when a client sends the message body in a form that the server does not understand.  DO  return  423 Locked  when using pessimistic locking.  DO  return  428 Precondition Required  when the server requires the request to be conditional (e.g. to make sure that the \"lost update problem\" is avoided).  DO  return  429 Too Many Requests  when the client does not consider rate limiting and sent too many requests. Include headers to indicate rate limits.", 
            "title": "4xx"
        }, 
        {
            "location": "/representations/#5xx", 
            "text": "For server errors:   DO  return  500 Internal Server Error  when your code on the server side failed due to come implementation bug.  DO  return  501 Not Implemented  to indicate that a future feature may become available.  DO  return  503 Service Unavailable  when the server cannot fulfill the request either for some specific interval or undetermined amount of time. If possible, include a  Retry-After  response header with either a date or a number of seconds as a hint.", 
            "title": "5xx"
        }, 
        {
            "location": "/representations/#entity-identifiers-in-representations", 
            "text": "When an API is part of a larger API portfolio or system, information may cross several system boundaries, and entity identifiers can be used to uniformly identify, cross-reference or transform data. Especially when a lot of different technologies are envolved (RPC, SOAP, asynchronous messaging, stored procedures, etc.) and/or third-party applications, the only common denominator may very well be entity identifiers.   CONSIDER  consider formatting identifiers as URNs, for each of the application domain entities included in the representation of a resource, to maintain uniqueness of identifiers.  CONSIDER  using strings rather than number types for identifiers, as this gives more flexibility to evolve the identifier naming scheme. Accordingly, if used as identifiers, UUIDs should not be qualified using a format property.  CONSIDER  using UUIDs as entity identifiers for scaling in high frequency and near real time use cases, as they can be generated without collisions in a distributed, non-coordinated way and without additional server roundtrips.  CONSIDER  limiting the use of UUIDs as entity identifiers when it is not strictly necessary, if it possible to come up with a better naming scheme, if the id volume is low, or if the ids have widespread steering functionality.       The Internet Assigned Number Authority ( IANA ) media type registry.    Web Linking .    Problem Details for HTTP APIs .", 
            "title": "Entity Identifiers in Representations"
        }, 
        {
            "location": "/resource-identifiers/", 
            "text": "Unique Resource Identifiers (URIs)\n\n\nAn important aspect of API design is to think about how to design unique resource identifiers, and as such, URIs should be treated as \nopaque resource identifiers\n1\n.\n\n\nThe opacity of URIs helps reduce coupling between servers and clients. This has nothing to do with readability or hackability, both of which may be extremely important aspects for developers consuming the API, where:\n\n\n\n\nreadable URIs\n help developers understand something about the resource.\n\n\nhackable URIs\n are manipulated by altering/removing portions of the path or query, and can help developers locate other resources.\n\n\n\n\n\n\nImportant\n\n\nClients should not be concerned with the design of URIs, nor should clients try to pick apart URIs in order to gather information from them. Instead URIs should be discovered through links (and the submission of forms).\n\n\nFor instance, clients must not use the fact that a URI ends with \n.xml\n to infer that it resolves to an XML representation, instead it must rely on the \nContent-Type\n header of the response. \n\n\n\n\nDesigning URIs\n\n\nWhen done successfully the result, of a thoughtful URI design, can be the most important \ndesign affordance\n2\n of your API.\n\n\nSo when designing URIs:\n\n\n\n\nDO\n design URIs to last a long time - \nCool URIs don't change\n.\n\n\nDO\n design URIs based on stable concepts, identifiers, and information. URIs cannot be permanent if the concepts or identifiers used cannot be permanent for business, technical, or security reasons. \n\n\nDO\n keep your base URIs simple and intuitive.\n\n\nDO\n use lowercase for URIs.\n\n\nDO\n use domains and subdomains to logically group or partition resources for localization, distribution, or to enforce various monitoring or security policies.\n\n\nDO\n use forward-slash (\n/\n) in the path segment to indicate a hierarchical relationship between resources.\n\n\nDO\n use the hyphen (\n-\n) or (\n_\n) characters to improve the readability of long path segments. \nPick one or the other for consistency\n.\n\n\nDO\n use ampersand (\n) to separate query parameters.\n\n\nDO\n use the URI only to determine which resource should process a request.\n\n\nCONSIDER\n providing URIs at runtime using links in the body of representations or headers, whenever appropriate.\n\n\nCONSIDER\n using \n/api\n as the first path segment, when the API also supports non-public APIs, e.g., for specific operational support functions. Otherwise, consider forgoing the \n/api\n prefix.\n\n\nCONSIDER\n using comma (\n,\n) and semi-colon (\n;\n) to indicate nonhierarchical elements in the path segment. The semi-colon (\n;\n) convention is used to identify matrix parameters. \nNot all libraries recognize these as separators and may require custom coding to extract these parameters\n.\n\n\nCONSIDER\n using URI templates, if it is impractical to supply all the possible URIs in the representation (e.g., ad hoc searching).\n\n\nCONSIDER\n disregarding opacity to protect against tampering using digitally signed URIs, or to protect sensitive information by encrypting parts of the URI.\n\n\nAVOID\n including file extensions, instead rely on the media types.\n\n\nAVOID\n using trailing forward slash, as some frameworks may incorrectly remove or add such slashes during URI normalization.\n\n\nAVOID\n expecting clients to construct URIs.\n\n\nAVOID\n unnecessary query strings in URIs.\n\n\nAVOID\n leaking implementation details to clients, by keeping the creating of URIs on the server, as those details will become part of the public interface.\n\n\nDO NOT\n use an URI as a generic gateway, by tunneling repeated state changes over \nPOST\n using the same URI.\n\n\nDO NOT\n use custom headers to overload URIs.\n\n\n\n\nURIs for Queries\n\n\nQueries usually involve filtering, sorting and projections. When providing query support for these and other actions:\n\n\n\n\nDO\n use snake_case (\nnever camelCase\n) for Query Parameters.\n\n\nDO\n use query parameters to let clients specify filter conditions, sort fields, and projections.\n\n\nDO\n treat query parameters as optional with sensible defaults.\n\n\nDO\n document each parameter.\n\n\nCONSIDER\n using \nq\n (e.g. used by browser tab completion) as the default query parameter.\n\n\nCONSIDER\n using a \nformat\n query parameter, if standard content negotiation is not possible.\n\n\nAVOID\n ad hoc queries that use general-purpose query languages such as \nSQL\n or \nXPath\n.\n\n\nAVOID\n \nRange\n requests for implementing queries.\n\n\n\n\nPartial Responses\n\n\n\n\nCONSIDER\n using a \nfields\n query parameter for projections (partial responses), like \nhttps://www.example.org/customers?fields=name,gender,birthday\n or \nhttps://example.org/customer?fields=(firstName,user(email))\n and \n!\n to negate field selection. Depending on the use case and payload size, it can reduce network bandwidth and reduce filtering on clients.\n\n\nCONSIDER\n using a \nview\n query parameter for predefined projections, like \nhttps://www.example.org/customers?view=summary\n\n\nCONSIDER\n supporting aliases for commonly used queries (it may also improve cacheability). For instance, \nGET /tickets/recently_closed\n\n\nCONSIDER\n using \nembed\n to allow for resource expansion. Embedding related resources can help reduce the number of requests.\n\n\n\n\nSorting\n\n\n\n\nCONSIDER\n using a generic \nsort\n parameter to describe sorting rules. To accommodate more complex sorting requirements, let the \nsort\n parameter take a list of comma-separated fields, each with a possible unary negative to imply descending sort order. Like: \nGET /tickets?sort=-priority,created_at\n\n\n\n\nPagination\n\n\n\n\nCONSIDER\n using \nlimit\n and \noffset\n, like \nhttps://www.example.org/authors?offset=50\nlimit=25\n, when resource collections are backed by traditional relation databases, as these ties into the general implementation on the data store. Opt for \ncursor\n and a cursor-based pagination strategy, when the dataset is very large and/or backed by a non-traditional relational data store, like a document database. For more information see \nPagination\n.\n\n\nCONSIDER\n using sensible defaults for pagination, e.g. limit=10 and offset=0. The pagination defaults are dependent on your data size.\n\n\n\n\n\n\n\n\n\n\n\n\nOpaque URIs != Unreadable URIs\n\n\n\n\n\n\na design property that communicates how something should be used without requiring documentation", 
            "title": "Resource identifiers"
        }, 
        {
            "location": "/resource-identifiers/#unique-resource-identifiers-uris", 
            "text": "An important aspect of API design is to think about how to design unique resource identifiers, and as such, URIs should be treated as  opaque resource identifiers 1 .  The opacity of URIs helps reduce coupling between servers and clients. This has nothing to do with readability or hackability, both of which may be extremely important aspects for developers consuming the API, where:   readable URIs  help developers understand something about the resource.  hackable URIs  are manipulated by altering/removing portions of the path or query, and can help developers locate other resources.    Important  Clients should not be concerned with the design of URIs, nor should clients try to pick apart URIs in order to gather information from them. Instead URIs should be discovered through links (and the submission of forms).  For instance, clients must not use the fact that a URI ends with  .xml  to infer that it resolves to an XML representation, instead it must rely on the  Content-Type  header of the response.", 
            "title": "Unique Resource Identifiers (URIs)"
        }, 
        {
            "location": "/resource-identifiers/#designing-uris", 
            "text": "When done successfully the result, of a thoughtful URI design, can be the most important  design affordance 2  of your API.  So when designing URIs:   DO  design URIs to last a long time -  Cool URIs don't change .  DO  design URIs based on stable concepts, identifiers, and information. URIs cannot be permanent if the concepts or identifiers used cannot be permanent for business, technical, or security reasons.   DO  keep your base URIs simple and intuitive.  DO  use lowercase for URIs.  DO  use domains and subdomains to logically group or partition resources for localization, distribution, or to enforce various monitoring or security policies.  DO  use forward-slash ( / ) in the path segment to indicate a hierarchical relationship between resources.  DO  use the hyphen ( - ) or ( _ ) characters to improve the readability of long path segments.  Pick one or the other for consistency .  DO  use ampersand ( ) to separate query parameters.  DO  use the URI only to determine which resource should process a request.  CONSIDER  providing URIs at runtime using links in the body of representations or headers, whenever appropriate.  CONSIDER  using  /api  as the first path segment, when the API also supports non-public APIs, e.g., for specific operational support functions. Otherwise, consider forgoing the  /api  prefix.  CONSIDER  using comma ( , ) and semi-colon ( ; ) to indicate nonhierarchical elements in the path segment. The semi-colon ( ; ) convention is used to identify matrix parameters.  Not all libraries recognize these as separators and may require custom coding to extract these parameters .  CONSIDER  using URI templates, if it is impractical to supply all the possible URIs in the representation (e.g., ad hoc searching).  CONSIDER  disregarding opacity to protect against tampering using digitally signed URIs, or to protect sensitive information by encrypting parts of the URI.  AVOID  including file extensions, instead rely on the media types.  AVOID  using trailing forward slash, as some frameworks may incorrectly remove or add such slashes during URI normalization.  AVOID  expecting clients to construct URIs.  AVOID  unnecessary query strings in URIs.  AVOID  leaking implementation details to clients, by keeping the creating of URIs on the server, as those details will become part of the public interface.  DO NOT  use an URI as a generic gateway, by tunneling repeated state changes over  POST  using the same URI.  DO NOT  use custom headers to overload URIs.", 
            "title": "Designing URIs"
        }, 
        {
            "location": "/resource-identifiers/#uris-for-queries", 
            "text": "Queries usually involve filtering, sorting and projections. When providing query support for these and other actions:   DO  use snake_case ( never camelCase ) for Query Parameters.  DO  use query parameters to let clients specify filter conditions, sort fields, and projections.  DO  treat query parameters as optional with sensible defaults.  DO  document each parameter.  CONSIDER  using  q  (e.g. used by browser tab completion) as the default query parameter.  CONSIDER  using a  format  query parameter, if standard content negotiation is not possible.  AVOID  ad hoc queries that use general-purpose query languages such as  SQL  or  XPath .  AVOID   Range  requests for implementing queries.", 
            "title": "URIs for Queries"
        }, 
        {
            "location": "/resource-identifiers/#partial-responses", 
            "text": "CONSIDER  using a  fields  query parameter for projections (partial responses), like  https://www.example.org/customers?fields=name,gender,birthday  or  https://example.org/customer?fields=(firstName,user(email))  and  !  to negate field selection. Depending on the use case and payload size, it can reduce network bandwidth and reduce filtering on clients.  CONSIDER  using a  view  query parameter for predefined projections, like  https://www.example.org/customers?view=summary  CONSIDER  supporting aliases for commonly used queries (it may also improve cacheability). For instance,  GET /tickets/recently_closed  CONSIDER  using  embed  to allow for resource expansion. Embedding related resources can help reduce the number of requests.", 
            "title": "Partial Responses"
        }, 
        {
            "location": "/resource-identifiers/#sorting", 
            "text": "CONSIDER  using a generic  sort  parameter to describe sorting rules. To accommodate more complex sorting requirements, let the  sort  parameter take a list of comma-separated fields, each with a possible unary negative to imply descending sort order. Like:  GET /tickets?sort=-priority,created_at", 
            "title": "Sorting"
        }, 
        {
            "location": "/resource-identifiers/#pagination", 
            "text": "CONSIDER  using  limit  and  offset , like  https://www.example.org/authors?offset=50 limit=25 , when resource collections are backed by traditional relation databases, as these ties into the general implementation on the data store. Opt for  cursor  and a cursor-based pagination strategy, when the dataset is very large and/or backed by a non-traditional relational data store, like a document database. For more information see  Pagination .  CONSIDER  using sensible defaults for pagination, e.g. limit=10 and offset=0. The pagination defaults are dependent on your data size.       Opaque URIs != Unreadable URIs    a design property that communicates how something should be used without requiring documentation", 
            "title": "Pagination"
        }, 
        {
            "location": "/resources/", 
            "text": "Resources\n\n\nA \nresource\n is an abstract entity that is identified by a URI, and can be data, processing logic, files, or basically anything else that can be named.\n\n\nIdentifying and Naming Resources\n\n\nMost often when identifying resources, the use of nouns instead of verbs will be obvious, however, sometimes it is necessary to veer from this naming convention, when exposing certain services through the public API.\n\n\nThere is no single approach that will work for all the situations, so care should be taking when identifying resources and finding the right resource granularity, in order for API consumers to get the desired functionality, the API to behave correctly, and for maintainability.\n\n\n\n\nNote\n\n\nTaking business needs, maintainability, extensibility, and perhaps some sort of cost-benefit analysis or ROI, into consideration may be pertinent.\n\n\n\n\nIn order to identify and name resources:\n\n\n\n\nDO\n analyze use cases to find domain nouns that can be operated using \ncreate\n, \nread\n, \nupdate\n, or \ndelete\n operations. Designate each noun as a resource. Use \nPOST\n, \nGET\n, \nPUT\n, or \nDELETE\n operations respectively, on each resource.\n\n\nDO\n design resources to suit client's usage patterns and not design them based on what exists in a database or the object model. \nThink from the client's perspective\n.\n\n\nDO\n use network efficiency, size of representations, and client convenience to guide resource granularity.\n\n\nDO\n think about frequency of change and cacheability. Try to separate immutable (less frequently changing) resources from less cacheable resources.\n\n\nCONSIDER\n the level of abstraction, as it is not always meaningful for developers, if the information conveyed in URIs are too abstract. \n\n\nCONSIDER\n limiting the number of resources to between \n12\n4\n and \n24\n8\n to keep maintenance and service evolution manageable. Avoid mixing different business functionalities in same API.\n\n\nAVOID\n using verbs in your URIs, instead use HTTP verbs to operate on them.\n\n\nAVOID\n blindly applying the same techniques for identifying resources, as for object-oriented design and database modeling.\n\n\nAVOID\n bluntly mapping domain entities into resources, as this may lead to resources that are inefficient and inconvenient to use and also leak irrelevant implementation details out to your public API.\n\n\nDO NOT\n limit yourself to identifying resources based on domain nouns alone, you are likely to find that the fixed set of methods in HTTP is quite a limitation. \nE.g., using a root-level \"Me\" endpoint is perfectly valid.\n\n\n\n\nCollection Resources\n\n\nResources almost always have relationships to other resources, and \ncollection resources\n can give the ability to refer to a group of a resources as one, to perform queries on the collection, or use the collection as a factory to create new resources.\n\n\n\n\nTip\n\n\nA collection resource does not necessarily imply hierarchical containment. A resource may be part of more than one collection resource.\n\n\n\n\nA collection resource should provide sufficient filter mechanisms, as well as pagination. So when organizing resources into collections:\n\n\n\n\nDO\n pluralizing collection resource names. To keep things simple, pragmatic and consistent always use plural to avoid odd pluralization (person/people). Using a mixed model, in which you use singular for some resources and plural for others will make it harder for developers to reason about the API.\n\n\nDO\n provide a way of searching the collection for it members, if applicable.\n\n\nDO\n provide a filtered view of the collection, if applicable.\n\n\nDO\n provide a paginated view of a collection, when appropriate.\n\n\nDO\n embed commonly requested relations alongside the resource, for client convenience.\n\n\nDO\n organize resources according to relationship using path segments (\n/\n), if a relation can only exist within another resource. Sub-resources should be referenced by their name and identifier in the path segments: \n/{resource}/{resource_id}/{sub_resource}/{sub_resource_id}\n.\n\n\nCONSIDER\n providing a link, if a relation can exist independently of the resource. However, if the relation is commonly requested it might be better to always embed the relation's representation, or perhaps offer a functionality to automatically embed the relation's representation and save the client a second round-trip (\nGET /bookings?embed=departures,vehicles\n).\n\n\nAVOID\n sub-sub-resource levels, etc. Try to simplify the association between resources.\n\n\n\n\nComposite Resources\n\n\nAt times it may prove convenient to identify new composite resources.\n\n\n\n\nDO\n identify new resources that aggregate other resources to reduce the number of client/server round-trips, based on client usage patterns, performance, and latency requirements.\n\n\nCONSIDER\n a snapshot page to summarize information, using an URI of the form \nhttps://www.example.org/customer/1234/snapshot\n.\n\n\nCONSIDER\n, if requests for composites are rare, or if network latency is an issue, whether caching may be a better option.\n\n\n\n\nProcessing Functions\n\n\nHaving the public API expose means to support business processes, like, calculate, translate, and convert, is not uncommon depending on the domain.\n\n\nThese may often not map well to nouns in our domain, but usually are in the form of verbs.\n\n\nBy using processing functions to abstract specific services the clients is able to perform tasks such computation or data validation.\n\n\n\n\nDO\n treat the processing function as a resource, as most often it will be difficult to find appropriate nouns. So when validating a vehicle registration number: \nhttps://www.example.org/vehicles/validate?regnum=ZY12345\n\n\nDO\n use \nGET\n to fetch a representation containing the output of the processing function.\n\n\nDO\n use query parameters to supply inputs to the processing function.\n\n\nDO\n document these resources, and make use of verbs clear.\n\n\n\n\nController Resources\n\n\nA \ncontroller\n is a resource that can atomically make changes to resources. It can help abstract complex business operations, which increase the separation of concerns and reduces coupling between clients and servers, which in turn may improve network efficiency.\n\n\n\n\nDO\n designate a controller resource for each distinct operation.\n\n\nDO\n use \nPOST\n to submit a request to trigger the operation.\n\n\nDO\n, if the output of the operation is the creation of a new resource, return \n201 Created\n with a \nLocation\n header referring to the URI of the newly created resource.\n\n\nDO\n, if the outcome is the modification of one or more existing resource, return \n303 See Other\n with a \nLocation\n to a URI that clients can use to fetch a representation of those modifications.\n\n\nDO\n, if the server cannot provide a single URI to all the modified resources, return \n200 OK\n with a representation in the body that clients can use to learn about the outcome.\n\n\nDO\n handle errors as described in \nErrors\n.\n\n\nAVOID\n tunneling at all costs. Instead, use a distinct resource (such as a controller) for each operation. Tunneling occurs whenever the client is using the same method on a single URI for different actions. Tunneling reduces protocol-level visibility, because the visible parts of requests such as the request URI, the HTTP method used, headers, and media types do not unambiguously describe the operation.", 
            "title": "Resources"
        }, 
        {
            "location": "/resources/#resources", 
            "text": "A  resource  is an abstract entity that is identified by a URI, and can be data, processing logic, files, or basically anything else that can be named.", 
            "title": "Resources"
        }, 
        {
            "location": "/resources/#identifying-and-naming-resources", 
            "text": "Most often when identifying resources, the use of nouns instead of verbs will be obvious, however, sometimes it is necessary to veer from this naming convention, when exposing certain services through the public API.  There is no single approach that will work for all the situations, so care should be taking when identifying resources and finding the right resource granularity, in order for API consumers to get the desired functionality, the API to behave correctly, and for maintainability.   Note  Taking business needs, maintainability, extensibility, and perhaps some sort of cost-benefit analysis or ROI, into consideration may be pertinent.   In order to identify and name resources:   DO  analyze use cases to find domain nouns that can be operated using  create ,  read ,  update , or  delete  operations. Designate each noun as a resource. Use  POST ,  GET ,  PUT , or  DELETE  operations respectively, on each resource.  DO  design resources to suit client's usage patterns and not design them based on what exists in a database or the object model.  Think from the client's perspective .  DO  use network efficiency, size of representations, and client convenience to guide resource granularity.  DO  think about frequency of change and cacheability. Try to separate immutable (less frequently changing) resources from less cacheable resources.  CONSIDER  the level of abstraction, as it is not always meaningful for developers, if the information conveyed in URIs are too abstract.   CONSIDER  limiting the number of resources to between  12 4  and  24 8  to keep maintenance and service evolution manageable. Avoid mixing different business functionalities in same API.  AVOID  using verbs in your URIs, instead use HTTP verbs to operate on them.  AVOID  blindly applying the same techniques for identifying resources, as for object-oriented design and database modeling.  AVOID  bluntly mapping domain entities into resources, as this may lead to resources that are inefficient and inconvenient to use and also leak irrelevant implementation details out to your public API.  DO NOT  limit yourself to identifying resources based on domain nouns alone, you are likely to find that the fixed set of methods in HTTP is quite a limitation.  E.g., using a root-level \"Me\" endpoint is perfectly valid.", 
            "title": "Identifying and Naming Resources"
        }, 
        {
            "location": "/resources/#collection-resources", 
            "text": "Resources almost always have relationships to other resources, and  collection resources  can give the ability to refer to a group of a resources as one, to perform queries on the collection, or use the collection as a factory to create new resources.   Tip  A collection resource does not necessarily imply hierarchical containment. A resource may be part of more than one collection resource.   A collection resource should provide sufficient filter mechanisms, as well as pagination. So when organizing resources into collections:   DO  pluralizing collection resource names. To keep things simple, pragmatic and consistent always use plural to avoid odd pluralization (person/people). Using a mixed model, in which you use singular for some resources and plural for others will make it harder for developers to reason about the API.  DO  provide a way of searching the collection for it members, if applicable.  DO  provide a filtered view of the collection, if applicable.  DO  provide a paginated view of a collection, when appropriate.  DO  embed commonly requested relations alongside the resource, for client convenience.  DO  organize resources according to relationship using path segments ( / ), if a relation can only exist within another resource. Sub-resources should be referenced by their name and identifier in the path segments:  /{resource}/{resource_id}/{sub_resource}/{sub_resource_id} .  CONSIDER  providing a link, if a relation can exist independently of the resource. However, if the relation is commonly requested it might be better to always embed the relation's representation, or perhaps offer a functionality to automatically embed the relation's representation and save the client a second round-trip ( GET /bookings?embed=departures,vehicles ).  AVOID  sub-sub-resource levels, etc. Try to simplify the association between resources.", 
            "title": "Collection Resources"
        }, 
        {
            "location": "/resources/#composite-resources", 
            "text": "At times it may prove convenient to identify new composite resources.   DO  identify new resources that aggregate other resources to reduce the number of client/server round-trips, based on client usage patterns, performance, and latency requirements.  CONSIDER  a snapshot page to summarize information, using an URI of the form  https://www.example.org/customer/1234/snapshot .  CONSIDER , if requests for composites are rare, or if network latency is an issue, whether caching may be a better option.", 
            "title": "Composite Resources"
        }, 
        {
            "location": "/resources/#processing-functions", 
            "text": "Having the public API expose means to support business processes, like, calculate, translate, and convert, is not uncommon depending on the domain.  These may often not map well to nouns in our domain, but usually are in the form of verbs.  By using processing functions to abstract specific services the clients is able to perform tasks such computation or data validation.   DO  treat the processing function as a resource, as most often it will be difficult to find appropriate nouns. So when validating a vehicle registration number:  https://www.example.org/vehicles/validate?regnum=ZY12345  DO  use  GET  to fetch a representation containing the output of the processing function.  DO  use query parameters to supply inputs to the processing function.  DO  document these resources, and make use of verbs clear.", 
            "title": "Processing Functions"
        }, 
        {
            "location": "/resources/#controller-resources", 
            "text": "A  controller  is a resource that can atomically make changes to resources. It can help abstract complex business operations, which increase the separation of concerns and reduces coupling between clients and servers, which in turn may improve network efficiency.   DO  designate a controller resource for each distinct operation.  DO  use  POST  to submit a request to trigger the operation.  DO , if the output of the operation is the creation of a new resource, return  201 Created  with a  Location  header referring to the URI of the newly created resource.  DO , if the outcome is the modification of one or more existing resource, return  303 See Other  with a  Location  to a URI that clients can use to fetch a representation of those modifications.  DO , if the server cannot provide a single URI to all the modified resources, return  200 OK  with a representation in the body that clients can use to learn about the outcome.  DO  handle errors as described in  Errors .  AVOID  tunneling at all costs. Instead, use a distinct resource (such as a controller) for each operation. Tunneling occurs whenever the client is using the same method on a single URI for different actions. Tunneling reduces protocol-level visibility, because the visible parts of requests such as the request URI, the HTTP method used, headers, and media types do not unambiguously describe the operation.", 
            "title": "Controller Resources"
        }, 
        {
            "location": "/rest/", 
            "text": "REpresentational State Transfer (REST)\n\n\nWe will focus our discussion on REST. Especially on how to achieve a more RESTful web API, by leveraging the capabilities of HTTP. For more information about REST itself, please refer to the \nWikipedia article on REST\n or \nWhat is REST?\n.\n\n\nSome of the aspects of designing RESTful web APIs include:\n\n\n\n\nUnique identification\n of resources by using URIs.\n\n\nOperation on resources by using the available \nHTTP methods\n.\n\n\nA choice of \nformats and media types\n that allow clients to specify representation formats they can render, and for servers to honor those (or indicate if it cannot).\n\n\nLinking\n between resources to indicate relationships (e.g., hypermedia links).\n\n\n\n\nRichardson Maturity Model\n\n\nToday, most web APIs are not truly RESTful APIs, instead they tend to be of a varying degree of RESTful. Therefore, the \nRichardson Maturity Model\n is often used to describe what it takes to make a well-designed RESTful API:\n\n\n\n\n\n\nLevel 0\n: Uses HTTP as a transport mechanism for RPC.\n\n\nLevel 1\n: Uses URIs for individual resources, but does not use HTTP methods, media types, or linking between resources.\n\n\nLevel 2\n: Uses HTTP methods and headers for interactions with resources, and returns appropriate HTTP status codes.\n\n\nLevel 3\n: Uses hypermedia controls for discoverability, which also helps making an API more self-documenting.\n\n\n\n\n\n\nSo a good RESTful API should\n\n\n\n\nUse unique URIs to expose resources for clients to use.\n\n\nUse the full spectrum of HTTP, to perform operations on those resources, and allow different representations of content.\n\n\nProvide relational links for resources, to inform the client what can be done next.\n\n\n\n\n\n\nWhat's in the Box?\n\n\nIn these guidelines we will offer advise on how to achieve this, when implementing clients as well as servers. Specifically we will focus on:\n\n\n\n\nHow to identify resources by using URIs\n\n\nHow to use the available HTTP methods\n\n\nWhat representation formats to you expose and what to do when the server cannot fulfill a request for a given representation\n\n\nHow to report errors, using HTTP status codes and representations\n\n\nHow to handle security, including HTTP authentication, OAuth2, and API tokens\n\n\nHow to handle hypermedia linking\n\n\nHow to document your API\n\n\n\n\nAnything else?\n\n\nBefore we get Started\n\n\nBecause REST is an architectural style and not a strict standard, it allows for a lot of flexibly. So before jumping straight into designing an API, it can be helpful to think about:\n\n\n\n\nthe target audience, i.e. customers, third-party services, or other developers looking to take advantage of your services for their own customers.\n\n\nease of life for the consuming developers\n\n\nuse cases\n\n\ntechnologies used\n\n\nproducts/services to expose\n\n\nother services to interact with\n\n\n\n\nAs long as the API only has one consumer, one could argue that it's entire job is to service that consumer. \n\n\n\n\nMake it RESTful, but be pragmatic!\n\n\nAiming at a level above 2, according to Richardson's Maturity Model, may simply be impractical.", 
            "title": "REpresentational State Transfer (REST)"
        }, 
        {
            "location": "/rest/#representational-state-transfer-rest", 
            "text": "We will focus our discussion on REST. Especially on how to achieve a more RESTful web API, by leveraging the capabilities of HTTP. For more information about REST itself, please refer to the  Wikipedia article on REST  or  What is REST? .  Some of the aspects of designing RESTful web APIs include:   Unique identification  of resources by using URIs.  Operation on resources by using the available  HTTP methods .  A choice of  formats and media types  that allow clients to specify representation formats they can render, and for servers to honor those (or indicate if it cannot).  Linking  between resources to indicate relationships (e.g., hypermedia links).", 
            "title": "REpresentational State Transfer (REST)"
        }, 
        {
            "location": "/rest/#richardson-maturity-model", 
            "text": "Today, most web APIs are not truly RESTful APIs, instead they tend to be of a varying degree of RESTful. Therefore, the  Richardson Maturity Model  is often used to describe what it takes to make a well-designed RESTful API:    Level 0 : Uses HTTP as a transport mechanism for RPC.  Level 1 : Uses URIs for individual resources, but does not use HTTP methods, media types, or linking between resources.  Level 2 : Uses HTTP methods and headers for interactions with resources, and returns appropriate HTTP status codes.  Level 3 : Uses hypermedia controls for discoverability, which also helps making an API more self-documenting.    So a good RESTful API should   Use unique URIs to expose resources for clients to use.  Use the full spectrum of HTTP, to perform operations on those resources, and allow different representations of content.  Provide relational links for resources, to inform the client what can be done next.", 
            "title": "Richardson Maturity Model"
        }, 
        {
            "location": "/rest/#whats-in-the-box", 
            "text": "In these guidelines we will offer advise on how to achieve this, when implementing clients as well as servers. Specifically we will focus on:   How to identify resources by using URIs  How to use the available HTTP methods  What representation formats to you expose and what to do when the server cannot fulfill a request for a given representation  How to report errors, using HTTP status codes and representations  How to handle security, including HTTP authentication, OAuth2, and API tokens  How to handle hypermedia linking  How to document your API   Anything else?", 
            "title": "What's in the Box?"
        }, 
        {
            "location": "/rest/#before-we-get-started", 
            "text": "Because REST is an architectural style and not a strict standard, it allows for a lot of flexibly. So before jumping straight into designing an API, it can be helpful to think about:   the target audience, i.e. customers, third-party services, or other developers looking to take advantage of your services for their own customers.  ease of life for the consuming developers  use cases  technologies used  products/services to expose  other services to interact with   As long as the API only has one consumer, one could argue that it's entire job is to service that consumer.    Make it RESTful, but be pragmatic!  Aiming at a level above 2, according to Richardson's Maturity Model, may simply be impractical.", 
            "title": "Before we get Started"
        }, 
        {
            "location": "/security/", 
            "text": "Security\n\n\nMUST: Secure Endpoints with OAuth 2.0\n\n\n\n\nOut-of-band authentication\n\n\nCORS\n\n\nUse Access and Refresh Tokens\n\n\nAccess Tokens\n\n\nRefresh Tokens\n\n\nLogging In\n\n\nRenewing a Token\n\n\nValidating a Token\n\n\nTerminating a Session\n\n\nKeep JWTs Small\n\n\n\n\n\n\n\n\nAlways use SSL. No exceptions. One thing to watch out for is non-SSL access to API URLs. Do not redirect these to their SSL counterparts. Throw a hard error instead!\n\n\nA RESTful API should be stateless. This means that request authentication should not depend on cookies or sessions. Instead, each request should come with some sort authentication credentials.\n\n\n\n\nAn API Manager should also be designed to handle security, not just by validating a boarding pass (API key) and directing them to their appropriate gate (permissions, SLA tier), but your API Manager should watch out for other dangerous threats, such as malicious IPs, DDoS, content threats (such as with JSON or XML), and others.\nIt should also be designed to work with your current user validation systems such as OAuth2 to help protect your user's sensitive data (such as their username and password) within your API.\n\n\nKeep in mind that even the most righteous of applications are still prone to being hacked \u2013 and if they have access to your user's sensitive data, that means that hackers might get access to it too.\n\n\nIt's always better to never have your users expose their credentials through the API (such as with basic auth) but instead rely on your website to handle logins and then return back an access token as OAuth2 does.\n\n\nBut... Security is Hard\n\n\nOne of my favorite talks, by Anthony Ferrara sums this up very nicely...  Don't do it.\n\n\nLeave it for the Experts.\n\n\nGranted, his talk was specifically on encryption, but there's a lot of careful thought, planning, and considerations that need to be taken when building an API Management tool.\n\n\nYou can certainly build it yourself, and handling API keys or doing IP white-listing/ black-listing is fairly easy to do.\n\n\nHowever, like an airport, what you don't see is all of the stuff happening in the background, all the things being monitored carefully, security measures implemented by experts with years of experience in risk mitigation.\n\n\nFor that reason, as tempting as it might be to build one yourself, I would strongly encourage you to take a look at a professional API Management company- such as MuleSoft (of course, I might be a little biased).\n\n\nAuthentication\n\n\nThere are many schools of thought. My colleagues at Apigee and I don't always agree on how to handle authentication - but overall here's my take.\n\n\nLet's look at these three top services. See how each of these services handles things differently:\n\n\n\n\nPayPal\n\n\nPermissions Service API\n\n\nFacebook\n\n\nOAuth 2.0\n\n\nTwitter\n\n\nOAuth 1.0a\n\n\n\n\nNote that PayPal's proprietary three-legged permissions API was in place long before OAuth was conceived.\n\n\nWhat should you do?\n\n\nUse the latest and greatest OAuth - OAuth 2.0 (as of this writing). It means that Web or mobile apps that expose APIs don't have to share passwords. It allows the API provider to revoke tokens for an individual user, for an entire app, without requiring the user to change their original password. This is critical if a mobile device is compromised or if a rogue app is discovered.\n\n\nAbove all, OAuth 2.0 will mean improved security and better end-user and consumer experiences with Web and mobile apps.\n\n\nDon't do something \nlike\n OAuth, but different. It will be frustrating for app developers if they can't use an OAuth library in their language because of your variation.\n\n\nSecurity\n\n\nSecuring may require:\n\n\n\n\nensure that only authenticated users access resources\n\n\nensure the condidentiality and integrity of information right from the moment it is collected until the time it is stored and later presented to authorized entities or users.\n\n\nprevent unauthorized or malicious clients from abusing resources and data.\n\n\nmaintain privacy, and follow the laws of the land that govern various security aspects.\n\n\n\n\nHow to use Basic Authentication to Authenticate Clients\n\n\n\n\nreturn \n401 Authorization Required\n along with a \nWWW-Authenticate: Basic realm=\nSome name\n.\n\n\n\n\nOn the client, concatenate the client identifier (a username if the client is making a request on behalf of a user) and the shared secret (password) as \nidentifier\n:\nsecret\n and then compute the Base64 encoding on this text. Include the value in the \nAuthorization: Basic \nBase64 encoded value\n. On the server decode the text and verify the values.\n\n\nDo not use basic authentication unless using TLS to connect to the server.\n\n\nHow to use Three-Legged OAuth\nHow to use Two-Legged OAuth\nHow to Deal with Sensitive Information in URIs\n\n\nHow to Maintain the Confidentiality and Integrity of Representations\n\n\nuse TLS and make resource accessible over a server configured to serve request only using HTTPS.\n\n\nAuthentication is Key\n\n\nBy providing your API users with a unique API token, or API key you can tell exactly who is making calls to your API.\n\n\nAlong with having quick access to determining potential malicious users which can immediately be removed, you can also set permissions and SLAs for users depending on their individual needs.\n\n\nThis means that you can set a default SLA for most users, giving them say only 4 calls per second, but for silver partners they get 10 calls per second, for gold partners 100 calls per second, etc.\n\n\nThis means that you can not only identify abuse quickly, but also help prevent it by limiting their access to certain aspects of your API, and by limiting the number of calls they can make to your API.", 
            "title": "Security"
        }, 
        {
            "location": "/security/#security", 
            "text": "", 
            "title": "Security"
        }, 
        {
            "location": "/security/#must-secure-endpoints-with-oauth-20", 
            "text": "Out-of-band authentication  CORS  Use Access and Refresh Tokens  Access Tokens  Refresh Tokens  Logging In  Renewing a Token  Validating a Token  Terminating a Session  Keep JWTs Small     Always use SSL. No exceptions. One thing to watch out for is non-SSL access to API URLs. Do not redirect these to their SSL counterparts. Throw a hard error instead!  A RESTful API should be stateless. This means that request authentication should not depend on cookies or sessions. Instead, each request should come with some sort authentication credentials.   An API Manager should also be designed to handle security, not just by validating a boarding pass (API key) and directing them to their appropriate gate (permissions, SLA tier), but your API Manager should watch out for other dangerous threats, such as malicious IPs, DDoS, content threats (such as with JSON or XML), and others.\nIt should also be designed to work with your current user validation systems such as OAuth2 to help protect your user's sensitive data (such as their username and password) within your API.  Keep in mind that even the most righteous of applications are still prone to being hacked \u2013 and if they have access to your user's sensitive data, that means that hackers might get access to it too.  It's always better to never have your users expose their credentials through the API (such as with basic auth) but instead rely on your website to handle logins and then return back an access token as OAuth2 does.", 
            "title": "MUST: Secure Endpoints with OAuth 2.0"
        }, 
        {
            "location": "/security/#but-security-is-hard", 
            "text": "One of my favorite talks, by Anthony Ferrara sums this up very nicely...  Don't do it.  Leave it for the Experts.  Granted, his talk was specifically on encryption, but there's a lot of careful thought, planning, and considerations that need to be taken when building an API Management tool.  You can certainly build it yourself, and handling API keys or doing IP white-listing/ black-listing is fairly easy to do.  However, like an airport, what you don't see is all of the stuff happening in the background, all the things being monitored carefully, security measures implemented by experts with years of experience in risk mitigation.  For that reason, as tempting as it might be to build one yourself, I would strongly encourage you to take a look at a professional API Management company- such as MuleSoft (of course, I might be a little biased).", 
            "title": "But... Security is Hard"
        }, 
        {
            "location": "/security/#authentication", 
            "text": "There are many schools of thought. My colleagues at Apigee and I don't always agree on how to handle authentication - but overall here's my take.  Let's look at these three top services. See how each of these services handles things differently:   PayPal  Permissions Service API  Facebook  OAuth 2.0  Twitter  OAuth 1.0a   Note that PayPal's proprietary three-legged permissions API was in place long before OAuth was conceived.  What should you do?  Use the latest and greatest OAuth - OAuth 2.0 (as of this writing). It means that Web or mobile apps that expose APIs don't have to share passwords. It allows the API provider to revoke tokens for an individual user, for an entire app, without requiring the user to change their original password. This is critical if a mobile device is compromised or if a rogue app is discovered.  Above all, OAuth 2.0 will mean improved security and better end-user and consumer experiences with Web and mobile apps.  Don't do something  like  OAuth, but different. It will be frustrating for app developers if they can't use an OAuth library in their language because of your variation.", 
            "title": "Authentication"
        }, 
        {
            "location": "/security/#security_1", 
            "text": "Securing may require:   ensure that only authenticated users access resources  ensure the condidentiality and integrity of information right from the moment it is collected until the time it is stored and later presented to authorized entities or users.  prevent unauthorized or malicious clients from abusing resources and data.  maintain privacy, and follow the laws of the land that govern various security aspects.   How to use Basic Authentication to Authenticate Clients   return  401 Authorization Required  along with a  WWW-Authenticate: Basic realm= Some name .   On the client, concatenate the client identifier (a username if the client is making a request on behalf of a user) and the shared secret (password) as  identifier : secret  and then compute the Base64 encoding on this text. Include the value in the  Authorization: Basic  Base64 encoded value . On the server decode the text and verify the values.  Do not use basic authentication unless using TLS to connect to the server.  How to use Three-Legged OAuth\nHow to use Two-Legged OAuth\nHow to Deal with Sensitive Information in URIs  How to Maintain the Confidentiality and Integrity of Representations  use TLS and make resource accessible over a server configured to serve request only using HTTPS.", 
            "title": "Security"
        }, 
        {
            "location": "/security/#authentication-is-key", 
            "text": "By providing your API users with a unique API token, or API key you can tell exactly who is making calls to your API.  Along with having quick access to determining potential malicious users which can immediately be removed, you can also set permissions and SLAs for users depending on their individual needs.  This means that you can set a default SLA for most users, giving them say only 4 calls per second, but for silver partners they get 10 calls per second, for gold partners 100 calls per second, etc.  This means that you can not only identify abuse quickly, but also help prevent it by limiting their access to certain aspects of your API, and by limiting the number of calls they can make to your API.", 
            "title": "Authentication is Key"
        }, 
        {
            "location": "/throttling/", 
            "text": "Throttling\n\n\nThrottling and rate limiting is not necessarily a bad thing. By throttling your API and setting up different SLA tiers you are able to help prevent abuse \u2013 often times completely accidental. This means that your API is able to operate optimally for all of your users, instead of having one infinite loop bring it crashing down for everyone.\n\n\nYou may have partners that need more calls than others, or who the limits do not make sense for. By setting up SLA tiers based on your standard API user's needs, and then creating partner tiers, you can easily give the the permissions they need, while limiting the standard user to prevent abuse.\n\n\nThe API key, or unique identifier for an user's application also helps you identify who your heavier users are \u2013 letting you get in contact with them to make sure their needs are being met, while also learning more about how they are using your API.\n\n\n\n\nRate limiting (Twitter-style)\n\n\n\n\nX-Rate-Limit-Limit - The number of allowed requests in the current period\n\n\nX-Rate-Limit-Remaining - The number of remaining requests in the current period\n\n\nX-Rate-Limit-Reset - The number of seconds left in the current period\n\n\n\n\n\n\nMUST: Use 429 with Headers for Rate Limits\n\n\nAPIs that wish to manage the request rate of clients must use the '429 Too Many Requests' response code if the client exceeded the request rate and therefore the request can't be fulfilled. Such responses must also contain header information providing further details to the client. There are two approaches a service can take for header information:\n\n\nReturn a 'Retry-After' header indicating how long the client ought to wait before making a follow-up request. The Retry-After header can contain a HTTP date value to retry after or the number of seconds to delay. Either is acceptable but APIs should prefer to use a delay in seconds.\n\n\nReturn a trio of 'X-RateLimit' headers. These headers (described below) allow a server to express a service level in the form of a number of allowing requests within a given window of time and when the window is reset.\n\n\nThe 'X-RateLimit' headers are:\n\n\nX-RateLimit-Limit: The maximum number of requests that the client is allowed to make in this window.\nX-RateLimit-Remaining: The number of requests allowed in the current window.\nX-RateLimit-Reset: The relative time in seconds when the rate limit window will be reset.\nThe reason to allow both approaches is that APIs can have different needs. Retry-After is often sufficient for general load handling and request throttling scenarios and notably, does not strictly require the concept of a calling entity such as a tenant or named account. In turn this allows resource owners to minimise the amount of state they have to carry with respect to client requests. The 'X-RateLimit' headers are suitable for scenarios where clients are associated with pre-existing account or tenancy structures. 'X-RateLimit' headers are generally returned on every request and not just on a 429, which implies the service implementing the API is carrying sufficient state to track the number of requests made within a given window for each named entity.", 
            "title": "Throttling"
        }, 
        {
            "location": "/throttling/#throttling", 
            "text": "Throttling and rate limiting is not necessarily a bad thing. By throttling your API and setting up different SLA tiers you are able to help prevent abuse \u2013 often times completely accidental. This means that your API is able to operate optimally for all of your users, instead of having one infinite loop bring it crashing down for everyone.  You may have partners that need more calls than others, or who the limits do not make sense for. By setting up SLA tiers based on your standard API user's needs, and then creating partner tiers, you can easily give the the permissions they need, while limiting the standard user to prevent abuse.  The API key, or unique identifier for an user's application also helps you identify who your heavier users are \u2013 letting you get in contact with them to make sure their needs are being met, while also learning more about how they are using your API.   Rate limiting (Twitter-style)   X-Rate-Limit-Limit - The number of allowed requests in the current period  X-Rate-Limit-Remaining - The number of remaining requests in the current period  X-Rate-Limit-Reset - The number of seconds left in the current period", 
            "title": "Throttling"
        }, 
        {
            "location": "/throttling/#must-use-429-with-headers-for-rate-limits", 
            "text": "APIs that wish to manage the request rate of clients must use the '429 Too Many Requests' response code if the client exceeded the request rate and therefore the request can't be fulfilled. Such responses must also contain header information providing further details to the client. There are two approaches a service can take for header information:  Return a 'Retry-After' header indicating how long the client ought to wait before making a follow-up request. The Retry-After header can contain a HTTP date value to retry after or the number of seconds to delay. Either is acceptable but APIs should prefer to use a delay in seconds.  Return a trio of 'X-RateLimit' headers. These headers (described below) allow a server to express a service level in the form of a number of allowing requests within a given window of time and when the window is reset.  The 'X-RateLimit' headers are:  X-RateLimit-Limit: The maximum number of requests that the client is allowed to make in this window.\nX-RateLimit-Remaining: The number of requests allowed in the current window.\nX-RateLimit-Reset: The relative time in seconds when the rate limit window will be reset.\nThe reason to allow both approaches is that APIs can have different needs. Retry-After is often sufficient for general load handling and request throttling scenarios and notably, does not strictly require the concept of a calling entity such as a tenant or named account. In turn this allows resource owners to minimise the amount of state they have to carry with respect to client requests. The 'X-RateLimit' headers are suitable for scenarios where clients are associated with pre-existing account or tenancy structures. 'X-RateLimit' headers are generally returned on every request and not just on a 429, which implies the service implementing the API is carrying sufficient state to track the number of requests made within a given window for each named entity.", 
            "title": "MUST: Use 429 with Headers for Rate Limits"
        }, 
        {
            "location": "/versioning-and-extensibility/", 
            "text": "Versioning and Extensibility\n\n\n\n\nversioning\n\n\nUse API Versioning\n\n\n\n\n\n\nwhat is a breaking change\n\n\nbreaking changes\n\n\n\n\nhttp://www.jenitennison.com/2009/07/22/versioning-uris.html\n\n\nA lot of things that we want to talk about (make RDF assertions about) are non-information resources. We give them URIs to name them, so that we can talk about them unambiguously, and we give them HTTP URIs so that we have a way of finding information resources (documents) that give us information about them.\n\n\n\n\nnon-information resource URIs must not include information that is likely to change\n\n\nnon-information resource URIs must not include unnecessary hierarchy\n\n\n\n\nAlways version your API. Versioning helps you iterate faster and prevents invalid requests from hitting updated endpoints. It also helps smooth over any major API version transitions as you can continue to offer old API versions for a period of time.\nHowever, the version needs to be in the URL to ensure browser explorability of the resources across versions\nWell documented and announced multi-month deprecation schedules can be an acceptable practice for many APIs.\n\nhttps://stripe.com/docs/api#versioning\n\n\n\n\nLike building an application it is important to keep your API standardized and extensible.\n\n\nIt's easy to want to add \"quick fixes\" to make customers happy, but everything you do should be carefully thought out in order to make sure your API continues to serve not only your needs, but also your clients.\n\n\nRemember, when you create an API you are creating a contract- your users are depending on your API not just to make their application work, but in order to make a living and feed their families.\n\n\nWhen you break things, or when you break backwards compatibility you are taking their time and resources to fix their application instead of adding features and keeping their customers happy.\n\n\n\n\nThe industry solution to this has been versioning, however, versioning is merely a Band-Aid, a temporary solution to make migration to the new system less stressful for your clients, but increasingly difficult on you.\n\n\nKeep in mind, when you have multiple versions of your API you end up supporting and maintaining those versions.\n\n\nOne of the greatest challenges in regards to versioning is getting developers to migrate from one version to another, all while keeping your support staff from going insane.\n\n\nThis doesn't mean that you shouldn't plan for versioning.\n\n\nRather it means that you should plan to incorporate a version identifier (either in the URI or in the content-header of the response), but work under the mindset that you will only version your API if...\n\n\n\n\nYou have backwards incompatible PLATFORM changes \u2013 in other words you completely change the UI or way your platform works\n\n\nYou find that your API is no longer extendable \u2013 which is exactly what we are trying to avoid here\n\n\nYou find that your spec no longer meets your developer's needs \u2013 for example, they are demanding REST instead of SOAP\n\n\n\n\nYou should NOT version your API just because:\n\n\n\n\nYou added additional endpoints\n\n\nYou added additional data in the response\n\n\nYou changed technologies \u2013 your API should be decoupled from your technology stack\n\n\nYou changed your applications services or code \u2013 your API should be decoupled from your service layer\n\n\n\n\nTo clarify on the last two, it shouldn't matter what technologies you are using, or how your services work.\n\n\nThe API should interact with both, but be decoupled enough that changing something in the background does not effect the API adversely.\n\n\nAny changes you make to your API in regards to the technology or service layer should be as seamless and transparent as possible.\n\n\nAfter all, the less you can break backwards compatibility, the happier you, and your customers will be.\n\n\nAnd this can only happen if you go into building your API with a long-term, flexibility, and extensibility focus.\n\n\nExtensibility and Versioning\n\n\nManaging change in any distributed client/server environment can be hard. In these environments, clients count on servers to honor their contracts.\n\n\nWhen a change is backward compatible, you need not upgrade clients at the same time as you modify the server.\n\n\nForward compatibility\n may be important when you have several clients and servers upgraded at different points in time. In this case, some newer clients may be interacting with older servers. The purpose of forward compatibility is to ensure that newer clients can continue to use the older servers without disruption albeit with reduced functionality.\n\n\nThe characteristic that lets you maintain compatibility is \nextensibility\n. Extensibility is a design process to account for future changes.\n\n\nAs a transfer protocol, HTTP is extensible, but that does not mean that APIs built over HTTP are automatically extensible.\n\n\nIt takes discipline, careful planning, and defensive coding practices.\n\n\nA one-time simultaneous upgrade of all server and clients is not a realistic task. You need to plan for a gradual rollout of upgrades to servers and clients to maintain the availability of the overall system.\n\n\nNote that both clients and server need to take the appropriate steps to operate smoothly under change. For the server, the goal is to keep the clients from breaking. For the clients, the objective is not fail when new unknown data or links appear in representations.\n\n\nHow to Maintain URI Compatibility (\nurl regression\n)\n\n\nKeeps URIs permanent.\n\n\nTreat URIs containing the same query parameters but in a different order as the same\n\n\nWhen you add new parameters to URIs, continue to honor existing parameters, and treat new parameters as optional.\n\n\nWhen changing data formats for query parameters, continue to honor existing formats. If that is not viable, introduce format changes via new query parameters or new URIs.\n\n\nTreat query parameters in URIs as optional except when need for concurrency and security.\n\n\n\n\nDO\n use rewrite rules on the server to shield clients from implementation-level changes.\n\n\nDO\n use \n301 Moved Permanently\n with the new URI in the \nLocation\n header, when URIs must change to honor old URIs.\n\n\nDO\n monitor request traffic for redirection.\n\n\nDO\n maintain redirection services until you are confident the majority of clients have updated their stored links to point to the new URI.\n\n\nDO\n communicate an appropriate end-of-life policy for old URIs, when you cannot monitor the old URIs.\n\n\nDO\n convert \n301 Moved Permanently\n to \n410 Gone\n or \n404 Not Found\n once the traffic has fallen of or the preset time interval has passed.\n\n\n\n\nHow to Maintain Compatibility of XML and JSON Representations\n\n\nWhen making changes to JSON preserve the hierarchical structure so that clients can continue to follow the same structure to extract data.\n\n\nMake new data elements in requests optional to maintain compatibility with existing clients. Clients that do not send new data fields must be able to continue to function.\n\n\nDo not remove or rename any data fields from representaions in reponse bodies.\n\n\nExample: Clients that do not understand new fields may not store them locally. If this causes the server to assume the user has no email address, introduce a new version of the resource that contains the email.\n\n\nHow to Maintain Compatibility of Links\n\n\nAvoid removing links\nDo not change the value of the \nrel\n and \nhref\n attributes of links.\nWhen introducing new resources, use links to provide URIs of those resources to clients.\n\n\nWhen to Version\n\n\nConsider versioning when the server cannot maintain compatibility. Also consider versioning if some clients require behavior or functionality different from other clients.\n\n\nVersioning may introduce new problems:\n\n\n\n\nData stored by the clients for one version may not automatically work with the data from a different version. Clients may have to port resource data stored locally before migrating to the new version.\n\n\nVersion changes may involve new business rules and new application flow, which requires code changes in clients.\n\n\nMaintaining multiple versions of resources at the same time is not trivial.\n\n\nWhen you use links to convey URIs to clients, clients may store them locally. When you assign new URIs, clients will have to upgrade those URIs along with other stored data of resources.\n\n\n\n\nHow to Version RESTful Web Services\n\n\nAdd new resources with new URIs when there is a change in the behavior of resource or a change in the information contained in representations.\n\n\nUse easily detectable patterns such as \nv1\n or \nv2\n in subdomain names, path segments, or query parameters to distinguish URIs by their version.\n\n\nAvoid treating each version as a new representation with a new media type of the same resource.\n\n\nVersioning involves versioning resources with new URIs. This is because HTTP dictates everything except URIs of resources and their representations. Although you can add custom HTTP methods and headers, such additions may impair interoperability.\n\n\nAvoid introducing new media types for each version since it leads to media type proliferation, which reduce interoperability.\n\n\nCompatibility\n\n\nMUST: Don't Break Backward Compatibility\n\n\nChange APIs, but keep all consumers running.\n\n\nConsumers usually have independent release life-cycles, focus on stability, and avoid changes that do not provide additional value. APIs are contracts between service providers and service consumers that cannot be broken via unilateral decisions.\n\n\nThere are two techniques to change APIs without breaking them:\n\n\n\n\nfollow rules for compatible extensions\n\n\nintroduce new API versions and still support older versions\n\n\n\n\nWe strongly encourage using compatible API extensions and discourage versioning. The below guideline rules for service providers and consumers enable us (having Postel's Law in mind) to make compatible changes without versioning.\n\n\nHint: Please note that the compatibility guarantees are for the \"on the wire\" format. Binary or source compatibility of code generated from an API definition is not covered by these rules. If client implementations update their generation process to a new version of the API definition, it has to be expected that code changes are necessary.\n\n\nSHOULD:: Prefer Compatible Extensions\n\n\nAPI designers should apply the following rules to evolve RESTful APIs for services in a backward-compatible way:\n\n\n\n\nAdd only optional, never mandatory fields.\n\n\nNever change the semantic of fields (e.g. changing the semantic from customer-number to customer-id, as both are different unique customer keys)\n\n\nInput fields may have (complex) constraints being validated via server-side business logic. - - Never change the validation logic to be more restrictive and make sure that all constraints a clearly defined in description.\n\n\nEnum ranges can be reduced when used as input parameters, only if the server is ready to accept and handle old range values too. Enum range can be reduced when used as output parameters.\n\n\nEnum ranges cannot not be extended when used for output parameters \u2014 clients may not be prepared to handle it. However, enum ranges can be extended when used for input parameters.\n\n\nSupport redirection in case an URL has to change (301 Moved Permanently).\n\n\n\n\nMUST: Prepare Clients To Not Crash On Compatible API Extensions\n\n\nService clients should apply the robustness principle:\n\n\n\n\nBe conservative with API requests and data passed as input, e.g. avoid to exploit definition eficits like passing megabytes for strings with unspecified maximum length.\n\n\nBe tolerant in processing and reading data of API responses, more specifically...\n\n\n\n\nService clients must be prepared for compatible API extensions of service providers:\n\n\n\n\nBe tolerant with unknown fields in the payload (see also Fowler's \"TolerantReader\" post), i.e. ignore new fields but do not eliminate them from payload if needed for subsequent PUT requests.\n\n\nBe prepared to handle HTTP status codes not explicitly specified in endpoint definitions. Note also, that status codes are extensible. Default handling is how you would treat the corresponding x00 code (see RFC7231 Section 6).\n\n\nFollow the redirect when the server returns HTTP status 301 Moved Permanently.\n\n\n\n\nSHOULD:: Design APIs Conservatively\n\n\nDesigners of service provider APIs should be conservative and accurate in what they accept from clients:\n\n\n\n\nUnknown input fields in payload or URL should not be ignored; servers should provide error feedback to clients via an HTTP 400 response code.\n\n\nBe accurate in defining input data constraints (like formats, ranges, lengths etc.) \u2014 and check constraints and return dedicated error information in case of violations.\n\n\nPrefer being more specific and restrictive (if compliant to functional requirements), e.g. by defining length range of strings. It may simplify implementation while providing freedom for further evolution as compatible extensions.\n\n\n\n\nNot ignoring unknown input fields is a specific deviation from Postel's Law (e.g. see also\nThe Robustness Principle Reconsidered) and a strong recommendation. Servers might want to take different approach but should be aware of the following problems and be explicit in what is supported:\n\n\nIgnoring unknown input fields is actually not an option for PUT, since it becomes asymmetric with subsequent GET response and HTTP is clear about the PUT \"replace\" semantics and default round-trip expectations (see RFC7231 Section 4.3.4). Note, accepting (i.e. not ignoring) unknown input fields and returning it in subsequent GET responses is a different situation and compliant to PUT semantics.\n\n\nCertain client errors cannot be recognized by servers, e.g. attribute name typing errors will be ignored without server error feedback. The server cannot differentiate between the client intentionally providing an additional field versus the client sending a mistakenly named field, when the client's actual intent was to provide an optional input field.\nFuture extensions of the input data structure might be in conflict with already ignored fields and, hence, will not be compatible, i.e. break clients that already use this field but with different type.\n\n\nIn specific situations, where a (known) input field is not needed anymore, it either can stay in the API definition with \"not used anymore\" description or can be removed from the API definition as long as the server ignores this specific parameter.\n\n\nMUST: Always Return JSON Objects As Top-Level Data Structures To Support Extensibility\n\n\nIn a response body, you must always return a JSON objects (and not e.g. an array) as a top level data structure to support future extensibility. JSON objects support compatible extension by additional attributes. This allows you to easily extend your response and e.g. add pagination later, without breaking backwards compatibility.\n\n\nSHOULD:: Avoid Versioning\n\n\nWhen changing your RESTful APIs, do so in a compatible way and avoid generating additional API versions. Multiple versions can significantly complicate understanding, testing, maintaining, evolving, operating and releasing our systems (supplementary reading).\n\n\nIf changing an API can't be done in a compatible way, then proceed in one of these three ways:\n\n\n\n\ncreate a new resource (variant) in addition to the old resource variant\n\n\ncreate a new service endpoint \u2014 i.e. a new application with a new API (with a new domain name)\n\n\ncreate a new API version supported in parallel with the old API by the same microservice\n\n\n\n\nAs we discourage versioning by all means because of the manifold disadvantages, we suggest to only use the first two approaches.\n\n\nMUST: Use Media Type Versioning\n\n\nWhen API versioning is unavoidable, you have to design your multi-version RESTful APIs using media type versioning (instead of URI versioning, see below). Media type versioning is less tightly coupled since it supports content negotiation and hence reduces complexity of release management.\n\n\nMedia type versioning: Here, version information and media type are provided together via the HTTP Content-Type header \u2014 e.g. application/x.zalando.cart+json;version=2. For incompatible changes, a new media type version for the resource is created. To generate the new representation version, consumer and producer can do content negotiation using the HTTP Content-Type and Accept headers. Note: This versioning only applies to the request and response content schema, not to URI or method semantics.\n\n\nIn this example, a client wants only the new version of the response:\n\n\nAccept: application/x.zalando.cart+json;version=2\nA server responding to this, as well as a client sending a request with content should use the Content-Type header, declaring that one is sending the new version:\n\n\nContent-Type: application/x.zalando.cart+json;version=2\n\n\nUsing header versioning should:\n\n\n\n\ninclude versions in request and response headers to increase visibility\n\n\ninclude Content-Type in the Vary header to enable proxy caches to differ between versions\n\n\n\n\n\n\nHint: OpenAPI currently doesn't support content negotiation, though a comment in this issue mentions a workaround (using a fragment identifier that gets stripped off). Another way would be to document just the new version, but let the server accept the old one (with the previous content-type).\n\n\n\n\nUntil an incompatible change is necessary, it is recommended to stay with the standard application/json media type.\n\n\nMUST: Do Not Use URI Versioning\n\n\nWith URI versioning a (major) version number is included in the path, e.g. /v1/customers. The consumer has to wait until the provider has been released and deployed. If the consumer also supports hypermedia links \u2014 even in their APIs \u2014 to drive workflows (HATEOAS), this quickly becomes complex. So does coordinating version upgrades \u2014 especially with hyperlinked service dependencies \u2014 when using URL versioning. To avoid this tighter coupling and complexer release management we do not use URI versioning, and go instead with media type versioning and content negotiation (see above).\n\n\nThe API will inevitably need to be modified in ways that will impact customer client code. Not all customer clients will be able to make the necessary changes in their code right away, so the API should maintain older versions for some time after releasing the new version, usually a minimum of 90 days.\n\n\nIn the \u2018When to Version\u2019 section should you mention APIs that use enum types? My company\u2019s API reference documentation has attributes with an enum type and we list all values. We ran into a problem when a requirement added an enum value to an existing attribute and it broke a partner app. The partner had coded to the defined enum values in the documentation and their app wasn\u2019t expecting new values with future releases. I corrected the problem by removing the new enum value and I defined any request to add a new enum value to an existing attribute requires a new API version. Last, going forward new attributes with an enum type will be defined as String in the documentation and we will indicate the values are not limited to the ones defined.\n\n\nVersioning Content Types\n\n\nThe use of content negotiation with custom MIME types allows for finer grained versioning at the resource level without the need to create a plethora of new endpoints. New versions must be communicated to developers through existing channels \u2013 email, developer blogs, etc. When a content version is no longer supported, the body of the HTTP error should include a list of supported content types.\n\n\nVersioning URIs\n\n\nThe use of both hyper links and content negotiation should all but eliminate the need to version at the URI level. However, there may be instances where the entire structure of the API must be changed, particularly when moving from one API style to another, such when moving from an RPC-type style to NARWHL. To prepare for these possibilities, it\u2019s recommended that a version be embedded within each API endpoint. The version can either be embedded at the root for all endpoints of a given API, such as:\n\n\nhttp://api.example.com/v1\n\n\nOr within the fully qualified domain name for the endpoint:\n\n\nhttp://apiv1.example.com\n\n\nThe version need not be numeric, nor specified using the \u201cv[x]\u201d syntax. Alternatives include dates, project names, seasons or other identifiers that are meaningful enough to the team producing the APIs and flexible enough to change as the versions change.\n\n\nSubbu Allamaraju, revisits one of the recurring debates in the REST community; the standard media types vs. custom media types and tries to determine the best practices when using them. He starts with the stating dichotomous views on the use of media types.\n\n\nOpinion 1: Web services must use standard media types to be RESTful.\nOpinion 2: Custom media types are necessary to keep interactions visible, and to serve as contracts.\nThe first opinion which, if adhered to strictly, per Roy Fieldings thesis, \u201cthe use of media types such as application/vnd.example.myway+xml is not RESTful\u201d. Subbu believes that understanding the impact of such media type usage in the real world is more important than following the thesis to the letter. There are however comments that suggest that this interpretation of the thesis might be up for debate as well.\n\n\nTo the contrary, the second opinion, he says, leads to visibility of the messages at the protocol level via the use of custom media types.\n\n\n[\u2026] For instance, how can anyone know if a representation that uses application/xml media type describes a purchase order, or a photo album? If the web service uses media types likeapplication/vnd.example.po and application/vnd.example.album, then any one can interpret the semantics of the representation without parsing the body of the representation. Per this line of thinking, a media type is an identifier for message semantics, and message recipients use media types to trigger processing code.\n\n\n\u201cSo what is the right thing to do?\u201d  He asks, as he puts forth his idea, in a effort to democratically determine the best practices\n\n\n\n\nIf the sender is formatting representations using standard extensible formats such as XML or JSON, use standard media types such as application/xml and application/json.\n\n\nMint new media types when you invent new formats.\n\n\nIf you are just looking for a way to communicate application level semantics for XML and JSON messages, use something else (e.g. XML namespaces and conventions).\n\n\nIf the goal is versioning, use version identifiers in URIs.\nGiving java-like examples, He asserts that though its possible to peek into the messages to see how a request can be processed, it compromises visibility or opacity as the case may be.\n\n\n\n\nMedia types such as application/xml and application/json are good enough for XML and JSON message processing in code. [\u2026] URI based approaches are guaranteed to work across the stack. Ignoring real-world interoperability for the sake of \"architectual purity\" or \"RESTful contracts\" may eventually back fire.\n\n\nVia the post is the solution presented by Subbu found the right balance between architectural purity and interoperable real-world solutions? Be sure to visit the original post to weigh in your opinion.\n\n\nTips for versioning\n\n\nVersioning is one of the most important considerations when designing your Web API.\n\n\nNever release an API without a version and make the version mandatory.\n\n\nLet's see how three top API providers handle versioning.\n\n\nTwilio /2010-04-01/Accounts/\n\n\nsalesforce.com /services/data/v20.0/sobjects/Account\n\n\nFacebook ?v=1.0\n\n\nTwilio uses a timestamp in the URL (note the European format).\n\n\nAt compilation time, the developer includes the timestamp of the application when the code was compiled. That timestamp goes in all the HTTP requests.\n\n\nWhen a request arrives, Twilio does a look up. Based on the timestamp they identify the API that was valid when this code was created and route accordingly.\n\n\nIt's a very clever and interesting approach, although we think it is a bit complex. For example, it can be confusing to understand whether the timestamp is the compilation time or the timestamp when the API was released.\n\n\nSalesforce.com uses v20.0, placed somewhere in the middle of the URL.\n\n\nWe like the use of the v. notation. However, we don't like using the .0 because it implies that the interface might be changing more frequently than it should. The logic behind an interface can change rapidly but the interface itself shouldn't change frequently.\n\n\nFacebook also uses the v. notation but makes the version an optional parameter.\n\n\nThis is problematic because as soon as Facebook forced the API up to the next version, all the apps that didn't include the version number broke and had to be pulled back and version number added.\n\n\nHow to think about version numbers in a pragmatic way with REST?\n\n\nNever release an API without a version. Make the version mandatory.\n\n\nSpecify the version with a 'v' prefix. Move it all the way to the left in the URL so that it has the highest scope (e.g. /v1/dogs).\n\n\nUse a simple ordinal number. Don't use the dot notation like v1.2 because it implies a granularity of versioning that doesn't work well with APIs--it's an interface not an implementation. Stick with v1, v2, and so on.\n\n\nHow many versions should you maintain? Maintain at least one version back.\n\n\nFor how long should you maintain a version? Give developers at least one cycle to react before obsoleting a version.\n\n\nSometimes that's 6 months; sometimes it's 2 years. It depends on your developers' development platform, application type, and application users. For example, mobile apps take longer to rev' than Web apps.\n\n\nShould version and format be in URLs or headers?\n\n\nThere is a strong school of thought about putting format and version in the header.\n\n\nSometimes people are forced to put the version in the header because they have multiple inter-dependent APIs. That is often a symptom of a bigger problem, namely, they are usually exposing their internal mess instead of creating one, usable API facade on top.\n\n\nThat's not to say that putting the version in the header is a symptom of a problematic API design. It's not!\n\n\nIn fact, using headers is more correct for many reasons: it leverages existing HTTP standards, it's intellectually consistent with Fielding's vision, it solves some hard realworld problems related to inter-dependent APIs, and more.\n\n\nHowever, we think the reason most of the popular APIs do not use it is because it's less fun to hack in a browser.\n\n\nSimple rules we follow:\n\n\nIf it changes the logic you write to handle the response, put it in the URL so you can see it easily.\n\n\nIf it doesn't change the logic for each response, like OAuth information, put it in the header.\n\n\nThe code we would write to handle the responses would be very different.\n\n\nThere's no question the header is more correct and it is still a very strong API design.\n\n\nDeprecation\n\n\nSometimes it is necessary to phase out an API endpoint (or version). I.e. this may be necessary if a field is no longer supported in the result or a whole business functionality behind an endpoint has to be shut down. There are many other reasons as well.\n\n\nMUST: Obtain Approval of Clients\n\n\nBefore shutting down an API (or version of an API) the producer must make sure, that all clients have given their consent to shut down the endpoint. Producers should help consumers to migrate to a potential new endpoint (i.e. by providing a migration manual). After all clients are migrated, the producer may shut down the deprecated API.\n\n\nMUST: External Partners Must Agree on Deprecation Timespan\n\n\nIf the API is consumed by any external partner, the producer must define a reasonable timespan that the API will be maintained after the producer has announced deprecation. The external partner (client) must agree to this minimum after-deprecation-lifespan before he starts using the API.\n\n\nMUST: Reflect Deprecation in API Definition\n\n\nAPI deprecation must be part of the OpenAPI definition. If a method on a path, a whole path or even a whole API endpoint (multiple paths) should be deprecated, the producers must set deprecated=true on each method / path element that will be deprecated (OpenAPI 2.0 only allows you to define deprecation on this level). If deprecation should happen on a more fine grained level (i.e. query parameter, payload etc.), the producer should set deprecated=true on the affected method / path element and add further explanation to the description section.\n\n\nIf deprecated is set to true, the producer must describe what clients should use instead and when the API will be shut down in the description section of the API definition.\n\n\nMUST: Monitor Usage of Deprecated APIs\n\n\nOwners of APIs used in production must monitor usage of deprecated APIs until the API can be shut down in order to align deprecation and avoid uncontrolled breaking effects. See also the general rule on API usage monitoring\n\n\nSHOULD:: Add a Warning Header to Responses\n\n\nDuring deprecation phase, the producer should add a Warning header (see RFC 7234 - Warning header) field. When adding the Warning header, the warn-code must be 299 and the warn-text should be in form of \"The path/operation/parameter/... {name} is deprecated and will be removed by {date}. Please see {link} for details.\" with a link to a documentation describing why the API is no longer supported in the current form and what clients should do about it. Adding the Warning header is not sufficient to gain client consent to shut down an API.\n\n\nSHOULD:: Add Monitoring for Warning Header\n\n\nClients should monitor the Warning header in HTTP responses to see if an API will be deprecated in future.\n\n\nMUST: Not Start Using Deprecated APIs\n\n\nClients must not start using deprecated parts of an API.", 
            "title": "Versioning and extensibility"
        }, 
        {
            "location": "/versioning-and-extensibility/#versioning-and-extensibility", 
            "text": "versioning  Use API Versioning    what is a breaking change  breaking changes   http://www.jenitennison.com/2009/07/22/versioning-uris.html  A lot of things that we want to talk about (make RDF assertions about) are non-information resources. We give them URIs to name them, so that we can talk about them unambiguously, and we give them HTTP URIs so that we have a way of finding information resources (documents) that give us information about them.   non-information resource URIs must not include information that is likely to change  non-information resource URIs must not include unnecessary hierarchy   Always version your API. Versioning helps you iterate faster and prevents invalid requests from hitting updated endpoints. It also helps smooth over any major API version transitions as you can continue to offer old API versions for a period of time.\nHowever, the version needs to be in the URL to ensure browser explorability of the resources across versions\nWell documented and announced multi-month deprecation schedules can be an acceptable practice for many APIs. https://stripe.com/docs/api#versioning   Like building an application it is important to keep your API standardized and extensible.  It's easy to want to add \"quick fixes\" to make customers happy, but everything you do should be carefully thought out in order to make sure your API continues to serve not only your needs, but also your clients.  Remember, when you create an API you are creating a contract- your users are depending on your API not just to make their application work, but in order to make a living and feed their families.  When you break things, or when you break backwards compatibility you are taking their time and resources to fix their application instead of adding features and keeping their customers happy.   The industry solution to this has been versioning, however, versioning is merely a Band-Aid, a temporary solution to make migration to the new system less stressful for your clients, but increasingly difficult on you.  Keep in mind, when you have multiple versions of your API you end up supporting and maintaining those versions.  One of the greatest challenges in regards to versioning is getting developers to migrate from one version to another, all while keeping your support staff from going insane.  This doesn't mean that you shouldn't plan for versioning.  Rather it means that you should plan to incorporate a version identifier (either in the URI or in the content-header of the response), but work under the mindset that you will only version your API if...   You have backwards incompatible PLATFORM changes \u2013 in other words you completely change the UI or way your platform works  You find that your API is no longer extendable \u2013 which is exactly what we are trying to avoid here  You find that your spec no longer meets your developer's needs \u2013 for example, they are demanding REST instead of SOAP   You should NOT version your API just because:   You added additional endpoints  You added additional data in the response  You changed technologies \u2013 your API should be decoupled from your technology stack  You changed your applications services or code \u2013 your API should be decoupled from your service layer   To clarify on the last two, it shouldn't matter what technologies you are using, or how your services work.  The API should interact with both, but be decoupled enough that changing something in the background does not effect the API adversely.  Any changes you make to your API in regards to the technology or service layer should be as seamless and transparent as possible.  After all, the less you can break backwards compatibility, the happier you, and your customers will be.  And this can only happen if you go into building your API with a long-term, flexibility, and extensibility focus.", 
            "title": "Versioning and Extensibility"
        }, 
        {
            "location": "/versioning-and-extensibility/#extensibility-and-versioning", 
            "text": "Managing change in any distributed client/server environment can be hard. In these environments, clients count on servers to honor their contracts.  When a change is backward compatible, you need not upgrade clients at the same time as you modify the server.  Forward compatibility  may be important when you have several clients and servers upgraded at different points in time. In this case, some newer clients may be interacting with older servers. The purpose of forward compatibility is to ensure that newer clients can continue to use the older servers without disruption albeit with reduced functionality.  The characteristic that lets you maintain compatibility is  extensibility . Extensibility is a design process to account for future changes.  As a transfer protocol, HTTP is extensible, but that does not mean that APIs built over HTTP are automatically extensible.  It takes discipline, careful planning, and defensive coding practices.  A one-time simultaneous upgrade of all server and clients is not a realistic task. You need to plan for a gradual rollout of upgrades to servers and clients to maintain the availability of the overall system.  Note that both clients and server need to take the appropriate steps to operate smoothly under change. For the server, the goal is to keep the clients from breaking. For the clients, the objective is not fail when new unknown data or links appear in representations.", 
            "title": "Extensibility and Versioning"
        }, 
        {
            "location": "/versioning-and-extensibility/#how-to-maintain-uri-compatibility-url-regression", 
            "text": "Keeps URIs permanent.  Treat URIs containing the same query parameters but in a different order as the same  When you add new parameters to URIs, continue to honor existing parameters, and treat new parameters as optional.  When changing data formats for query parameters, continue to honor existing formats. If that is not viable, introduce format changes via new query parameters or new URIs.  Treat query parameters in URIs as optional except when need for concurrency and security.   DO  use rewrite rules on the server to shield clients from implementation-level changes.  DO  use  301 Moved Permanently  with the new URI in the  Location  header, when URIs must change to honor old URIs.  DO  monitor request traffic for redirection.  DO  maintain redirection services until you are confident the majority of clients have updated their stored links to point to the new URI.  DO  communicate an appropriate end-of-life policy for old URIs, when you cannot monitor the old URIs.  DO  convert  301 Moved Permanently  to  410 Gone  or  404 Not Found  once the traffic has fallen of or the preset time interval has passed.", 
            "title": "How to Maintain URI Compatibility (url regression)"
        }, 
        {
            "location": "/versioning-and-extensibility/#how-to-maintain-compatibility-of-xml-and-json-representations", 
            "text": "When making changes to JSON preserve the hierarchical structure so that clients can continue to follow the same structure to extract data.  Make new data elements in requests optional to maintain compatibility with existing clients. Clients that do not send new data fields must be able to continue to function.  Do not remove or rename any data fields from representaions in reponse bodies.  Example: Clients that do not understand new fields may not store them locally. If this causes the server to assume the user has no email address, introduce a new version of the resource that contains the email.", 
            "title": "How to Maintain Compatibility of XML and JSON Representations"
        }, 
        {
            "location": "/versioning-and-extensibility/#how-to-maintain-compatibility-of-links", 
            "text": "Avoid removing links\nDo not change the value of the  rel  and  href  attributes of links.\nWhen introducing new resources, use links to provide URIs of those resources to clients.", 
            "title": "How to Maintain Compatibility of Links"
        }, 
        {
            "location": "/versioning-and-extensibility/#when-to-version", 
            "text": "Consider versioning when the server cannot maintain compatibility. Also consider versioning if some clients require behavior or functionality different from other clients.  Versioning may introduce new problems:   Data stored by the clients for one version may not automatically work with the data from a different version. Clients may have to port resource data stored locally before migrating to the new version.  Version changes may involve new business rules and new application flow, which requires code changes in clients.  Maintaining multiple versions of resources at the same time is not trivial.  When you use links to convey URIs to clients, clients may store them locally. When you assign new URIs, clients will have to upgrade those URIs along with other stored data of resources.", 
            "title": "When to Version"
        }, 
        {
            "location": "/versioning-and-extensibility/#how-to-version-restful-web-services", 
            "text": "Add new resources with new URIs when there is a change in the behavior of resource or a change in the information contained in representations.  Use easily detectable patterns such as  v1  or  v2  in subdomain names, path segments, or query parameters to distinguish URIs by their version.  Avoid treating each version as a new representation with a new media type of the same resource.  Versioning involves versioning resources with new URIs. This is because HTTP dictates everything except URIs of resources and their representations. Although you can add custom HTTP methods and headers, such additions may impair interoperability.  Avoid introducing new media types for each version since it leads to media type proliferation, which reduce interoperability.", 
            "title": "How to Version RESTful Web Services"
        }, 
        {
            "location": "/versioning-and-extensibility/#compatibility", 
            "text": "", 
            "title": "Compatibility"
        }, 
        {
            "location": "/versioning-and-extensibility/#must-dont-break-backward-compatibility", 
            "text": "Change APIs, but keep all consumers running.  Consumers usually have independent release life-cycles, focus on stability, and avoid changes that do not provide additional value. APIs are contracts between service providers and service consumers that cannot be broken via unilateral decisions.  There are two techniques to change APIs without breaking them:   follow rules for compatible extensions  introduce new API versions and still support older versions   We strongly encourage using compatible API extensions and discourage versioning. The below guideline rules for service providers and consumers enable us (having Postel's Law in mind) to make compatible changes without versioning.  Hint: Please note that the compatibility guarantees are for the \"on the wire\" format. Binary or source compatibility of code generated from an API definition is not covered by these rules. If client implementations update their generation process to a new version of the API definition, it has to be expected that code changes are necessary.", 
            "title": "MUST: Don't Break Backward Compatibility"
        }, 
        {
            "location": "/versioning-and-extensibility/#should-prefer-compatible-extensions", 
            "text": "API designers should apply the following rules to evolve RESTful APIs for services in a backward-compatible way:   Add only optional, never mandatory fields.  Never change the semantic of fields (e.g. changing the semantic from customer-number to customer-id, as both are different unique customer keys)  Input fields may have (complex) constraints being validated via server-side business logic. - - Never change the validation logic to be more restrictive and make sure that all constraints a clearly defined in description.  Enum ranges can be reduced when used as input parameters, only if the server is ready to accept and handle old range values too. Enum range can be reduced when used as output parameters.  Enum ranges cannot not be extended when used for output parameters \u2014 clients may not be prepared to handle it. However, enum ranges can be extended when used for input parameters.  Support redirection in case an URL has to change (301 Moved Permanently).", 
            "title": "SHOULD:: Prefer Compatible Extensions"
        }, 
        {
            "location": "/versioning-and-extensibility/#must-prepare-clients-to-not-crash-on-compatible-api-extensions", 
            "text": "Service clients should apply the robustness principle:   Be conservative with API requests and data passed as input, e.g. avoid to exploit definition eficits like passing megabytes for strings with unspecified maximum length.  Be tolerant in processing and reading data of API responses, more specifically...   Service clients must be prepared for compatible API extensions of service providers:   Be tolerant with unknown fields in the payload (see also Fowler's \"TolerantReader\" post), i.e. ignore new fields but do not eliminate them from payload if needed for subsequent PUT requests.  Be prepared to handle HTTP status codes not explicitly specified in endpoint definitions. Note also, that status codes are extensible. Default handling is how you would treat the corresponding x00 code (see RFC7231 Section 6).  Follow the redirect when the server returns HTTP status 301 Moved Permanently.", 
            "title": "MUST: Prepare Clients To Not Crash On Compatible API Extensions"
        }, 
        {
            "location": "/versioning-and-extensibility/#should-design-apis-conservatively", 
            "text": "Designers of service provider APIs should be conservative and accurate in what they accept from clients:   Unknown input fields in payload or URL should not be ignored; servers should provide error feedback to clients via an HTTP 400 response code.  Be accurate in defining input data constraints (like formats, ranges, lengths etc.) \u2014 and check constraints and return dedicated error information in case of violations.  Prefer being more specific and restrictive (if compliant to functional requirements), e.g. by defining length range of strings. It may simplify implementation while providing freedom for further evolution as compatible extensions.   Not ignoring unknown input fields is a specific deviation from Postel's Law (e.g. see also\nThe Robustness Principle Reconsidered) and a strong recommendation. Servers might want to take different approach but should be aware of the following problems and be explicit in what is supported:  Ignoring unknown input fields is actually not an option for PUT, since it becomes asymmetric with subsequent GET response and HTTP is clear about the PUT \"replace\" semantics and default round-trip expectations (see RFC7231 Section 4.3.4). Note, accepting (i.e. not ignoring) unknown input fields and returning it in subsequent GET responses is a different situation and compliant to PUT semantics.  Certain client errors cannot be recognized by servers, e.g. attribute name typing errors will be ignored without server error feedback. The server cannot differentiate between the client intentionally providing an additional field versus the client sending a mistakenly named field, when the client's actual intent was to provide an optional input field.\nFuture extensions of the input data structure might be in conflict with already ignored fields and, hence, will not be compatible, i.e. break clients that already use this field but with different type.  In specific situations, where a (known) input field is not needed anymore, it either can stay in the API definition with \"not used anymore\" description or can be removed from the API definition as long as the server ignores this specific parameter.", 
            "title": "SHOULD:: Design APIs Conservatively"
        }, 
        {
            "location": "/versioning-and-extensibility/#must-always-return-json-objects-as-top-level-data-structures-to-support-extensibility", 
            "text": "In a response body, you must always return a JSON objects (and not e.g. an array) as a top level data structure to support future extensibility. JSON objects support compatible extension by additional attributes. This allows you to easily extend your response and e.g. add pagination later, without breaking backwards compatibility.", 
            "title": "MUST: Always Return JSON Objects As Top-Level Data Structures To Support Extensibility"
        }, 
        {
            "location": "/versioning-and-extensibility/#should-avoid-versioning", 
            "text": "When changing your RESTful APIs, do so in a compatible way and avoid generating additional API versions. Multiple versions can significantly complicate understanding, testing, maintaining, evolving, operating and releasing our systems (supplementary reading).  If changing an API can't be done in a compatible way, then proceed in one of these three ways:   create a new resource (variant) in addition to the old resource variant  create a new service endpoint \u2014 i.e. a new application with a new API (with a new domain name)  create a new API version supported in parallel with the old API by the same microservice   As we discourage versioning by all means because of the manifold disadvantages, we suggest to only use the first two approaches.", 
            "title": "SHOULD:: Avoid Versioning"
        }, 
        {
            "location": "/versioning-and-extensibility/#must-use-media-type-versioning", 
            "text": "When API versioning is unavoidable, you have to design your multi-version RESTful APIs using media type versioning (instead of URI versioning, see below). Media type versioning is less tightly coupled since it supports content negotiation and hence reduces complexity of release management.  Media type versioning: Here, version information and media type are provided together via the HTTP Content-Type header \u2014 e.g. application/x.zalando.cart+json;version=2. For incompatible changes, a new media type version for the resource is created. To generate the new representation version, consumer and producer can do content negotiation using the HTTP Content-Type and Accept headers. Note: This versioning only applies to the request and response content schema, not to URI or method semantics.  In this example, a client wants only the new version of the response:  Accept: application/x.zalando.cart+json;version=2\nA server responding to this, as well as a client sending a request with content should use the Content-Type header, declaring that one is sending the new version:  Content-Type: application/x.zalando.cart+json;version=2  Using header versioning should:   include versions in request and response headers to increase visibility  include Content-Type in the Vary header to enable proxy caches to differ between versions    Hint: OpenAPI currently doesn't support content negotiation, though a comment in this issue mentions a workaround (using a fragment identifier that gets stripped off). Another way would be to document just the new version, but let the server accept the old one (with the previous content-type).   Until an incompatible change is necessary, it is recommended to stay with the standard application/json media type.", 
            "title": "MUST: Use Media Type Versioning"
        }, 
        {
            "location": "/versioning-and-extensibility/#must-do-not-use-uri-versioning", 
            "text": "With URI versioning a (major) version number is included in the path, e.g. /v1/customers. The consumer has to wait until the provider has been released and deployed. If the consumer also supports hypermedia links \u2014 even in their APIs \u2014 to drive workflows (HATEOAS), this quickly becomes complex. So does coordinating version upgrades \u2014 especially with hyperlinked service dependencies \u2014 when using URL versioning. To avoid this tighter coupling and complexer release management we do not use URI versioning, and go instead with media type versioning and content negotiation (see above).  The API will inevitably need to be modified in ways that will impact customer client code. Not all customer clients will be able to make the necessary changes in their code right away, so the API should maintain older versions for some time after releasing the new version, usually a minimum of 90 days.  In the \u2018When to Version\u2019 section should you mention APIs that use enum types? My company\u2019s API reference documentation has attributes with an enum type and we list all values. We ran into a problem when a requirement added an enum value to an existing attribute and it broke a partner app. The partner had coded to the defined enum values in the documentation and their app wasn\u2019t expecting new values with future releases. I corrected the problem by removing the new enum value and I defined any request to add a new enum value to an existing attribute requires a new API version. Last, going forward new attributes with an enum type will be defined as String in the documentation and we will indicate the values are not limited to the ones defined.  Versioning Content Types  The use of content negotiation with custom MIME types allows for finer grained versioning at the resource level without the need to create a plethora of new endpoints. New versions must be communicated to developers through existing channels \u2013 email, developer blogs, etc. When a content version is no longer supported, the body of the HTTP error should include a list of supported content types.  Versioning URIs  The use of both hyper links and content negotiation should all but eliminate the need to version at the URI level. However, there may be instances where the entire structure of the API must be changed, particularly when moving from one API style to another, such when moving from an RPC-type style to NARWHL. To prepare for these possibilities, it\u2019s recommended that a version be embedded within each API endpoint. The version can either be embedded at the root for all endpoints of a given API, such as:  http://api.example.com/v1  Or within the fully qualified domain name for the endpoint:  http://apiv1.example.com  The version need not be numeric, nor specified using the \u201cv[x]\u201d syntax. Alternatives include dates, project names, seasons or other identifiers that are meaningful enough to the team producing the APIs and flexible enough to change as the versions change.  Subbu Allamaraju, revisits one of the recurring debates in the REST community; the standard media types vs. custom media types and tries to determine the best practices when using them. He starts with the stating dichotomous views on the use of media types.  Opinion 1: Web services must use standard media types to be RESTful.\nOpinion 2: Custom media types are necessary to keep interactions visible, and to serve as contracts.\nThe first opinion which, if adhered to strictly, per Roy Fieldings thesis, \u201cthe use of media types such as application/vnd.example.myway+xml is not RESTful\u201d. Subbu believes that understanding the impact of such media type usage in the real world is more important than following the thesis to the letter. There are however comments that suggest that this interpretation of the thesis might be up for debate as well.  To the contrary, the second opinion, he says, leads to visibility of the messages at the protocol level via the use of custom media types.  [\u2026] For instance, how can anyone know if a representation that uses application/xml media type describes a purchase order, or a photo album? If the web service uses media types likeapplication/vnd.example.po and application/vnd.example.album, then any one can interpret the semantics of the representation without parsing the body of the representation. Per this line of thinking, a media type is an identifier for message semantics, and message recipients use media types to trigger processing code.  \u201cSo what is the right thing to do?\u201d  He asks, as he puts forth his idea, in a effort to democratically determine the best practices   If the sender is formatting representations using standard extensible formats such as XML or JSON, use standard media types such as application/xml and application/json.  Mint new media types when you invent new formats.  If you are just looking for a way to communicate application level semantics for XML and JSON messages, use something else (e.g. XML namespaces and conventions).  If the goal is versioning, use version identifiers in URIs.\nGiving java-like examples, He asserts that though its possible to peek into the messages to see how a request can be processed, it compromises visibility or opacity as the case may be.   Media types such as application/xml and application/json are good enough for XML and JSON message processing in code. [\u2026] URI based approaches are guaranteed to work across the stack. Ignoring real-world interoperability for the sake of \"architectual purity\" or \"RESTful contracts\" may eventually back fire.  Via the post is the solution presented by Subbu found the right balance between architectural purity and interoperable real-world solutions? Be sure to visit the original post to weigh in your opinion.", 
            "title": "MUST: Do Not Use URI Versioning"
        }, 
        {
            "location": "/versioning-and-extensibility/#tips-for-versioning", 
            "text": "Versioning is one of the most important considerations when designing your Web API.  Never release an API without a version and make the version mandatory.  Let's see how three top API providers handle versioning.  Twilio /2010-04-01/Accounts/  salesforce.com /services/data/v20.0/sobjects/Account  Facebook ?v=1.0  Twilio uses a timestamp in the URL (note the European format).  At compilation time, the developer includes the timestamp of the application when the code was compiled. That timestamp goes in all the HTTP requests.  When a request arrives, Twilio does a look up. Based on the timestamp they identify the API that was valid when this code was created and route accordingly.  It's a very clever and interesting approach, although we think it is a bit complex. For example, it can be confusing to understand whether the timestamp is the compilation time or the timestamp when the API was released.  Salesforce.com uses v20.0, placed somewhere in the middle of the URL.  We like the use of the v. notation. However, we don't like using the .0 because it implies that the interface might be changing more frequently than it should. The logic behind an interface can change rapidly but the interface itself shouldn't change frequently.  Facebook also uses the v. notation but makes the version an optional parameter.  This is problematic because as soon as Facebook forced the API up to the next version, all the apps that didn't include the version number broke and had to be pulled back and version number added.", 
            "title": "Tips for versioning"
        }, 
        {
            "location": "/versioning-and-extensibility/#how-to-think-about-version-numbers-in-a-pragmatic-way-with-rest", 
            "text": "Never release an API without a version. Make the version mandatory.  Specify the version with a 'v' prefix. Move it all the way to the left in the URL so that it has the highest scope (e.g. /v1/dogs).  Use a simple ordinal number. Don't use the dot notation like v1.2 because it implies a granularity of versioning that doesn't work well with APIs--it's an interface not an implementation. Stick with v1, v2, and so on.  How many versions should you maintain? Maintain at least one version back.  For how long should you maintain a version? Give developers at least one cycle to react before obsoleting a version.  Sometimes that's 6 months; sometimes it's 2 years. It depends on your developers' development platform, application type, and application users. For example, mobile apps take longer to rev' than Web apps.  Should version and format be in URLs or headers?  There is a strong school of thought about putting format and version in the header.  Sometimes people are forced to put the version in the header because they have multiple inter-dependent APIs. That is often a symptom of a bigger problem, namely, they are usually exposing their internal mess instead of creating one, usable API facade on top.  That's not to say that putting the version in the header is a symptom of a problematic API design. It's not!  In fact, using headers is more correct for many reasons: it leverages existing HTTP standards, it's intellectually consistent with Fielding's vision, it solves some hard realworld problems related to inter-dependent APIs, and more.  However, we think the reason most of the popular APIs do not use it is because it's less fun to hack in a browser.  Simple rules we follow:  If it changes the logic you write to handle the response, put it in the URL so you can see it easily.  If it doesn't change the logic for each response, like OAuth information, put it in the header.  The code we would write to handle the responses would be very different.  There's no question the header is more correct and it is still a very strong API design.", 
            "title": "How to think about version numbers in a pragmatic way with REST?"
        }, 
        {
            "location": "/versioning-and-extensibility/#deprecation", 
            "text": "Sometimes it is necessary to phase out an API endpoint (or version). I.e. this may be necessary if a field is no longer supported in the result or a whole business functionality behind an endpoint has to be shut down. There are many other reasons as well.", 
            "title": "Deprecation"
        }, 
        {
            "location": "/versioning-and-extensibility/#must-obtain-approval-of-clients", 
            "text": "Before shutting down an API (or version of an API) the producer must make sure, that all clients have given their consent to shut down the endpoint. Producers should help consumers to migrate to a potential new endpoint (i.e. by providing a migration manual). After all clients are migrated, the producer may shut down the deprecated API.", 
            "title": "MUST: Obtain Approval of Clients"
        }, 
        {
            "location": "/versioning-and-extensibility/#must-external-partners-must-agree-on-deprecation-timespan", 
            "text": "If the API is consumed by any external partner, the producer must define a reasonable timespan that the API will be maintained after the producer has announced deprecation. The external partner (client) must agree to this minimum after-deprecation-lifespan before he starts using the API.", 
            "title": "MUST: External Partners Must Agree on Deprecation Timespan"
        }, 
        {
            "location": "/versioning-and-extensibility/#must-reflect-deprecation-in-api-definition", 
            "text": "API deprecation must be part of the OpenAPI definition. If a method on a path, a whole path or even a whole API endpoint (multiple paths) should be deprecated, the producers must set deprecated=true on each method / path element that will be deprecated (OpenAPI 2.0 only allows you to define deprecation on this level). If deprecation should happen on a more fine grained level (i.e. query parameter, payload etc.), the producer should set deprecated=true on the affected method / path element and add further explanation to the description section.  If deprecated is set to true, the producer must describe what clients should use instead and when the API will be shut down in the description section of the API definition.", 
            "title": "MUST: Reflect Deprecation in API Definition"
        }, 
        {
            "location": "/versioning-and-extensibility/#must-monitor-usage-of-deprecated-apis", 
            "text": "Owners of APIs used in production must monitor usage of deprecated APIs until the API can be shut down in order to align deprecation and avoid uncontrolled breaking effects. See also the general rule on API usage monitoring", 
            "title": "MUST: Monitor Usage of Deprecated APIs"
        }, 
        {
            "location": "/versioning-and-extensibility/#should-add-a-warning-header-to-responses", 
            "text": "During deprecation phase, the producer should add a Warning header (see RFC 7234 - Warning header) field. When adding the Warning header, the warn-code must be 299 and the warn-text should be in form of \"The path/operation/parameter/... {name} is deprecated and will be removed by {date}. Please see {link} for details.\" with a link to a documentation describing why the API is no longer supported in the current form and what clients should do about it. Adding the Warning header is not sufficient to gain client consent to shut down an API.", 
            "title": "SHOULD:: Add a Warning Header to Responses"
        }, 
        {
            "location": "/versioning-and-extensibility/#should-add-monitoring-for-warning-header", 
            "text": "Clients should monitor the Warning header in HTTP responses to see if an API will be deprecated in future.", 
            "title": "SHOULD:: Add Monitoring for Warning Header"
        }, 
        {
            "location": "/versioning-and-extensibility/#must-not-start-using-deprecated-apis", 
            "text": "Clients must not start using deprecated parts of an API.", 
            "title": "MUST: Not Start Using Deprecated APIs"
        }
    ]
}